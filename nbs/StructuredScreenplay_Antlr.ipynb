{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert IMSDB screenplays to structured json using Antlr\n",
    "\n",
    "Note that the attempt to [use OpenAI to parse the screenplay](./LLM_StructuredOutput_Screenplay.ipynb) failed with a `ContentFilterError`. Either flagged as copyrighted work or something else. Switching to a proper parser. One of the risks with using OpenAI or any LLM for that matter, is that you need to catch the hallucinations _(gpt-4o-mini, for instance, was making up some dialogues. Caught it entirely by accident)_. So might need a proper parser in any case. However, given that it tooke me almost 3 days to get the parser cleaned up and the LLM could figure out the format instantly, I am looking at a large amount of time investment if I come across other formats for screen-plays. At that point, worth investing in installing a local LLM _(Ollama, TGI etc)_ and see if those also fail with ContentFilter error. For now, moving on.\n",
    "\n",
    " - Taking ScreenJSON schema as a starting point\n",
    " - Using Aladin script for now\n",
    " - Copying bits and pieces from OpenAI access notebooks\n",
    "\n",
    "## Completed files\n",
    "\n",
    "> Links are relative to the file. Will not work when executed on colab, please view the notebook in github.\n",
    "\n",
    " - [README_DevelopingTheParser-2.md](../lib/python/imsdb/README_DevelopingTheParser-2.md) \n",
    " - [Antlr Grammar - Screenplay.g4](../lib/python/imsdb/antlr/Screenplay.g4)\n",
    " - [Screenplay json code (dataclasses and pydantic bits)](../lib/python/imsdb/screenplay_json.py)\n",
    " - [Antlr Parser driver](../lib/python/imsdb/screenplay_parser.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install pre-reqs\n",
    "!pip install nb-js-diagrammers --quiet\n",
    "!pip install iplantuml --quiet\n",
    "!pip install tiktoken --quiet\n",
    "\n",
    "# For charts and such\n",
    "%load_ext nb_js_diagrammers\n",
    "import iplantuml\n",
    "\n",
    "# For displaying HTML and Markdown responses from ChatGPT\n",
    "from IPython.display import display, HTML, Markdown\n",
    "\n",
    "def colorBox(txt):\n",
    "    display(HTML(f\"<div style='border-radius:15px;padding:15px;background-color:pink;color:black;'>{txt}</div>\"))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANTLR\n",
    "\n",
    "The screenplay is so nicely structured. At first I thought regex could work. However, the regex was getting somewhat hairy with named sub-patterns and such. I remember back in the day, perl regexes got complex enough I had to make them whitespace insensitive and break them into multiple lines, nicely indented. Those were complex. Python not yet so familiar and I am thinking, getting refamiliarized with Antlr is not a bad thing after all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = \"\"\"\n",
    "PEDDLER:    Oh I come from a land\n",
    "    From a faraway place\n",
    "    Where the caravan camels roam\n",
    "    Where they cut off your ear /Where it's flat and immense\n",
    "    If they don't like your face /And the heat is intense\n",
    "    It's barbaric, but hey--it's home!\n",
    "    When the wind's at your back\n",
    "\n",
    "(Camera tilts down to find JAFAR sitting on his horse and IAGO\n",
    "    on his shoulder.  GAZEEM comes riding up to the pair.)\n",
    "\n",
    "JAFAR:  You...are late.\n",
    "GAZEEM:A thousand apologies, O patient one.\n",
    "JAFAR:  You have it, then?\n",
    "GAZEEM:I had to slit a few throats to get it.  (Pulls out\n",
    "        half of the medallion.  JAFAR reaches out for it,\n",
    "        but GAZEEM yanks it back.)  Ah, ah, ahhh!  The treasure!\n",
    "        (IAGO squawks as he flies by and grabs the medallion.)  Ouch!\n",
    "JAFAR:  Trust me, my pungent friend.  You'll get what's\n",
    "        coming to you.\n",
    "IAGO:   What's coming to you!  Awk!\n",
    "\n",
    "(JAFAR pulls out the second half of the medallion.  He connects\n",
    "    them, and the insect medallion begins to glow.  Finally, it\n",
    "    flies out of JAFAR's hand, scaring the horses, and is off\n",
    "    towards the dunes.)\n",
    "\n",
    "JAFAR:  Quickly, follow the trail!    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I did manage to get some copy/paste action going and came up with a parser/lexr fairly quickly. Quite a bi rusty after all this time, but a lot like riding a bike. As long as you remember `zero-width-look-behind`, it'll all come back :-).\n",
    "\n",
    "```python\n",
    "# Use examples from\n",
    "# - \n",
    "# - https://yetanotherprogrammingblog.medium.com/antlr-with-python-974c756bdb1b\n",
    "# Except use the stream-from-text for temp writing\n",
    "\n",
    "import sys\n",
    "from antlr4 import*\n",
    "from antlrgen.ScreenplayLexer  import ScreenplayLexer\n",
    "from antlrgen.ScreenplayParser import ScreenplayParser\n",
    "\n",
    "sample = \"\"\"SULTAN: That's right.  You've certainly proven your worth\n",
    "        as far as I'm concerned. It's that law that's the\n",
    "        problem.\n",
    "JASMINE:    Father?\n",
    "SULTAN: Well, am I sultan or am I sultan?  From this day\n",
    "        forth, the princess shall marry whomever she deems\n",
    "        worthy.\n",
    "JASMINE:    (She smiles widely and runs into ALADDIN's arms.)\n",
    "        Him!  I choose...I choose you, Aladdin.\n",
    "ALADDIN:    Ha, ha.  Call me Al.\n",
    "\n",
    "(They are about to kiss when giant blue hands pull everybody together.\n",
    "    GENIE is decked out in a Hawaiian shirt with golf clubs and a Goofy\n",
    "     hat.)\n",
    "\n",
    "GENIE:  Oh, all of ya. Come over here.  Big group hug!\n",
    "        Mind if I kiss the monkey?  (He kisses ABU.)  Ooh,\n",
    "        hairball!  Well, I can't do any more damage around\n",
    "        this popsicle stand.  I'm outta here!  Bye, bye,\n",
    "        you two crazy lovebirds.  Hey, Rugman: ciao!  I'm\n",
    "        history!   No, I'm mythology!  No, I don't care\n",
    "        what I am--I'm free!\n",
    "\"\"\"\n",
    "\n",
    "def main(argv):\n",
    "    print(f\"Have {len(argv)} arguments\")\n",
    "\n",
    "    # Either FileStream if I have an arg or the local hardcoded sample.\n",
    "    input_stream = FileStream(argv[1]) if len(argv) > 1 else InputStream(sample)    \n",
    "\n",
    "    lexer  = ScreenplayLexer(input_stream)\n",
    "    stream = CommonTokenStream(lexer)\n",
    "    parser = ScreenplayParser(stream)\n",
    "\n",
    "    tree = parser.screenplay()\n",
    "    print(tree.toStringTree(recog=parser))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(sys.argv)\n",
    "```\n",
    "\n",
    "Note that the code is all under `repo: hillops/libs/python/hillops/imsdb`. The above allows me to quicly debug the parsing of the entire file\n",
    " - `python screenplay_parser.py samples/aladdin.txt`\n",
    " - for each lexer error I encounter\n",
    "   - copy the offending parts to `sample`\n",
    "   - run `python screenplay_parser.py` so it'll pick the sample inside\n",
    "   - fix that particular problem and then run the whole file.\n",
    "\n",
    "Most were issues with unbalanced parens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grammer TODOs\n",
    "\n",
    "Am building up a list here as I encounter problems. Will refine all of them one by one.\n",
    "\n",
    " - ‚¨ú **Nested parens inside a `scene_section`**. Keep a push/pop count of parens and make a nested ( section semantically belong to the currently under-parse `scene_section`. \n",
    "   - üëâ [this slackoverflow post](https://stackoverflow.com/questions/63400627/antlr4-java-how-to-make-a-semantic-predicate-that-skips-a-token-lexer-accord) on implementing semantic predicates. Hopefully it works in python.\n",
    " - ‚úîÔ∏è **Scene lines using trailing `:`** Once the `NAME:` is passed. Allow the use of subsequent words that also end in `:`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse Problem - nested parens in scene lines\n",
    "\n",
    "_I remember way back that I had to keep some code in the parser rule to count the parens_. Maybe I can simply start a new rule ?\n",
    "\n",
    "\n",
    "```antlr\n",
    "scene_section       : PARENS_OPEN section_line+ PARENS_CLOSE\n",
    "                    ;\n",
    "```\n",
    "\n",
    "*to*\n",
    "\n",
    "```antlr\n",
    "scene_section       : PARENS_OPEN \n",
    "                        (\n",
    "                            section_line\n",
    "                            |\n",
    "                            scene_section\n",
    "                        )+ \n",
    "                        PARENS_CLOSE WS? CR?\n",
    "                    ;\n",
    "```\n",
    "\n",
    "This will simply add nested scene_sections. After parse, will need to merge them in. Might be simpler to deal with them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse - Problem - distinguish NAME: and other colon terminated words\n",
    "\n",
    "Not sure yet how to distinguish `^ALADDIN:` and `...Turned into:`. The rule could be that the start of a new line with no-space can only be a name. All others can be words. How ? look-behind sntactic assertion ?\n",
    "\n",
    "> Temporarily changed `ABU into:` ‚Üí `ABU into - `\n",
    "\n",
    "---\n",
    "\n",
    "**Problem**: not sure yet how to distinguish `^ALADDIN:` and `...Alladin:)`. The rule could be that the start of a new line with no-space can only be a name. All others can be words. How ? look-behind sntactic assertion ?\n",
    "\n",
    "> Temporarily changed `Whispering:` ‚Üí `Whispering`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse Problem - Semantics of actor introduction with no lines ?\n",
    "\n",
    "Have this strange text:\n",
    "\n",
    "```screenplay\n",
    "GENIE:\n",
    "        GIRLS: (in couterpoint)\n",
    "    Prince Ali, Handsome is he, Ali Ababwa\n",
    "        There's no question this Ali's alluring\n",
    "    That physique, how can I speak\n",
    "        Never ordinary, never boring\n",
    "    Weak at the knee\n",
    "        Everything about the man just plain impresses\n",
    "    Well, get on out in that square\n",
    "        He's a wonder, he's a whiz, a wonder\n",
    "    Adjust your veil and prepare\n",
    "        He's about to pull my heart asunder\n",
    "    To gawk and grovel and stare at Prince Ali!\n",
    "        And I absolutely love the way he dresses!\n",
    "```\n",
    "\n",
    "Not sure if this is a typo or is allowed. Does this mean a scene with `GENIE and GIRLS` ? Ignore for now by simply removing `GENIE:` _(line 1557)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse Problem - Formalize end of actor block\n",
    "\n",
    "While parsing the test passage below\n",
    "\n",
    "```screenplay\n",
    "ALADDIN:    Sultan?  They want me to be sultan?\n",
    "\n",
    "(GENIE comes out of lamp)\n",
    "\n",
    "GENIE:  Huzzah!  Hail the conquering hero! \n",
    "```\n",
    "\n",
    "The parse-tree print looked like below:\n",
    "\n",
    "```text\n",
    "(screenplay (actor_section (actor_name ALADDIN :) (section_line      Sultan?   They  want  me  to  be  sultan?\\n\\n) (scene_section ( (....\n",
    "```\n",
    " - Note that the `\\n\\n` sequence was included in the section_line. \n",
    " - I want this to terminate the `actor_section` and start a new `scene_section`\n",
    "\n",
    "I currently have the following relevant bits\n",
    "\n",
    "```antlr\n",
    "\n",
    "actor_section       : actor_name \n",
    "                        (\n",
    "                            section_line\n",
    "                            |\n",
    "                            scene_section\n",
    "                        ) +\n",
    "                        (\n",
    "                            CR \n",
    "                            | \n",
    "                            EMPTY_LINE\n",
    "                            |\n",
    "                            EOF\n",
    "                        ) ?\n",
    "                    ;\n",
    "\n",
    "section_line        : WS? (WORD WS? PUNCT? WS?)+\n",
    "\n",
    "WORD               : ~[ \\n\\r\\t:()]+ (WS | CR | EOF)?\n",
    "\n",
    "CR                 : [\\r\\n]+\n",
    "                   ;\n",
    "\n",
    "WS                 : [ \\t]+\n",
    "                   ;\n",
    "\n",
    "EMPTY_LINE         : (CR WS* CR)+\n",
    "                   ;                   \n",
    "\n",
    "```\n",
    "\n",
    "Obvious issue right away\n",
    " - Why is `WORD` including `WS|CR|EOF` ??\n",
    " - I would have like to have a look-ahead assertion in the lexer to terminate a WORD.\n",
    " - If WS is not significant can I just `-> skip` it and drop it from the parser rules ?\n",
    "\n",
    "Since a carriage-return (CR) is simply a continuation of the actor lines, we need more complex semantics to when an actor's segment ends: any of the following\n",
    " - EMPTY_LINE \n",
    " - CR `<nospace>` NAME COLON   _next actor segment starts_\n",
    " - CR `<nospace>` (...) _scene section starts_\n",
    "\n",
    "So far all actor lines continuations have had space in front to visually group it with the lines above, so maybe the `<nospace>` can be made meaningful.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "**Fix 1**\n",
    "\n",
    "Doing this iteratively in the order listed.\n",
    "\n",
    " - `WORD: : ~[ \\n\\r\\t:()]+ ;` remove the idiotic tacking on of WS \n",
    " - `WS    : ... -> skip;` Skip the WS token.\n",
    " - `section_line        : (WORD PUNCT?)+;` since WS is skipped, might as well remove all `WS?` tokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Convert parse-tree to JSON\n",
    "\n",
    "Started following example to convert things to an internal structure that I could later convert to JSON. Initially, I went with a solution of multiple `@dataclass` objects. However, those would need custom conversion to json _(you can use their underlying `__dict` to dump as json string I think but this struck me later)_ so, following some advice on the net, switched to use pydantic classes.\n",
    "\n",
    "```python\n",
    "from pydantic import BaseModel\n",
    "from typing import Optional, List\n",
    "\n",
    "# Using pydantic classes instead of dataclasses to get the .json() method.\n",
    "class SceneSection(BaseModel):\n",
    "    content: str\n",
    "\n",
    "class ActorSceneSection(SceneSection):\n",
    "    pass\n",
    "\n",
    "class ActorSection(BaseModel):\n",
    "    name   : str\n",
    "    content: List[str | ActorSceneSection]\n",
    "\n",
    "class ScreenPlay(BaseModel):    \n",
    "    sections: List[ActorSection | SceneSection]\n",
    "```\n",
    "\n",
    "Followed the example code at [sumeets medium article](), I came up with this.\n",
    "\n",
    "```python\n",
    "class ScreenplayASTToDataclass(ScreenplayListener):\n",
    "\n",
    "    def __init__(self):\n",
    "        # Keep a stack with whatever object is being\n",
    "        # built at the current parse level\n",
    "        self.stack : List[any] = []\n",
    "        self.parsed_screenplay = None\n",
    "\n",
    "    def parsed_data(self):\n",
    "        return self.parsed_screenplay\n",
    "    \n",
    "    #- Stack management ------------\n",
    "    def _pop(self):\n",
    "        self.stack.pop()\n",
    "\n",
    "    def _push(self, obj):\n",
    "        self.stack.append(obj)\n",
    "\n",
    "    def _peek(self):\n",
    "        return self.stack[-1]\n",
    "    #-------------- Stack management -\n",
    "\n",
    "    # Enter a parse tree produced by ScreenplayParser#screenplay.\n",
    "    def enterScreenplay(self, ctx:ScreenplayParser.ScreenplayContext):\n",
    "        self._push(\n",
    "            ScreenPlay(sections=[])\n",
    "            )\n",
    "\n",
    "    # Exit a parse tree produced by ScreenplayParser#screenplay.\n",
    "    def exitScreenplay(self, ctx:ScreenplayParser.ScreenplayContext):\n",
    "        self.parsed_screenplay = self._pop()\n",
    "\n",
    "    # Enter a parse tree produced by ScreenplayParser#actor_section.\n",
    "    #    screenplay : (\n",
    "    #                 actor_section \n",
    "    #                 | \n",
    "    #                 scene_section\n",
    "    #               )+ EOF\n",
    "    #               ;\n",
    "    def enterActor_section(self, ctx:ScreenplayParser.Actor_sectionContext):\n",
    "        self._push(\n",
    "            ActorSection(name='not_set', content=[])\n",
    "        )        \n",
    "\n",
    "    # Exit a parse tree produced by ScreenplayParser#actor_section.\n",
    "    def exitActor_section(self, ctx:ScreenplayParser.Actor_sectionContext):\n",
    "        actor_section = self._pop()\n",
    "\n",
    "        top = self._peek()\n",
    "        assert isinstance(top, ScreenPlay)\n",
    "        top.sections.append(actor_section)\n",
    "\n",
    "\n",
    "    # Enter a parse tree produced by ScreenplayParser#actor_name.\n",
    "    def enterActor_name(self, ctx:ScreenplayParser.Actor_nameContext):\n",
    "        name = \"unknown\"\n",
    "        token = ctx.NAME_WORD()\n",
    "        print(f\"actor_name. NAME_WORD = {token}\")        \n",
    "        print(f\"token.getText() = {token.getText()}\")\n",
    "        print(f\"token.getSymbol() = {token.getSymbol()}\")\n",
    "        print(f\"token.getChildCount() = {token.getChildCount()}\")\n",
    "\n",
    "        top = self._peek()\n",
    "        assert isinstance(top, ActorSection)\n",
    "        top.name = name\n",
    "\n",
    "    # Exit a parse tree produced by ScreenplayParser#actor_name.\n",
    "    def exitActor_name(self, ctx:ScreenplayParser.Actor_nameContext):\n",
    "        # Nothing to pop as enterActor_name directly modifies the \n",
    "        # actorSection on the stack.\n",
    "        pass\n",
    "\n",
    "\n",
    "    # Enter a parse tree produced by ScreenplayParser#section_line.\n",
    "    def enterSection_line(self, ctx:ScreenplayParser.Section_lineContext):\n",
    "        pass\n",
    "\n",
    "    # Exit a parse tree produced by ScreenplayParser#section_line.\n",
    "    def exitSection_line(self, ctx:ScreenplayParser.Section_lineContext):\n",
    "        pass\n",
    "\n",
    "\n",
    "    # Enter a parse tree produced by ScreenplayParser#scene_section.\n",
    "    def enterScene_section(self, ctx:ScreenplayParser.Scene_sectionContext):\n",
    "        pass\n",
    "\n",
    "    # Exit a parse tree produced by ScreenplayParser#scene_section.\n",
    "    def exitScene_section(self, ctx:ScreenplayParser.Scene_sectionContext):\n",
    "        pass\n",
    "```\n",
    "\n",
    "While investigating the `actor_name` rule. Realized that the `ctx.NAME_WORD` was giving me `ALLADIN:`. I will have to strip the colon later on. Seeing if I can change it so I get two tokens _(and then in `enterActorName only use the `WORD` token)_.\n",
    "\n",
    "```diff\n",
    "+actor_name          : WORD COLON\n",
    "-actor_name          : NAME_WORD\n",
    "                    ;                    \n",
    "```                    \n",
    "\n",
    "‚úîÔ∏è that worked. Now I have `WORD() and COLON()` in the context and the listener code changes to \n",
    "\n",
    "```python\n",
    "def enterActor_name(self, ctx:ScreenplayParser.Actor_nameContext):        \n",
    "        token = ctx.WORD()\n",
    "        name  = token.getText()\n",
    "        \n",
    "        # debug\n",
    "        print(f\"actor_name. WORD token= {token}\")\n",
    "        print(f\"token.getText() = {token.getText()}\")\n",
    "        print(f\"token.getSymbol() = {token.getSymbol()}\")\n",
    "        print(f\"token.getChildCount() = {token.getChildCount()}\")\n",
    "```\n",
    "\n",
    "gives me the following output\n",
    "\n",
    "```console\n",
    "actor_name. WORD token= ALADDIN\n",
    "token.getText() = ALADDIN\n",
    "token.getSymbol() = [@0,0:6='ALADDIN',<1>,1:0]\n",
    "token.getChildCount() = 0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
