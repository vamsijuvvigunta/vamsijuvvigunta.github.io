## Information Transfer Rate in BCIs: Towards Tightly Integrated Symbiosis

Suayb S. Arslan and Pawan Sinha

Department of Brain and Cognitive Sciences,
Massachusetts Institute of Technology,
Cambridge, MA, USA, 02139.

E-mail: sarslan@mit.edu, psinha@mit.edu


Abstract.

Objective. The information transmission rate (ITR), or effective bit rate, is a popular
and widely used information measurement metric, particularly popularized for SSVEPbased Brain-Computer (BCI) interfaces. By combining speed and accuracy into a
single-valued parameter, this metric aids in the evaluation and comparison of various
target identification algorithms across different BCI communities. In order to calculate
ITR, it is customary to assume a uniform input distribution and an oversimplified
channel model that is memoryless, stationary, and symmetrical in nature with discrete
alphabet sizes. To accurately depict performance and inspire an end-to-end design for
futuristic BCI designs, a more thorough examination and definition of ITR is therefore
required. Approach. We model the symbiotic communication medium, hosted by the
retinogeniculate visual pathway, as a discrete memoryless channel and use the modified
capacity expressions to redefine the ITR. We leverage a result for directed graphs to
characterize the relationship between the asymmetry of the transition statistics and
the ITR gain due to the new definition, leading to potential bounds on data rate
performance. Main Results. On two well-known SSVEP datasets, we compared two
cutting-edge target identification methods. Results indicate that the induced DM
channel asymmetry has a greater impact on the actual perceived ITR than the change
in input distribution. Moreover, it is demonstrated that the ITR gain under the
new definition is inversely correlated with the asymmetry in the channel transition
statistics. Individual input customizations are further shown to yield perceived ITR
performance improvements. Finally, an algorithm is proposed to find the capacity of
binary classification and further discussions are given to extend such results to multiclass case through ensemble techniques. Significance. We anticipate that the results
of our study will contribute to the characterization of the highly dynamic BCI channel
capacities, performance thresholds, and improved BCI stimulus designs for a tighter
symbiosis between the human brain and computer systems while ensuring the efficient
utilization of the underlying communication resources.


-----

2

1. Introduction

The primary goal of brain-computer interfaces (BCIs) is to provide new channel
formations for communication and control between the human brain and its surrounding
devices with computational capabilities [1]. One of the most commonly used modality
in BCIs is known as Electroencephalography (EEG), which results due to stimuli
generating electrical fields caused by synchronously firing neuron populations in the
human brain. The majority of BCI research efforts are focused on developing effective
stimuli, experimental protocol developments and target identification/classification
algorithms to boost information transfer and eventually help novel communication
paradigms to emerge such as found in recent semantic communications [2]. A summary
of the system diagram for a cannonical BCI is shown in Fig. 1, where the components of
the system and their interactions are illustrated. Despite low information rates, different
types of BCIs are actively employed in various applications nowadays, ranging from
clinical deployments [3] to entertainment world, including but not limited to gaming [4],

[5] and virtual/augmented reality [6]. Such commonplace applications has become quite
encouraging and pushed current state-of-the-art BCI research forward, enabling tight
coupling and enhanced human involvements in hybrid (human and machine combined)
systems [7].
As shown in Fig. 1, a generic BCI system typically consists of three main parts:
(1) the stimulation/feedback generation, (2) the communication channel hosted by the
participating subject, and (3) the target identification system. To be able to deliver
fast communication rates and form a close symbiosis between the human brain and

Figure 1: Closed loop system of generic BCIs. A BCI system consists of
(1) the stimulation/feedback, (2) the communication channel and (3) the target
identification/classification.


-----

3

computing devices, these components must work in concert. In other words, a joint
design of these components is required to modulate and control the communication
channel formed by the combined effects of these three components. On the other hand,
for a truly coupled system design in which the stimulus generation and TIs co-adapt
to each other [8], better understanding of the performance evaluations, controlling
measures and the underlying statistical channel formed is needed. Once established,
new research directions can be explored such as optimal stimuli designs, developing
useful performance bounds on the data transfer rates and develop genuine interfaces for
enhanced end-user experience [9].

1.1. Performance Evaluation

Assessments of BCI system performance are typically performed at two levels of
evaluation, namely user-level and system-level. User-level performance is measured by
the degree of congruence between user intent and the signal feature(s) the BCI uses to
identify the intent. The user-level quality control heavily depends on the visual setup,
the selection and presentation of stimuli, and how the stimulation is carried out (usually
forming a protocol). However, system-level performance evaluations are often done in
terms of target identification speed and classification accuracy, conventionally tied to
each other. Fair comparisons are difficult since these two criteria, when articulated
independently, are affected by the program’s capability as well as how well the system
combines the user’s control with that application. Additionally, it can be challenging
to theoretically quantify the structural representations of content since they may be
influenced by perception [10]. In many applications, the interpretation of quality may
differ across different users, leading to indispensable subjectivity. It is anticipated that
forthcoming BCI systems will impose less cognitive burden, as stimulation paradigms
become more personalized and rely on individualized internal representations [11]. As
a result, many researchers have opted to use context-sensitive definitions of information
instead [12]. However, in mainstream BCI applications where systematic and well‡
defined stimulation paradigms and protocols are used, the semantic meanings of inputs
and outputs are established beforehand, and users are essentially trained on the internal
structure of the presented symbols that are to be communicated. This is what
fundamentally makes objective (context-independent) definitions of information still
relevant for practical BCI implementations. Information transfer rate (ITR), cited
primarily in [13] and [14], is one of a number of context-independent information
measuring tools developed in response to the demand for a single theoretical measure
that combines accuracy and speed. In our work, information transfer is quantified

In some of these applications, there may be a requirement for enhanced definitions of information
‡
that consider the contextual dependence in achieving data transfer rates. Nonetheless, this would pose
additional challenges by introducing greater subjectivity in evaluating performance across various BCIs.


-----

4

according to information theory measures such as entropy, pioneered by Shannon’s
seminal work in 1948 [15].
As shall be demonstrated, it is not hard to realize that ITR can be used to
measure the magnitude of coupling in a BCI communication setting as well as the
levels of attention and consciousness, which can be leveraged heavily in passive-BCI
settings as well [16]. In the past, ITR is employed in BCIs both using P300 paradigm

[17] and in particular steady-state visual evoked potentials (SSVEPs) due to proven
high data communication performance. For instance, recent progression towards taskrelated component analysis for SSVEPs is shown to achieve rates up to 325 bits/min
ITR in a cue-guided 40-character spelling task [18]. For that reason, the rest of
our discussions will rely on SSVEP-based BCIs due to their excellent information
transfer rates. We primarily note that such performance has been possible due to
carefully designed stimulus generation and Target Identification (TI) techniques. Stimuli
generation involves embedding information into frequencies and phases of the signals
(neural modulation) in an SSVEP paradigm [19]. TI requires compensating for the noise
and degradations imposed on the information passing through a channel induced by the
BCI, resting on the physical medium of the retinogeniculate visual pathway. It turns
out that many information processing strategies are used throughout the visual system
and the basic approach is to lump them into a coarse description of an information
link [20]. The main objective of the majority of the past work has been to maximize
the information transfer rate that can be transmitted over this induced channel [21].
Although the BCI channel properties are determined by the choice of stimulation and the
target identification methods combined, without the accurate measurement of the ITR
performance, it would not be possible to assess the user experience, develop successful
stimuli design techniques and conduct joint end-to-end optimizations of BCIs.
Preconditions and deficiencies of the conventional ITR definition are considered
in a number of past studies. For instance, [22] summarizes the problems with the
conventional definition and particularly emphasizes the significance of the channel
parameter estimations (accuracy or false alarm rates) in online synchronous BCIs.
The same study proposed a task-oriented online BCI test in the hope to help with
the real-world applications. Moreover, recent works such as [23] proposed to use an
alternative closed-form formulation derived in [24] for the ITR computation via making
approximations such as removing negativity constraint on the input distribution using
only a fairly limited dataset. In fact, this closed form’s usefulness is restricted to square
and non-singular channel transition characterizations [25]. Moreover, no further analysis
or intuition is presented in both studies in terms of the channel transition characteristics,
the stimuli design, and means and strategies for achieving the capacity of the underlying
BCI channel models.


-----

5

1.2. Contributions and Organization

One of the main objectives of this study is to outline the basic principles of conventional
ITR definition and in order to re-express its deficiencies, highlight the challenges of
channel characterization problems between the human brain and the computer system.
As part of our contributions, we realize that the performance characterization of any
technique for an asymmetric and non-stationary channel requires a precise computation
procedure to accurately determine the practical ITR the subjects experience. Moreover,
we outline a numerical calculation of the ITR and provided a few directions for tighter
symbiosis within the context of joint system design. More specifically, we demonstrate
that our analysis can be used to design better input sequences as well as novel design
of user interfaces for futuristic BCIs to maximize the information flow in the induced
communication channel. For instance, we have found that customizing the stimuli for
each subject increases the channel capacity dramatically and an end-to-end joint system
design seems to reduce the performance gap due to using different TIs in SSVEP settings.
Finally, we have provided a preliminary algorithm for finding fundamental data transfer
rate limitations of a two-symbol BCI as a proof-of-concept.
The rest of the paper is organized as follows. In Section II, we introduce the
generalized DM channel model and rephrased the conventional ITR definition. We
report the deficiencies as well as workarounds through integrating the algorithmic
capacity calculations into the ITR definition, subject to information theoretic bounds.
In Section III, we present a few results to distinguish different ITR definitions, and
explore the asymmetry in channel transition statistics and establish the ties with the
channel conditional entropy. We discuss some of the important implications of our
results in Section IV. For instance, we have shown a potential performance (ITR) upper
bound using ensemble learning with binary weak learners. Finally, we conclude our
paper in Section V by prodiving a few future directions.

2. Methods

2.1. Channel Model and Conventional ITR Definition

Let us consider a discrete BCI communication system, where one of the M symbols
from the set X = {x1, . . ., xM } is to be transferred at a given time. It is quite typical to
express BCI system performance in terms of the information transfer rate (ITR) [13].
This is expressed in bits per trial observation window T [1] as,


�
(1)


ITR = log2(M) + P (T ) log2(P (T )) + (1 − P (T )) log2


� 1 P (T )
−

M 1
−


where M is the number of targets and P (T ) is the aggregate average accuracy of the
target identification algorithm. Note that the trial time dependency of the accuracy is


-----

6

crucial in this formulation. Equation (1) is derived from the popular mutual information
measure defined for two random variables X and Y as

I(X; Y ) = H(Y ) H(Y X) (2)
− |

� 1 �

� �
= PY (y) log2 − PX (x)H(Y |X = x) (3)

y∈Y PY (y) x


where H(.) is the entropy, X represents the discrete source taking on one of the M
∈X
target classes and Y (typically = ) is the predicted output at the other end of
∈Y Y X
the BCI system with distribution PY (y). Capacity (C) is defined to be the supremum
of the mutual information over all input (probability) distributions PX(x) i.e.,

= sup I(X; Y ) (4)
C
PX (x)

In the case of perfect communication (P (T ) → 1) the ITR will simply be log2(M), the
number of bits used to represent all targets assuming these targets have equal probability
of occurring i.e., 1/M (uniform input distribution i.e., PX (x) = M1 [) [26].]
Equality given for ITR (1) is based on the capacity of a symmetric Discrete
Memoryless Channel (DMC) that errs with an equal probability 1−p
M −1 [in favor of all]
other M 1 classes. In addition, T is expressed in terms of seconds and the ITR is
−
usually scaled with 60/T and expressed in terms of bits/min. Let us define the channel
transition matrix of the induced DMC and express it as follows,


p1,1 p1,2 . . . p1,M
p2,1 p2,2 . . . p2,M
... ... ... ...
pM,1 pM,2 . . . pM,M







P =







with j [p][i,j][ = 1 for][ i][ ∈{][1][,][ 2][, . . ., M][}][. We use the short-cut notation][ P][Y][ |][X][(][y][j][|][x][i][) =][ p][i,j]

[�]

as each entry of P to refer to the channel transition/conditional probability distribution.
Note that symmetry assumption in the channel transition statistics i.e., the distribution
of the probability of erring over all non-target values make the uniform input distribution
achieve the DMC capacity. Hence,


= ITR (5)


�[�]


max
PX (.) [I][(][X][;][ Y][ ) =]


�

�
log2(M) − pi,j log2

j


� 1

pi,j


Although we have assumed the possible number of outcomes to be M i.e., = M,
|Y|
the channel outputs can be expanded to include “erasures” i.e., making no decision on
the final output, leading to the channel transition matrix P to be of size M (M + 1).
×
Both channel models are illustrated in Fig. 2.


-----

7

Figure 2: Typical discrete BCI Channel Models for symbol/character communications.
A discrete set of characters are communicated. In case, the communication reliability
is below a threshold, the communicated character can be assumed to be erased. In the
figure, e is used to represent erasure.

2.2. Deficiencies and Workarounds

Some of the major deficiencies of the conventional ITR definition have already been
articulated in [22]. One of these deficiencies is the assumption that the input (the
stimuli) has uniform distribution of M input symbols. However, this assumption is not
necessarily true and optimal in realistic settings. For instance, in a speller application,
the characters of the English alphabet are not necessarily used equally frequently in
everyday language and hence in an online experiment, some of the characters would
naturally be intended to spell more often. In addition, transition probabilities of the
underlying channel are not necessarily symmetric and stationary [27]. In an SSVEPbased BCI, the ability to distinguish between two targets is determined by factors such
as the frequency and phase selections, as well as the spatial distance at which these
targets are presented to the subjects. Therefore, the assumption pi,j = M1−−p1 [for all]
i, j satisfying i = j (i.e., equal probability transitions to all non-target classes) is not
̸
necessarily totally accurate.
Calculating the capacity of the dynamic channel model described in our work
poses a challenge because the channel transition matrix is dependent not only on


-----

8

the stimulus design (how information is encoded into the visual pathway) but also
on the methods used for identifying the target, which is quite untypical in classical
digital communications. In addition, as the observation window (T ) widens, accuracy
is reported to increase since the identification is performed via observation of more time
series data [28]. However, the observation window being larger will change the stochastic
nature of the channel (and its parameters) i.e., the channel transition matrix indeed is a
function of time. The extent of the introduced channel memory is yet another challenge
to tackle. Thus, instead of considering the entire timeline, we consider specific time
points such that the dependency of the channel transition matrix at those points is
sufficiently eliminated. Some of the previous works proposed closed form expressions

[29] under certain assumptions about Px(x) and non-singularity assumption for P, which
is highly unlikely for larger window lengths. Our approach in this study involves treating
the channel as a DMC without any preconceived notions about its statistical nature. We
first estimate the transition statistics and then use numerical methods to calculate the
capacity. Finally, we compare our ITR results with those obtained using the conventional
formulation.

2.3. An iterative definition of ITR

In this section, we have provided the details of the proposed ITR definition and its
numerical computation, derived primarily from the capacity results of asymmetric
DMCs. Let us begin with M = 2 binary symbol communication case as the baseline
which leads to a closed form expression.

2.3.1. Exemplary Case: “Binary Classification”: Let us suppose X = Y = {x1, x2} i.e.,
the input is one of the two possible symbols with PX (x1) = px. This would correspond
to differentiation of two different classes such as face/non-face [30] or familiar/nonfamiliar (target/non-target paradigm) dichotomies. Thus, we can express the mutual
information

I(X; Y ) = H(Y ) H(Y X) (6)
− |

= h(px(1 − p1,2) + (1 − px)p2,1) − pxh(p1,2) − (1 − px)h(p2,1) (7)

where h(x) = x log(x) (1 x) log(1 x) is the binary entropy function. Setting the
− − − −
derivative with respect to px to zero, we obtain
1 1 = 2 h(1p−1,p2)1,−2−h(pp22,1,1) (8)
−
px(1 − p1,2 − p2,1) + p2,1

Subsequently, px that satisfies this equality can be plugged into (7) and following some
algebraic operations, the final capacity can be expressed as


h(p1,2)−h(p2,1) �

1−p1,2 −p2,1 (9)
− [(1][ −] [p][2][,][1][)][h][(][p][1][,][2][) +][ p][1][,][2][h][(][p][2][,][1][)]

1 − p1,2 − p2,1


C2(p1,2, p2,1) = log2


�
1 + 2


-----

9

Figure 3: For a given estimate of the channel transition statistics P[ˆ] (T ) based on a
window length T, this figure illustrates the numerical computation of the capacity
C
that is used to estimate the information transfer rates. Note that this procedure also
computes the optimal input distribution PX[∗] [(][x][) that leads to][ C][. In BCI settings however,]
we typically need to optimize both the input and the channel transition statistics P[ˆ] (T )
simultaneously (see Discussion section).

Finally, the ITR in bits/min can be found by [60]

T [C][2][(][p][1][,][2][, p][2][,][1][).]

2.3.2. Extension to General Case “M symbols”: When there are more than two classes,
the computations mentioned above become more complex as they require the calculation
of partial derivatives and solving of transcendental equations. This complexity makes it
impossible to obtain closed form results. In the past, there have been successful efforts
to iteratively compute the capacity for discrete stationary channel models.
For memoryless channels (independent choice of symbols) with finite input and
output alphabets and respectively, the capacity can be computed by the BlahutX Y
Arimoto (BA) algorithm [25, 31]. On the other hand, in a typical speller task, due
to the formation of language and words, the source will inherently have memory. The
Blahut-Arimoto algorithm was also extended to channels with memory and finite input
alphabets and state spaces [32] such as Hidden Markov Models (HMM). However,
modeling language with an HMM is quite challenging [34] and can result in inordinate
computation time and/or only an approximation for the capacity.
We have employed a variant of the BA algorithm, which is an iterative procedure
and assumes an arbitrary input probability distribution function PX[(0)][(][x][) in the beginning]
and optimizes it over multiple iterations [33]. Since access to the real channel transition
statistics is unavailable, we used data to estimate transition probabilities as ˆpi,j. Let us
express the non-normalized estimated input distribution for xi ∈X at the (k − 1)-th


-----

10

step (k 1) as
≥

D[(][k][−][1)](xi) = PX[(][k][−][1)](xi) exp �D�pˆi,j||PY[(][k][−][1)](yj)�� (10)


�
pˆi,j
PY[(][k][−][1)](yj)


= PX[(][k][−][1)](xi) exp


��


(11)


�pˆi,j
(12)


= PX[(][k][−][1)](xi)


N
�

i=0


� N
�

pˆi,j log
i=0

�
pˆi,j
PY[(][k][−][1)](yj)


where PY[(][k][−][1)](yj) = i [P][ (]X[k][−][1)](xi)ˆpi,j and D[.||.] is the relative entropy (also known as

[�]

Kullback-Leibler or KL divergence) which is given for two probability distributions P (x)
and Q(x) as

�

[P Q] = P (x) log [P] [(][x][)] (13)
D ||

Q(x) [.]

x


Then, the input distribution can be normalized and finally expressed as,

PX[(][k][)][(][x][i][) =] D[(][k][−][1)](xi) (14)
�

j [D][(][k][−][1)][(][x][j][)] [.]

Note that we can compute D[(][k][)](xi) and PX[(][k][)][(][x][i][) iteratively using equations (12) and]
(14) as given above. Ultimately, iterations will cease if


maxxi �pˆi,j||PY[(][k][)][(][y][j][)]� − � PX[(][k][)][(][x][i][)][D]�pˆi,j||PY[(][k][)][(][y][j][)]�

[D] i

� I(X��;Y ) �


< γth (15)


holds for a given error threshold γth (e.g., γth = 10[−][5]). For the rest of our discussions,
we refer to this iterative process as

[C, PX[∗] [(][x][)] =][ BA][(ˆ][P][)][,] (16)

where BA(.) refers to the algorithm leveraging the estimated probabilities, is the
C
capacity, Pˆ = {pˆi,j} and PX[∗] [(][x][):=][ P][ ∞]X [(][x][) is the optimal input distribution that]
maximizes the mutual information. For better visualization, we have also provided
the flow diagram of the iterative computation of the capacity in Fig. 3.

Remark 1. This two-step process can be shown to converge through iterations of two
different convex optimization problems and the convergence rate is shown to improve in
a later study [35].

Remark 2. The expressions we have developed can be applied to channel models that
have a number of outputs greater than M. For instance, Fig. 2 depicts an example of a
channel model with an “erasure” output, which has M + 1 possible outcomes.


-----

11


2.4. Fano’s Inequality

Optimization of channel transition statistics may lead to impractical and unrealistic
outcomes. To impose practical constraints, we invoke one of the well known bounds on
the conditional entropy of the channel statistics, known as Fano’s inequality. In essense,
Fano’s inequality provides a lower bound for the probability of target identification
error ǫM (= 1 − [�]i [P][X] [(][x][i][)][p][i,i][) due to information degradation via the channel induced]

by the BCI. The channel transition (conditional) probabilities PY |X(yj|xi), emprically
estimated by the confusion matrices, appear in the bound as follows,


ǫM ≥ [H][(]log[Y][ |]2[X](M[)][ −] −[h]1)[(][ǫ][M] [)] ≥ [H][(][Y][ )][ −]log[I]2[(]([X]M[;][ Y]) [ )][ −] [1] (17)

where h(ǫM ) = −ǫM log(ǫM ) − (1 − ǫM ) log(1 − ǫM ) is the binary entropy function.
Accordingly, for a fixed ǫM, we can upper bound the conditional entropy as

�M 1� � 1 �
−

H(Y |X) ≤ ǫM log2 + (1 − ǫM ) log2 (18)

ǫM 1 − ǫM

= h(ǫM ) + ǫM log2(M − 1) (19)

Since in typical telecommunication applications the channel transition probabilities
are given as part of the model, the symbol detection error is bounded. As can be seen,
ǫM appears in both sides of the inequality (17).

Remark 3. Note that the bound in (17) does not apply to M = 2 case (zero
denominator) and countably infinite sets. However later studies extended this bound
to such corner cases [36, 37].

Remark 4. The bound on the conditional entropy given in (18) becomes h(ǫM ) when
M = 2 and can be shown to be looser for larger ǫM (see our experimental results).

2.5. Target Identification

It is conventional to divide TI methods developped for SSVEP-based BCIs into
two broad overarching categories, namely supervised and unsupervised (training-free).
Unsupervised techniques are particularly attractive since their use does not involve
user-specific-calibration phase (long training cycles) and provides more versatility in
everyday practices. On the other hand, supervised methods are shown to outperform
the unsupervised early strategies such as Cannonical Correlation Analysis (CCA) [38].
One of the most effective frequency recognition performance has been demonstrated
by a number of spatial filtering techniques to isolate task-specific source activities
from EEG signals. The task-related component analysis (TRCA) is one of prominent
techniques proposed in literature which hypothesizes that there are distinct cortical
sources in the brain which generates potentials upon the presentation of flickering


-----

12

stimuli. This idea originally applied to near-infrared spectroscopy (NIRS) [39], [40]
and later proven useful for multivariate EEG data [18]. Assuming s(t) R to be the
∈
task-related, n(t) to be the task-unrelated (noise and some other background brain
activity) components, the multivariate EEG signal x(t) R[N][c] is formed as a result of a
∈
linear generative model as follows,

xj(t) = ajs(t) + bjn(t) for j = 1, 2, . . ., Nc (20)

where Nc is the number of channels. Spatial filtering is about extracting the task-related
component s(t) from a linear combinations of multiple channel output signals x(t), i.e.,


Nc
�

wjajs(t) + wjbjn(t) (21)

j


s˜(t) =


Nc
�

wjxj(t) =

j


Main idea behind TRCA is to optimize weight coefficients (wj) so as to maximize
inter-trial covariance (reproducibility) of time-locked biomedical data. If we denote the
h-th trial of y(t) as y[(][h][)](t), then the sum of covariances of all possible combinations of
trials can be expressed as


Nt
�

h1,h2=1
h1̸=h2


Cov �y[(][h][1][)](t), y[(][h][2][)](t)� = w[T] Sw (22)


where Nt is the total number of trials, Cov(.) is the covariance operator, w = (wj)1≤j≤Nc
represents the weights of the spatial filter and S = (Sj1,j2)1≤j1,j2≤Nc is given by


Sj1,j2 =


Nt
�

h1,h2=1
h1̸=h2


� �
Cov xj[(][h]1 [1][)][(][t][)][, x]j[(][h]2 [2][)][(][t][)] (23)


For a finite solution, TRCA maximizes w[T] Sw subject to variance constraint, i.e.,
Var(y(t)) = w[T] Qw 1. The solution is given by the following unconstrained
≤
optimization problem

w[T] Sw
w[∗] = arg max (24)
w w[T] Qw

which can be recognized as a generalized Eigenvalue problem.
By creating a spatial mapping that projects the multivariate EEG data onto
a standard SSVEP representation space, the sum of squared correlations (SSCOR)
framework [46] seeks to identify a session independent representation of SSVEP
response. In this case, we express the optimization problem as


wX[∗] [,][ (][w]i[∗][) = arg max]wX,wi


Nt
�

i=1


�wX[T] [Cov] �x[(][X] [)](t), x[(][i][)](t)� wi�2 (25)


where


x[(][X] [)](t) = [1]

Nt


Nt
�

x[(][i][)](t) (26)

i=1


-----

13

is the template signal calculated for each target frequency, separately. Again for the
sake of obtaining a finite solution and put the optimization problem into a generalized
eigenvalue framework, we use the set of constraints for ∀i, wi[T] [Cov] �x[(][i][)](t), x[(][i][)](t)� wi = 1.
Note that there could be other spatial filtering techniques that can generate the
filter weights (w) as an application of generalized Eigenvalue problem [44]. However,
the arguments for the detection logic is common to all. Thus, in our work we will focus
on these two TIs when we report our results.
After determining the spatial filter weights, for a given single-trial test sample X,
the classification decision is made in favor of the frequency fn ∈{f1, . . ., fNf } based on
the Pearson’s correlation coefficient (ρ) as a solution to

τ = arg maxn ρ �X[T] wn, Xn[T] [w][n]�, (27)

where Nf is the total number and n is the index of the stimulation frequency. Assuming
the i-th maximum correlation for the frequencies fn is denoted by τi, consider a given
correlation threshold τt. If there exist multiple frequencies that satisfy the condition
ρ �X[T] wn, Xn[T] [w][n]� ≤ τt, i.e., ∀i, τi ≤ τt, then it might be advisable to refrain from
making any definitive decisions. Instead, the threshold value τ could be replaced with
e, which represents an “erasure” (see Fig. 2). Finally, if we concatenate all weights to
construct the matrix W = [w1 w2 . . . wNf ] and replace it with wn in Equation (27),
we obtain an ensemble TI algorithm. Same idea can be applied to both TI methods.

3. Experimental Results

3.1. Datasets

We have used two well-known datasets in the literature, namely, Benchmark [42] and
Beta datasets [43] to analyze/compare two known target identification algorithms,
namely the ensemble extensions of TRCA and SSCOR, based on the conventional as
well as proposed ITR definitions.
Benchmark dataset was collected from 35 subjects with normal/corrected-to-normal
vision on a 40-character (26 English alphabet letters, 10 digits, and 4 other symbols)
speller task using a 64-channel EEG recorder. Each subject was shown target characters
in distinct trials, where characters flicker at frequencies 8-15.8 Hz with 0.2 Hz increments
and phases 0-1.5π with 0.5π increments, where both increments are proportional to
stimulus index. Each trial began with a visual cue that was shown on the screen for
0.5 seconds to direct the subject’s gaze to the intended target, followed by 5 seconds
of stimulation and a final trailing 0.5-second offset, respectively. The observation
window includes gaze length as well as the signal length after the stimuli onset. At
the preprocessing stage, the recorded signals were downsampled to 250Hz. We have
assumed 130 ms visual pathway delay for both datasets. In this study, the following


-----

14

set of 9 channels (OZ, O1, O2, PZ, POZ, PO3 PO4, PO5 and PO6) are considered
since they are reported to be most reflective of neural activity due to tasks performed
in the experiment [42]. In Beta dataset on the other hand, 70 subjects participated in
four blocks of a cued-spelling task on a QWERTY virtual keyboard. The stimulation
duration is 2 seconds for the first 15 subjects whereas the rest of the other subjects are
stimulated for 3 seconds. Sixty-four channels of EEG data were collected by SynAmps2
(Neuroscan Inc.) data acquisition/amplifier system at a sampling rate of 1000Hz, which
were later downsampled to 250Hz. The rest of the settings are the same (channels used,
electrode locations, gaze-shift times, visual pathway latency, etc.). Since the trials were
carried out outside a laboratory setting, the Signal-to-Noise Ratio (SNR) of EEG in
Beta dataset is measured to be lower than that of the Benchmark dataset. To obtain
additional details about the pre-processing procedures, we suggest that the readers
consult the publications in which the creators of these datasets initially introduced
them.

3.2. Filter Banks

In our work, we have leveraged filter banks to decompose the EEG signals into
five overlapping sub-bands to make use of the independent information found in the
harmonics. A target detection technique is used independently for each of the sub-bands.
The cut-off frequency range for the sub-bands based on the EEG data bandwidth is set
between b 8 Hz and 90 Hz, where b 1, 2, 3, 4, 5 [45]. As the Target Identification
× ∈{ }
(TI) algorithm, we have employed two competing approaches, namely the TRCA [18]
and SSCOR [46] due to their high performance relative to other methods with reasonable
complexity (in terms of the number of parameters to optimize).
As mentioned before, the design methodology behind TRCA was the hypothesis
that the single-trial EEG data can be reconstructed as a linear sum of multiple time
series from different cortical sources [47]. Therefore, TRCA is used as a technique for
highlighting the task-related elements embedded in the EEG signals through enhancing
repeatability among different time-locked activities across trials. The covariance
between different trials is maximized to ensure such repeatability. On the other
hand, SSCOR transforms SSVEP signals to a common representation space through
the optimization of the individual SSVEP templates. Similar to TRCA, SSCOR also
achieves space transformation. In both of these methods, we learn a spatial filter for each
frequency (character) [44]. In our work, we have also employed an ensemble technique for
both methods where all spatial filters belonging to different frequencies are concatenated
for a performance boost. To determine a final score (a single correlation coefficient) for
classification, the correlation coefficients of the sub-band components are combined using
the weighted sum of squares approach [45].


-----

15


0.12


6


Figure 4: Capacity achieving distributions for different signal lengths (sec) as well as
their entropies for TRCA method using Benchmark dataset. Each bar plot consists
of 40 bars corresponding to the the probabilities assigned to each input symbol in the
speller application.

3.3. Evaluation Process

For each subject, we evaluated performance in a leave-one-trial-out fashion as in the
past literature i.e., the TI algorithms are trained over u 1 trials and tested on the
−
remaining trial for all u different combinations for u = 6 in Benchmark and u = 4 in
Beta datasets. When we present average subject performance, test performances are
combined (classification outcomes) in a single confusion matrix, which is normalized to
obtain the estimate of the channel transition probability matrix P[˜] with M = 40. In some
of the past works c.f. [18], [46], using conventional definition, ITR is calculated for each
subject and the average of these values (with the standard error) is reported despite the
nonlinear dependency of the definition on the accuracy. This type of averaging typically
leads to larger ITR values. In our work, we report all ITR results after averaging the
accuracy values (similarly false positive and negatives etc.) over all subjects before
calculating and reporting the final ITR. This way, we also ensure that the aggregate
human accuracy performance is translated into a single ITR metric. Note that with the
proposed definition, it would be unrealistic to expect the system to optimize the input
distributions for each subject separately in order to attain higher ITRs. To address this
point however, we have also demonstrated via violin plots by calculating the individual
ITRs using both definitions (conventional v.s. proposed) for all observation windows.
To this end, we use individual data to estimate the channel transition statistics for
each subject and observation window, separately. We have leveraged BA(.) algorithm
to compute the capacity–achieving input distributions and the corresponding capacity
value for signal lengths of 0.18, 0.2, 0.25, 0.3, . . ., 1 seconds, whereby the conditional


-----

16

0.12 6

0.1 5

0.08 4

0.06 3

0.04 2

0.02 1

0 0
0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1

Figure 5: Capacity achieving distributions for different signal lengths (sec) as well as
their entropies for SSCOR method using Benchmark dataset. Each bar plot consists
of 40 bars corresponding to the the probabilities assigned to each input symbol in the
speller application.

entropy of P[˜] is observed to comply with the Fano’s inequality.

3.4. Numerical Results

3.4.1. ITR performance averaged over subjects: In Figs. 4 and 5, using Benchmark
dataset, we demonstrate capacity–achieving distributions (with channel transition
statistics estimated using the data of all subjects) as bar plots for each signal length.
Also included in the same figures are the corresponding input entropy H(X), output
entropy H(Y ) and the conditional entropy H(Y X) that characterizes the channel
|
transition statistics for both TI methods, respectively. It is apparent that, as the
observation window length expands, there is an increase in both input entropy H(X) and
output entropy H(Y ). However, the channel transition probabilities begin to display
more intricate patterns, such as decreased symmetry and a more evenly distributed set
of probabilities (the far right bar plot), resulting in lower conditional entropy. As a
result, the mutual information of the induced channel (i.e., H(Y ) H(Y X)) increases
− |
with growing signal length in both techniques. As can be seen, particularly at low signal
lengths, SSCOR fails to enhance the channel capacity due to poorer reduction in the
conditional entropy H(Y X). However, as the observation window length increases, the
|
reduction in H(Y X) for both TIs become on par, almost equating the capacity gain
|
at around an observation window of one seconds. We observed similar trends using the
Beta dataset.
We have also provided the ITR results using the proposed scheme as well as the
confusion matrices in Fig. 6 using both datasets. Since the ITR is maximized at the


-----

17

220

150

200

140

180 130

120

160

110

140

100

120

90

100 80
0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1

Figure 6: Average ITR as a function of signal Length (sec) for different TIs for
Benchmark dataset (left) and Beta dataset (right). The plots clearly show the difference
between the conventional definition as well as the proposed definitions. Since input
distribution depends on the window length T, we have also expressed which time window
the ID is optimal for.

signal length of 0.5 secs for TRCA and 0.65 secs for SSCOR for Benchmark dataset
≈ ≈
(and 0.45 secs for TRCA and 0.55 secs for SSCOR for Beta dataset), we use the
≈ ≈
capacity-achieving or optimal input distribution (ID) of the signal lengths 0.5 (0.45)
and 0.65 (0.55) secs, respectively, for all window lengths to obtain the ITR for the TI
algorithms (Asym.+Optimal ID). For comparison purposes, we have also included the
conventional ITR definition in Fig. 6, which neither takes the input distribution nor
the asymmetry the channel introduces into account and consequently underestimates
the maximum information transfer rate that can be achieved over the induced channel.
To investigate it statistically, we have carried out paired t-test and f -test (two-tailed)
to determine whether the proposed ITR definition is statistically different from the
conventional. Recall that the f -test and t-test are statistical tests that are used to
determine whether there is a significant difference between the means and variances
(respectively) of two groups or samples. Using Benchmark dataset, both methods
showed dramatic mean differences (p 3.97 10[−][8] for SSCOR and p 3.7 10[−][7] for
≈ × ≈ ×
TRCA). However, there were no significant variational differences between the different
ITR definitions (F (17, 17) = 1.25, p > 0.05 for SSCOR and F (17, 17) = 1.47, p > 0.05
for TRCA). This clearly demonstrates that although the trend is almost the same
for both TI algorithms, the actual ITR experience is meaningfully different than the
reported average ITR results in the literature.


-----

18

0.08

0.07

0.06

0.05

0.04

0.03

0.02
0 0.1 0.2 0.3 0.4 0.5 0.6

Figure 7: On the left, we show asymmetry score ∆asm as a function of the ratio of change
in the ITR with the new definition for all T . On the right, we have also depicted the
asymmetry score ∆asm as a function of the conditional entropy of the induced channel.
We have varied the transparency of the markings from dark to light as we change the
observation time window from 0.18 seconds to 1 seconds.

3.4.2. Channel asymmetry and ITR performance: To be able to demonstrate the effect
of asymmetry of the channel on the ITR, we have used the optimal ID while keeping the
accuracy intact and divide the error probabilities equally over all other non-target classes
for each class (character) i.e., pi,j = M1−−p1 [for all][ i, j][ satisfying][ i][ ̸][=][ j][. We have dubbed]
this scheme “Balanced transition probability matrix” and used it with the optimal ID
for all signal lengths (Balanced +Optimal ID). Upon analyzing the results, it becomes
evident that the effect of the asymmetry in probability transition characteristics on
the final ITR outcomes is much more pronounced in comparison to the impact of the
non-uniformity of the input distribution.
On the other hand, to quantify the degree of asymmetry, we have used the
largest singular value of the skewed Laplacian of the channel transition matrix, namely
∆asm = (Γ − Γ[T] )/2 [48], where Γ = Φ[1][/][2](I − P)Φ[−][1][/][2], I is the identity matrix,


√
φ1 0 . . . 0
√
0 φ2 . . . 0
... ... ... ...
√
0 0 . . . φM




,



Φ[1][/][2] =







and [φ]1≤i≤M are the stationary probabilities§ of a Markovian process whose transitions
are governed by the channel transition statistics. In Fig. 7 (left), we depicted the degree

In our work, we use the estimates of these probabilities, computed based on a given dataset.
§


-----

19

Figure 8: Proposed ITR v.s. conventional ITR for subject-specific input customization
using two TIs and the Beta Dataset. Input customization can be shown to be effective
even with longer observation windows.

of asymmetry ∆asm as a function of the ratio of change in the ITR (∆ITR) using the
proposed definition. More specifically,

∆ITR ≜ [(Asym.+Optimal ID)][ −] [(Conventional)] . (28)

(Conventional)

As can be clearly seen from Fig. 7 (left), asymmetry increases the ITR gain,
and it turns out to satisfy a logarithmic relationship. The parameters of this estimate
is explicitly given in the same figure using regression. This suggests that although
the asymmetry in the channel transition statistics helps with increasing the rate of
communication, it also quickly saturates due to increased conditional entropy of the
channel and reduced accuracy. Note that the conditional entropy is bounded above
by the Fano’s inequality as expressed in (18) which forms an upper bound on ∆asm.
One of the interesting conclusions is that particularly at short window lengths, stimuli
design that generates more asymmetric channel transition characteristics is likely to
improve ∆ITR, higher improvement ratio with respect to the conventional definition.
However, the relationship between ∆asm and H(Y |X) clearly suggests that as we have
larger observation windows, to be able to maximize the mutual information, system
prefers to have less asymmetry in the channel transition characteristics (to minimize
the conditional entropy) and maximize the input entropy via uniform distribution.


-----

20

Figure 9: Proposed ITR v.s. conventional ITR for subject-specific input customization
using two TIs and the Benchmark Dataset. Input customization can be shown to be
effective even with longer observation windows.

On the other hand in Fig. 5 (right), we have illustrated ∆asm as a function
of conditional entropy H(Y X). As anticipated, there is a monotonic relationship
|
(presented with a linear regression) in between and both the degree of asymmetry
and conditional entropy increase as the observation window length grows. One of the
interesting observations is that the dataset has more significant effect on the slope of
the relationship compared to target identification algorithms. Different slopes can also
be interpreted as an indicator of the difficulty of the datasets (TIs perform worse with
Beta dataset compared to Benchmark) and reduced SNR while recording these EEG
datasets.

3.4.3. ITR performance customized to each subject: We have also investigated via
violin plots in Figs. 8 and 9 (considering all 70 subjects in the Beta,and all 35
subjects in the Benchmark individually as data points, respectively) whether the
proposed ITR computed per subject (estimating the channel transition statistics based
on individual subject data and finding the optimal input distribution for each subject)
differs significantly compared to conventional definition for the two different TIs using
both datasets. There are two important observations about the performance of TIs
as a function of observation window (0.2, 0.3, . . ., 1 seconds). First, customizing the
input distribution can tremendously help with the experienced ITR as compared to


-----

21

Proposed ITR Differences Conventional ITR Differences
Window

t-test t-test

Length p value F (69, 69) p value F (69, 69)

CV CV

T (sec)

0.2 2.87e-11 8.1 0.83 1.49e-17 24.41 0.865
0.3 1.45e-9 6.61 0.59 2.84e-11 17 0.614
0.4 3.68e-6 3.08 0.577 3.48e-07 8.61 0.58
0.5 1.49e-3 1.24 0.602 5.6e-06 6.14 0.57
0.6 6.21e-5 1.31 0.552 1.98e-05 4.23 0.57
0.7 9.2e-05 1.13 0.566 1.92e-05 3.59 0.568
0.8 3.4e-3 0.52 0.579 7.38e-4 2.13 0.559
0.9 2.51e-3 0.55 0.588 1.43e-3 1.903 0.573
1.0 8.04e-3 0.32 0.572 7.36e-4 1.905 0.567

Table 1: Critical and p values for the right-tailed paired t-tests (95% confidence) for
70 subjects of Beta data set using both definitions of ITR. The table also shows the
f -statistic for p 0.041 for the same confidence interval. CV: Critical Value.
≥

conventional definition. Particularly, at shorter observation windows, the difference
is quite significant for both TIs tested over both datasets. Second observation is
that even though the two TIs seem to differ in performance, more so with shorter
observation windows, using the conventional definition, their ITR performance do not
show significant difference using the proposed ITR definition with input distribution
optimized across all observation windows. To show that statistically, using Beta dataset,
we have conducted right-tailed paired t-test with the alternative hypothesis being the
mean of TRCA performance is greater than that of the SSCOR performance. Using
95% confidence interval, we have presented in Table 1 the corresponding critical as well
as the associated p values. As can be seen, lower critical value and higher p values
for the proposed ITR difference indicates the minor variation in the performance of
TRCA and SSCOR algorithms. In addition, we have also conducted f -test to measure
the variational difference of both algorithm’s performances. As can be seen in Table 1,
our f -statistic (F (69, 69)) demonstrates (for all T and p 0.041) that the variational
≥
differences are not significant. To corroborate our visual aids and put our results into
perspective, we have additionally charted the average ITR for both conventional and
proposed definitions, as a function of window lengths (T 0.4, 0.5, 0.6) in Fig. 10,
∈
accompanied by their corresponding p-value thresholds of : 10[−][2], : 10[−][4], : 10[−][6].
∗ ∗∗ ∗∗∗
The outcomes of the experiment demonstrates that the proposed definition mitigates the
performance variability across diverse subjects. Moreover, it attenuates the significance
of the mean performance disparity between the two TIs, namely SSCOR and TRCA.


Window
Length
T (sec)


Proposed ITR Differences


0.3


0.5


0.7


0.9


-----

22

400 400 400

300 300 300

200 200 200

100 100 100

Conventional Conventional Conventional
Proposed Proposed Proposed

0 0 0

Figure 10: Performance (ITR) comparisons using different definitions (Conventional v.s.
Proposed) using three window lengths (that provides the best average ITR for the Beta
dataset) along with the results of the statistical tests.

4. Discussion

In this work, we have investigated the conventional definition of ITR, highlighted
the deficiencies and proposed to use an algorithmic approach for more accurate
computation of the information transfer. One conclusion we derive from this study
is that the effect of the input distribution changes on the experienced ITR is quite
minor when the performance is averaged over all subjects. This implies that in an
online speller task, for instance, we typically would not have the option to change
the ID and yet the TI algorithm would be operating close to the capacity–maximum
ITR. However, the asymmetry (proportion of false positives and negatives) in the
channel significantly changes the ITR in a typical BCI-based communication setting.
Therefore, target identification algorithms, while in the design phase, should not solely
optimize the accuracy performance. Note that “accuracy” and ITR have long been
used interchangeably in the SSVEP-based BCI literature and it is the only objective
performance indicator of a TI that appears in the conventional ITR definition (see
Equation (1)).
On the other hand, our results lead us to consider the possibility of alternative
(better) channel transition (confusion) matrices. In other words, given an average target
accuracy level (1 − ǫM ) and a fixed ID (Px(x)), one can optimize the channel transition
probability matrix such that the channel mutual information is maximized i.e. to achieve
the maximum ITR subject to conditional entropy bound of the channel statistics, given
by the Fano’s inequality. With this study, we can show the potential of this approach


-----

23

for the binary classification scenario as follows.
Let us consider a special case, a binary character transmission i.e. M = 2. First,
from (9), we observe the symmetry C2(p1,2, p2,1) = C2(p2,1, p1,2) which is minimized for
a given average accuracy target A < 1 (or a classification error ǫM > 0) when p1,2 =
p2,1 = 1 − A. On the other hand, capacity is maximized when (p1,2, p2,1) ≅ (2(1 − A), 0)
or (p2,1, p1,2) ≅ (0, 2(1 − A)) with equality if the input distribution is uniform i.e.,
PX(x) = M1 [. In other words, the ITR is maximized when either Precision or Recall is]
unity which can be obtained by playing with the parameters of the TI algorithm i.e.,
replacing the separating hyperplanes of the classifiers. However this argument does not
take into account the natural bounds on the classification error and asymmetry of the
channel statistics.
For a given classification target error rate ǫM, an iterative algorithm is provided in
Algorithm 1 to optimize the input and channel statistics at the same time. Both
optimizations are subject to postulates of probability as well as Fano’s inequality.
Capacity results for accuracy targets 0.99, 9.95, 0.9, 0.85, 0.8 and 0.75 are provided in
Table 1. Using these results, we can practically determine the upper bounds on the
maximum achievable ITR. For instance, if a genuine TI achieves an accuracy of 0.99
using only an observation window of T = 0.2 seconds, our capacity results imply that
the upper bound on ITR can be calculated as 0.9277 [60]
× 0.2 [= 278][.][3bpm. Such a high]

ITR is quite untypical in binary symbol communications in the BCI context, and yet it
motivates us for a joint design to fully exploit the available capacity. We finally remark
that the mapping between the achievable accuracy and the observation window T is
also a function of the structure of the data manifold as well as the dimension reduction
techniques used before the application of TIs.
On the other hand, for M > 2, such optimizations can be carried out based on
the separability of the input data using a multi-class classification algorithm. However,

Algorithm 1 Joint calculation of P[∗] = {p[∗]i,j[}][ and][ P][ ∗]X[(][x][) in an iterative manner.]


Require: [�]j [p][i,j][ = 1][,][ 0][ ≤] [p][i,j][ ≤] [1][,][ 0][ ≤] [P][X][(][x][i][)][ ≤] [1.]

Ensure: ǫM = 1 − [�]xi [P][X] [(][x][i][)][p][i,i][.]

1
1: PX(xi) ⇐ M [for all][ i][ ∈{][1][,][ 2][, . . ., M][}][.]

2: pi,j ⇐ RAND(0,1)

3: pi,j ⇐ pi,j/ [�]j [p][i,j][ {][⊲] [Normalization][}]

4: while [�]xi [P][X][(][x][i][)][p][i,i][ ≤] [1][ −] [ǫ][M][ and][ H][(][Y][ |][X][)][ ≤] [h][(][ǫ][M] [) +][ ǫ][M][ log]2[(][M][ −] [1)][ do]

5: Pˆ = arg maxP I(X, Y ) {⊲ Fix PX(x) and optimize P}

6: [CDMC, PX(x)] = BA(P[ˆ] ) {⊲ Fix P, optimize PX (x)}

7: end while

8: P[∗] ⇐ P[ˆ], PX[∗] [(][x][)][ ⇐] [P][X][(][x][)]


-----

24

Avg. Accuracy Target 0.99 0.95 0.9 0.85 0.8 0.75

Capacity 0.9277 0.746 0.5787 0.4412 0.3219 0.2155

Conditional Entropy 0.0703 0.2271 0.3367 0.3908 0.4001 0.3655

Fano’s Bound 0.0932 0.3627 0.6343 0.8644 1.0613 1.2276

Table 2: Optimization of the channel statistics (M = 2) to maximize the mutual
information (capacity) given the target average accuracy (classification error) rate.

as the number of classes increase, the possibility of hitting a local minimum grows,
making the outcome unstable and vary at each run of the proposed algorithm (line 3,
Algorithm 1). However, multi-class classification can be implemented as an ensemble
of multiple binary (weak and unstable) classifications (such as one-vs-one, one-vs-all

[49] or expressed in a more general framework called error correction output codes [50]),
thus making the arguments of the previous paragraph directly applicable.
Note that channel parameter optimizations are indeed not the characteristic of
telecommunication systems (regarding Shannon’s channel coding theorem [15]). The
channel model is usually a given quantity defined by the transmission medium and
capacity-achieving IDs are found via solving an optimization problem so as to determine
the maximum information transfer rate over the communication medium. Therefore,
the practice of this paper will hopefully help us understand what is achievable using TI
algorithms or classification techniques subject to a target accuracy threshold. Such an
upper bound on the performance will also help compare the performances of different
TI algorithms under equal settings and highlight how much improvement they can bring
into the ITR enhancements for future BCI systems.
As a result, we would like to highlight that most offline BCI signal detection
techniques employ subject-specific optimizations, such as training the TI based on
individual template signals for each observation window. Furthermore, we have observed
that the experimental design and the resulting channel formation are closely intertwined,
resulting in highly collaborative systems with interconnected components. In this
regard, we have recognized that extending the optimizations to include subject-level
stimuli design and constructing the requisite set of input patterns for a better channel
design could significantly enhance the experienced ITR, thereby narrowing down the
considerable performance gaps that exist in published TI schemes in the literature.
Therefore, the outcomes of our study underscore the criticality of joint design in SSVEPbased BCIs, emphasizing the need for stronger individual calibrations for each user of
the system and tighter symbiosis between the neural circuits of the brain and the digital
circuits of the computer.


-----

25

5. Conclusion

In this study, we have considered a more realistic ITR definition without making
superfluous assumptions about the channel transition and input statistics and
numerically supported it using two well known datasets along with two prominent TI
algorithms in an SSVEP-based BCI context. This numerical definition characterizes
the communication rate between the computer and the brain as if sending symbols
over a discrete, asymmetric, non-stationary memoryless channel. This definition also
provided a set of intriguing ways of comparing all previously developed TIs and highlight
where they suffer information-theoretically in achieving better or worse ITRs. Our
findings also imply that the proposed ITR definition is particularly important for
subject-level customizations, enabling a more realistic measurement tool. Moreover,
the proposed definition is shown to help with the design of the channel transitions
(binary classification use case) and potentially lead to future work for finding upper
bounds on TI performances with large alphabet sizes in SSVEP-based BCI settings.

Acknowledgments

This research was supported in part by Scientific and Technological Research Council
of Turkey (TUBITAK) under grant number 1059B192100830.

References

[1] J. R. Wolpaw, N. Birbaumer, D. J. McFarland, G. Pfurtscheller, and T. M. Vaughan, “Braincomputer interfaces for communication and control,” Electroenceph. Clin. Neurophysiol., vol.
113, no. 6, pp. 767–791, June 2002.

[2] Geuze, J., Farquhar, J. and Desain, P. “Towards a Communication Brain Computer Interface
Based on Semantic Relations,” PLoS ONE 9, e87511. 2014.

[3] J. N. Mak and J. R. Wolpaw, “Clinical Applications of Brain-Computer Interfaces: Current State
and Future Prospects,” in IEEE Reviews in Biomedical Engineering, vol. 2, pp. 187-199, 2009.

[4] A. Nijholt, “BCI for games: A state of the art survey,” in Proc. Int. Conf. Entertainment Comput.,
2008, pp. 225–228.

[5] E. Ertekin, B. B. G¨unden, Y. Yilmaz, A. Sayar, T. C¸akar and S. S¸. Arslan, “EMG-based BCI for
PiCar Mobilization,” 2022 7th International Conference on Computer Science and Engineering
(UBMK), 2022, pp. 496-500.

[6] F. Putze, “2019. Methods and tools for using BCI with augmented and virtual reality,” In Brain
art (pp. 433-446). Springer, Cham.

[7] S. Branson, G. Van Horn, C. Wah, P. Perona, and S. Belongie, “The ignorant led by the blind:
A hybrid human–machine vision system for fine-grained categorization,” Int. J. Comput. Vis.,
vol. 108, nos. 1–2, pp. 3–29, 2014.

[8] T. Verhoeven, P. Buteneers, J. Wiersema, J. Dambre, and P.-J. Kindermans, “Towards a symbiotic
brain–computer interface: Exploring the application–decoder interaction,” J. Neural Eng., vol.
12, no. 6, pp. 066027, Nov. 2015.


-----

26

[9] S. Z. Diva, R.A. Prorna, I.I. Rahman, A.B. Islam, M.N. Islam. “Applying brain-computer interface
technology for evaluation of user experience in playing games,” In: 2019 International Conference
on Electrical, Computer and Communication Engineering (ECCE). IEEE; 2019. p. 1–6.

[10] M. Lungarella, T. Pegors, D. Bulwinkle, and O. Sporns, “Methods for quantifying the informational
structure of sensory and motor data,” Neuroinformatics, vol. 3, pp. 243–262, 2005.

[11] Xu, M., He, F., Jung, T.P., Gu, X. and Ming, D., “Current challenges for the practical application
of electroencephalography-based brain–computer interfaces,” Engineering, 7(12), pp.1710-1712.

[12] C. Thorton, “A new way of linking information theory with cognitive science,” in Proc. Annu.
Meeting Cogn. Sci. Soc., vol. 35, 2013, pp. 3545–3550.

[13] D. J. McFarland and D.J. Krusienski, “BCI signal processing: feature translation,” BCI Principles
and Practice (Oxford, New York: Oxford University Press) Chp. 8., 2012.

[14] S. Sadeghi and A. Maleki. “Accurate estimation of information transfer rate based on symbol
occurrence probability in brain-computer interfaces,” Biomedical Signal Processing and Control
54, 101607, 2019.

[15] C. E. Shannon, “A mathematical theory of communication,” Bell Syst. Tech. J., vol. 27, no. 3, pp.
379–423, 1948.

[16] A. Cotrina et al., “Towards an architecture of a hybrid BCI based on SSVEP-BCI and passiveBCI,” in Proc. IEEE 36th Annu. Int. Conf. Eng. Med. Biol. Soc. (EMBC), Aug. 2014, pp.
1342–1345.

[17] M. Devos, M. Kroesen, R. Emkes, and S. Debener, “P300 speller BCI with a mobile EEG system:
Comparison to a traditional amplifier,” J. Neural Eng., vol. 11, no. 3, pp. 1–8, 2014.

[18] M. Nakanishi et al., “Enhancing detection of ssveps for a highspeed brain speller using task-related
component analysis,” IEEE Trans. Biomed. Eng., vol. 65, no. 1, pp. 104–112, 2018.

[19] X. Chen et al., “Hybrid frequency and phase coding for a high-speed SSVEP-based BCI speller,”
In Proc. 36th Ann. Int. Conf. IEEE Eng. Med. Biol. Soc., 2014, pp.3993-3996.

[20] D. C. Van Essen and C. H Anderson. Information processing strategies and pathways in the primate
visual system. In Zornetzer S. F., Davis J. L., Lau C., and McKenna T., editors, An introduction
to neural and electronic networks, page 45–76, San Diego, CA, 1995. Academic Press.

[21] X. Han, G. S. Link and X. Gao, “A novel system of SSVEP-based human robot coordination,” J.
Neural Eng. 16 1–15, 2019.

[22] P. Yuan, X. Gao, B. Allison, G. Bin and S. Gao, “A study of the existing problems of estimating
the information transfer rate in online brain–computer interfaces,” J. Neural Eng. 10 1–11, 2013.

[23] T. B. da Silva Costa, L. F. S. Uribe, S. N. de Carvalho, D. C. Soriano, G. Castellano, R. Suyama,
R. Attux and C. Panazio, “Channel capacity in brain-computer interfaces” J. Neural Eng. 17
016060, 2020.

[24] S. Muroga, “On the capacity of a discrete channel I,” J. Phys. Sot. Jup., vol. 8, 1953, pp. 484494.

[25] S. Arimoto, “An algorithm for computing the capacity of arbitrary discrete memoryless channels,”
IEEE Trans. Information Theory, vol. 18, pp. 14–20, 1972.

[26] T. M. Cover, Elements of information theory. John Wiley & Sons, 1999.

[27] N. J. Williams, I. Daly, S. J. Nasuto, “Markov Model-Based Method to Analyse Time-Varying
Networks in EEG Task-Related Data,” Front. Comput. Neurosci. 2018 Sep 21; 12:76.

[28] J. N. da Cruz, C. M. Wong, and F. Wan, ”An SSVEPBased BCI with adaptive time-window
length,” in International Symposium on Neural Networks, 2013, pp. 305-314: Springer.

[29] R. Ash, Information Theory. New York: Interscience, 1965.

[30] Y. Zhang, Q. B. Zhao, J. Jin, X. Y. Wang, and A. Cichocki, “A novel BCI based on ERP
components sensitive to configural processing of human faces,” J. Neural Eng., vol. 9, no. 2,
p. 026018, 2012.

[31] R. Blahut, “Computation of channel capacity and rate-distortion functions,” IEEE Trans.


-----

27

Information Theory, vol. 18, pp. 460–473, 1972.

[32] P. O. Vontobel, A. Kav´ci´c, D. Arnold, and H.-A. Loeliger, “Capacity of Finite-State Machine
Channels,” submitted to IEEE Trans. Inform. Theory, Nov. 2004.

[33] Z. Naja, F. Alberge, and P. Duhamel, “Geometrical interpretation and improvements of the BlahutArimoto’s algorithm,” in Proc. IEEE Int. Conf. Acoust., Speech Signal Process., Apr. 2009, pp.
2505–2508.

[34] J. T. Chiu and A. M. Rush, “Scaling hidden Markov language models.” arXiv preprint
[arXiv:2011.04640 (2020).](http://arxiv.org/abs/2011.04640)

[35] A. Sinha, “Convex optimization methods for computing channel capacity,” May 2014. [Online].
Available: https://home.iitm.ac.in/abhishek.sinha/ Capacity Convex Opt.pdf.

[36] D. Erdogmus and J. Principe, “Lower and upper bounds for misclassification probability based on
Renyi’s information,” J. VLSI Signal Process. Syst., vol. 37, no. 2/3, pp. 305–317, 2004.

[37] S. -W. Ho and S. Verd´u, “On the Interplay Between Conditional Entropy and Error Probability,”
in IEEE Transactions on Information Theory, vol. 56, no. 12, pp. 5930-5942, Dec. 2010.

[38] Z. Lin, C. Zhang, W. Wu, and X. Gao, “Frequency recognition based on canonical correlation
analysis for ssvep-based bcis,” IEEE transactions on biomedical engineering, vol. 53, no. 12, pp.
2610–2614, 2006.

[39] H. Takana et al., “Task-related component analysis for functional neuroimaging and application
to near-infrared spectroscopy data,” NeuroImage, vol. 64, pp. 308–327, 2013.

[40] H. Takana et al., “Task-related oxygenation and cerebral blood volume changes estimated form
NIRS signals in motor and cognitive tasks,” NeuroImage, vol. 94, pp. 107–119, 2014.

[41] M. Chiang and S. Boyd, “Geometric programming duals of channel capacity and rate distortion,”
in IEEE Transactions on Information Theory, vol. 50, no. 2, pp. 245-258, Feb. 2004.

[42] Y. Wang, X. Chen, X. Gao and S. Gao, “A Benchmark Dataset for SSVEP-Based Brain–Computer
Interfaces,” in IEEE Transactions on Neural Systems and Rehabilitation Engineering, vol. 25,
no. 10, pp. 1746-1752, Oct. 2017.

[43] B. Liu, X. Huang, Y. Wang, X. Chen, and X. Gao, “BETA: A large Benchmark database toward
SSVEP-BCI application,” Frontiers Neurosci., vol. 14, p. 627, Jun. 2020.

[44] C. M. Wong, B. Wang, Z. Wang, K. F. Lao, A. Rosa and F. Wan, “Spatial Filtering in SSVEPBased BCIs: Unified Framework and New Improvements,” in IEEE Transactions on Biomedical
Engineering, vol. 67, no. 11, pp. 3057-3072, Nov. 2020.

[45] X. Chen, Y. Wang, S. Gao, T.-P. Jung, and X. Gao, “Filter bank canonical correlation
analysis for implementing a high-speed ssvep-based brain–computer interface,” Journal of Neural
Engineering, vol. 12, p. 046008, Aug 2015.

[46] G. R. Kumar and M. R. Reddy, “Designing a Sum of Squared Correlations Framework for
Enhancing SSVEP Based BCIs”, IEEE Trans. Neural Syst. Rehabil. Eng., vol. 27, pp. 2044-2050,
2019.

[47] J. Onton et al., “Imaging human EEG dynamics using independent component analysis,” Neurosci.
Biobehav. Rev., vol.30, no.6, 808-822, 2006.

[48] Y. Li and Z.-L. Zhang, “Digraph Laplacian and the Degree of Asymmetry,” Internet Mathematics,
vol. 8, no. 4, 2012.

[49] M. Galar, A. Fernandez, E. Barrenechea, H. Bustince, and F. Herrera, “An overview of ensemble
methods for binary classifiers in multi-class problems: Experimental study on one-vs-one and
one-vs-all schemes,” Pattern Recog., vol. 44, no. 8, pp. 1761–1776, 2011.

[50] O. B. G¨uney and S¸. S¸. Arslan, “Error Correction Output Codes: Overview, Challenges and
Future Trends,” 2019 27th Signal Processing and Communications Applications Conference
(SIU), Sivas, Turkey, 2019, pp. 1-4.


-----

### This figure "BCIpaper.jpg" is available in "jpg"� format from:

 http://arxiv.org/ps/2301.00488v3


-----

### This figure "BCIpaper.png" is available in "png"� format from:

 http://arxiv.org/ps/2301.00488v3


-----

