{
    "title": "AIhub",
    "fname": "AIhub",
    "url": "https://aihub.org/feed/",
    "items": [
        {
            "title": "Shlomo Zilberstein wins the 2025 ACM/SIGAI Autonomous Agents Research Award",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "https://aihub.org/feed/",
                "value": "Shlomo Zilberstein wins the 2025 ACM/SIGAI Autonomous Agents Research Award"
            },
            "links": [
                {
                    "rel": "alternate",
                    "type": "text/html",
                    "href": "https://aihub.org/2025/03/19/shlomo-zilberstein-wins-the-2025-acm-sigai-autonomous-agents-research-award/"
                }
            ],
            "link": "https://aihub.org/2025/03/19/shlomo-zilberstein-wins-the-2025-acm-sigai-autonomous-agents-research-award/",
            "authors": [
                {
                    "name": "AIhub"
                }
            ],
            "author": "AIhub",
            "author_detail": {
                "name": "AIhub"
            },
            "published": "Wed, 19 Mar 2025 14:36:20 +0000",
            "published_parsed": [
                2025,
                3,
                19,
                14,
                36,
                20,
                2,
                78,
                0
            ],
            "tags": [
                {
                    "term": "news",
                    "scheme": null,
                    "label": null
                },
                {
                    "term": "ACM SIGAI",
                    "scheme": null,
                    "label": null
                },
                {
                    "term": "quick read",
                    "scheme": null,
                    "label": null
                }
            ],
            "id": "https://aihub.org/?p=17144",
            "guidislink": false,
            "summary": "Congratulations to Shlomo Zilberstein on winning the 2025 ACM/SIGAI Autonomous Agents Research Award. This prestigious award is made for excellence in research in the area of autonomous agents. It is intended to recognize researchers in autonomous agents whose current work is an important influence on the field. Professor Shlomo Zilberstein was recognised for his work [&#8230;]",
            "summary_detail": {
                "type": "text/html",
                "language": null,
                "base": "https://aihub.org/feed/",
                "value": "Congratulations to Shlomo Zilberstein on winning the 2025 ACM/SIGAI Autonomous Agents Research Award. This prestigious award is made for excellence in research in the area of autonomous agents. It is intended to recognize researchers in autonomous agents whose current work is an important influence on the field. Professor Shlomo Zilberstein was recognised for his work [&#8230;]"
            },
            "content": [
                {
                    "type": "text/html",
                    "language": null,
                    "base": "https://aihub.org/feed/",
                    "value": "<img alt=\"ACM SIGAI logo\" class=\"aligncenter size-full wp-image-9893\" height=\"509\" src=\"https://aihub.org/wp-content/uploads/2022/07/acmsigai-logo.png\" width=\"906\" />\n<p>Congratulations to Shlomo Zilberstein on winning the <a href=\"https://sigai.acm.org/main/2025/03/09/shlomo-zilberstein-2025-autonomous-agents-research-award/\">2025 ACM/SIGAI Autonomous Agents Research Award</a>. This prestigious award is made for excellence in research in the area of autonomous agents. It is intended to recognize researchers in autonomous agents whose current work is an important influence on the field.</p>\n<p><a href=\"https://www.cics.umass.edu/about/directory/shlomo-zilberstein\">Professor Shlomo Zilberstein</a> was recognised for his work establishing the field of decentralized Markov Decision Processes (DEC-MDPs), laying the groundwork for decision-theoretic planning in multi-agent systems and multi-agent reinforcement learning (MARL). The selection committee noted that these contributions have become a cornerstone of multi-agent decision-making, influencing researchers and practitioners alike.<br />\n<img alt=\"\" class=\"alignleft size-medium wp-image-17145\" height=\"300\" src=\"https://aihub.org/wp-content/uploads/2025/03/zilberstein-980x980-1-300x300.jpg\" width=\"300\" /><br />\nShlomo Zilberstein is Professor of Computer Science and former Associate Dean of Research at the University of Massachusetts Amherst. He is a Fellow of AAAI and the ACM, and has received numerous awards, including the UMass Chancellor\u2019s Medal, the IFAAMAS Influential Paper Award, and the AAAI Distinguished Service Award.</p>"
                }
            ]
        },
        {
            "title": "#AAAI2025 workshops round-up 1: Artificial intelligence for music, and towards a knowledge-grounded scientific research lifecycle",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "https://aihub.org/feed/",
                "value": "#AAAI2025 workshops round-up 1: Artificial intelligence for music, and towards a knowledge-grounded scientific research lifecycle"
            },
            "links": [
                {
                    "rel": "alternate",
                    "type": "text/html",
                    "href": "https://aihub.org/2025/03/18/aaai2025-workshops-round-up-1-artificial-intelligence-for-music-and-towards-a-knowledge-grounded-scientific-research-lifecycle/"
                }
            ],
            "link": "https://aihub.org/2025/03/18/aaai2025-workshops-round-up-1-artificial-intelligence-for-music-and-towards-a-knowledge-grounded-scientific-research-lifecycle/",
            "authors": [
                {
                    "name": "AIhub"
                }
            ],
            "author": "AIhub",
            "author_detail": {
                "name": "AIhub"
            },
            "published": "Tue, 18 Mar 2025 09:18:25 +0000",
            "published_parsed": [
                2025,
                3,
                18,
                9,
                18,
                25,
                1,
                77,
                0
            ],
            "tags": [
                {
                    "term": "articles",
                    "scheme": null,
                    "label": null
                },
                {
                    "term": "AAAI",
                    "scheme": null,
                    "label": null
                },
                {
                    "term": "AAAI2025",
                    "scheme": null,
                    "label": null
                }
            ],
            "id": "https://aihub.org/?p=17120",
            "guidislink": false,
            "summary": "Top: Group shot from the workshop &#8220;Artificial Intelligence for Music&#8221;. Bottom: Two best paper award winners at the workshop: &#8220;AI4Research: Towards a Knowledge-grounded Scientific Research Lifecycle&#8221;. In a series of articles, we&#8217;ll be publishing summaries with some of the key takeaways from a few of workshops held at the 39th Annual AAAI Conference on Artificial [&#8230;]",
            "summary_detail": {
                "type": "text/html",
                "language": null,
                "base": "https://aihub.org/feed/",
                "value": "Top: Group shot from the workshop &#8220;Artificial Intelligence for Music&#8221;. Bottom: Two best paper award winners at the workshop: &#8220;AI4Research: Towards a Knowledge-grounded Scientific Research Lifecycle&#8221;. In a series of articles, we&#8217;ll be publishing summaries with some of the key takeaways from a few of workshops held at the 39th Annual AAAI Conference on Artificial [&#8230;]"
            },
            "content": [
                {
                    "type": "text/html",
                    "language": null,
                    "base": "https://aihub.org/feed/",
                    "value": "<p><img alt=\"\" class=\"aligncenter size-full wp-image-17128\" height=\"1410\" src=\"https://aihub.org/wp-content/uploads/2025/03/research-and-music.jpg\" width=\"1764\" /><em>Top: Group shot from the workshop &#8220;Artificial Intelligence for Music&#8221;. Bottom: Two best paper award winners at the workshop: &#8220;AI4Research: Towards a Knowledge-grounded Scientific Research Lifecycle&#8221;.</em></p>\n<p>In a series of articles, we&#8217;ll be publishing summaries with some of the key takeaways from a few of workshops held at the <a href=\"https://aaai.org/conference/aaai/aaai-25/\">39th Annual AAAI Conference on Artificial Intelligence (AAAI 2025)</a>. In this first round-up, we hear from the organisers of the workshops on:</p>\n<ul>\n<li>AI4Research: Towards a Knowledge-grounded Scientific Research Lifecycle</li>\n<li>Artificial Intelligence for Music</li>\n</ul>\n<hr />\n<p><a href=\"https://sites.google.com/view/ai4research2024\">AI4Research: Towards a Knowledge-grounded Scientific Research Lifecycle</a><br />\n<strong>By Qingyun Wang</strong></p>\n<p>Organisers: <em>Qingyun Wang, Wenpeng Yin, Lifu Huang, May Fung, Xinya Du, Carl Edwards, Tom Hope</em></p>\n<p>This workshop focused on grounding AI methods in existing scientific publications and experimental datasets to discover potential \u201cSleeping Beauties\u201d. </p>\n<p>The three main takeaways from the event were:</p>\n<ul>\n<li>The workshop featured 20 accepted papers across diverse application areas, including five oral presentations and 15 posters. Research topics ranged from agent debate evaluation and taxonomy expansion to hypothesis generation, AI4Research benchmarks, caption generation, drug discovery, and financial auditing. Additionally, the workshop hosted a dedicated mentoring session for early-career researchers.</li>\n<li>The workshop had six inspiring invited talks from academic and industry experts covering a wide range of research topics. Professor Wei Wang (UCLA) presented work on multimodal scientific foundation models for knowledge extraction and synthesis. Next, Professor Marinka Zitnik (Harvard &#038; Broad Institute) shared their recent progress in &#8220;AI Scientists&#8221; to apply diffusion models and large language models for biomedical discovery. Professor Doug Downey (AI2 &#038; Northwestern) presented state-of-the-art ScholarQA from AI2, a literature-based long-form question-answering assistant, and highlighted possible future directions. Professor Aviad Levis (University of Toronto) introduced physics-constrained neural fields for 3D imaging in astronomy. Professor Jinho Choi (Emory) gave a talk about AI-assisted scientific writing and explored potential solutions to the growing peer-review crisis in academic publishing. Finally, Dr Cong Lu (DeepMind) described their work about fully autonomous open-ended scientific discovery in the machine learning domain.</li>\n<li>Professor Doug Downey, Professor Aviad Levis, Professor Jinho Choi, and Dr Cong Lu gave an insightful panel discussion on emerging methods, challenges, and ethical considerations in AI4research, including a discussion about the potential social impact of replacing incremental research with automatic AI systems. The panelists also discussed the potential copyright issues for using LLM tools to help researchers discover new hypotheses, solutions to existing peer review crises, and the exponential growth of papers in the machine learning domain.</li>\n</ul>\n<img alt=\"\" class=\"aligncenter size-full wp-image-17129\" height=\"1991\" src=\"https://aihub.org/wp-content/uploads/2025/03/ai4research.png\" width=\"1771\" />\n<hr />\n<p><a href=\"https://ai4musicians.org/2025aaai.html\">Artificial Intelligence for Music</a><br />\n<strong>By Yung-Hsiang Lu</strong></p>\n<p>Organisers: <em>Yung-Hsiang Lu, Kristen Yeon-Ji Yun, George K. Thiruvathukal, Benjamin Shiue-Hal Chou</em></p>\n<p>This workshop explored the dynamic intersection of artificial intelligence and music. It covered topics including the impact of AI on music education and careers of musicians, AI-driven music composition, AI-assisted sound design, AI-generated audio and video, and legal and ethical considerations of AI in music.</p>\n<p>The three main takeaways from the event were:</p>\n<ul>\n<li>Artificial Intelligence technologies should be designed for users. Technologists should collaborate with musicians and understand users&#8217; needs.</li>\n<li>AI technologies can provide many benefits to musicians and music students, for example, composition, error detection, adaptive accompaniment, transcription, generating video from music, generating music from video.</li>\n<li>Major barriers to further improvements include (1) lack of training data, (2) lack of widely accepted metrics for evaluation, (3) difficulty to find experts in both technologies and music.</li>\n</ul>\n<img alt=\"\" class=\"aligncenter size-full wp-image-17125\" height=\"667\" src=\"https://aihub.org/wp-content/uploads/2025/03/aiandmusic.jpg\" width=\"1539\" />"
                }
            ]
        },
        {
            "title": "The Good Robot podcast: Re-imagining voice assistants with Stina Hasse J\u00f8rgensen and Frederik Juutilainen",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "https://aihub.org/feed/",
                "value": "The Good Robot podcast: Re-imagining voice assistants with Stina Hasse J\u00f8rgensen and Frederik Juutilainen"
            },
            "links": [
                {
                    "rel": "alternate",
                    "type": "text/html",
                    "href": "https://aihub.org/2025/03/17/the-good-robot-podcast-re-imagining-voice-assistants-with-stina-hasse-jorgensen-and-frederik-juutilainen/"
                },
                {
                    "length": "0",
                    "type": "audio/mpeg",
                    "href": "https://www.buzzsprout.com/1786427/episodes/16767549-re-imagining-voice-assistants-with-stina-hasse-jorgensen-and-frederik-juutilainen.mp3",
                    "rel": "enclosure"
                }
            ],
            "link": "https://aihub.org/2025/03/17/the-good-robot-podcast-re-imagining-voice-assistants-with-stina-hasse-jorgensen-and-frederik-juutilainen/",
            "authors": [
                {
                    "name": "The Good Robot Podcast"
                }
            ],
            "author": "The Good Robot Podcast",
            "author_detail": {
                "name": "The Good Robot Podcast"
            },
            "published": "Mon, 17 Mar 2025 11:41:51 +0000",
            "published_parsed": [
                2025,
                3,
                17,
                11,
                41,
                51,
                0,
                76,
                0
            ],
            "tags": [
                {
                    "term": "opinions",
                    "scheme": null,
                    "label": null
                }
            ],
            "id": "https://aihub.org/?p=17114",
            "guidislink": false,
            "summary": "Hosted by Eleanor Drage and Kerry McInerney, The Good Robot is a podcast which explores the many complex intersections between gender, feminism and technology. Re-imagining voice assistants with Stina Hasse J\u00f8rgensen and Frederik Juutilainen To develop voice assistants like Siri and Alexa, companies spend years investigating what sounds like a human voice and what doesn&#8217;t. [&#8230;]",
            "summary_detail": {
                "type": "text/html",
                "language": null,
                "base": "https://aihub.org/feed/",
                "value": "Hosted by Eleanor Drage and Kerry McInerney, The Good Robot is a podcast which explores the many complex intersections between gender, feminism and technology. Re-imagining voice assistants with Stina Hasse J\u00f8rgensen and Frederik Juutilainen To develop voice assistants like Siri and Alexa, companies spend years investigating what sounds like a human voice and what doesn&#8217;t. [&#8230;]"
            },
            "content": [
                {
                    "type": "text/html",
                    "language": null,
                    "base": "https://aihub.org/feed/",
                    "value": "<img alt=\"Space scene with words Good Robot Podcast\" class=\"alignnone size-full wp-image-10827\" height=\"837\" src=\"https://aihub.org/wp-content/uploads/2022/11/good-robot.png\" width=\"1704\" />\n<p>Hosted by Eleanor Drage and Kerry McInerney, <a href=\"https://www.thegoodrobot.co.uk/\">The Good Robot</a> is a podcast which explores the many complex intersections between gender, feminism and technology. </p>\n<h4>Re-imagining voice assistants with Stina Hasse J\u00f8rgensen and Frederik Juutilainen</h4>\n<p>To develop voice assistants like Siri and Alexa, companies spend years investigating what sounds like a human voice and what doesn&#8217;t. But what we&#8217;ve ended up with is just one possibility of the kinds of voices that we could be interacting with. In this episode, we talked to sound engineer Frederik Juutilainen, and assistant professor at the University of Copenhagen, Stina Hasse J\u00f8rgensen, about their participation in <a href=\"https://multivocal.org/\">[multi&#8217;vocal]</a>, an experimental research project that created an alternative voice assistant by asking people at a rock festival in Denmark to speak into a portable recording box. We talk about voice assistants&#8217; inability to stutter, lisp and code switch, and whether a voice can express multiple personalities, genders and ages. </p>\n<p>Listen to the episode here:</p>\n<div class=\"audio\"><audio controls=\"controls\" src=\"https://www.buzzsprout.com/1786427/episodes/16767549-re-imagining-voice-assistants-with-stina-hasse-jorgensen-and-frederik-juutilainen.mp3\"></audio></div>\n<p></p>\n<div class=\"keep-aspect\"></div>\n<p></p>\n<p>Stina Hasse J\u00f8rgensen (she/her) is an assistant professor at the Digital Design Department at the IT University of Copenhagen. Stina started her path as a practitioner and theorist of sound art and interactive sound at Tonespace / Electronic Music and Sound Art, at the Danish National Academy of Music (SDMK). She then took courses on advanced music technology and creative sound design at the School of Music and Media Arts, at University of London, Royal Holloway (RHUL), and studied sound art at Art History and Auditive Culture at University of Copenhagen (UCPH). Later she was taught by Douglas Repetto, Brad Garton and George Lewis at the Columbia Computer Music Center (CMC).</p>\n<p>Frederik Juutilainen is a software developer and dj from Copenhagen. He has a degree in philosophy and computer science from Roskilde University, and a Master&#8217;s in IT &#038; Cognition. He works in the development and programming of digital-/physical installations and is a part of Group Therapy, a Copenhagen-based club-night focusing on diversity and representation in underground dance music.</p>\n<p>You can find the episode reading list and transcript <a href=\"https://www.thegoodrobot.co.uk/post/re-imagining-voice-assistants-with-stina-hasse-j%C3%B8rgensen-and-frederik-juutilainen\">here</a>.</p>\n<h4>About The Good Robot Podcast</h4>\n<p><a href=\"https://www.eleanordrage.com/\">Dr Eleanor Drage</a> and <a href=\"https://www.kerrymackereth.com/\">Dr Kerry McInerney</a> are Research Associates at the Leverhulme Centre for the Future of Intelligence, where they work on the Mercator-Stiflung funded project on Desirable Digitalisation. Previously, they were Christina Gaw Postdoctoral Researchers in Gender and Technology at the University of Cambridge Centre for Gender Studies. During the COVID-19 pandemic they decided to co-found <a href=\"https://www.thegoodrobot.co.uk/\">The Good Robot Podcast</a> to explore the many complex intersections between gender, feminism and technology. </p>"
                }
            ]
        },
        {
            "title": "Visualizing research in the age of AI",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "https://aihub.org/feed/",
                "value": "Visualizing research in the age of AI"
            },
            "links": [
                {
                    "rel": "alternate",
                    "type": "text/html",
                    "href": "https://aihub.org/2025/03/14/visualizing-research-in-the-age-of-ai/"
                }
            ],
            "link": "https://aihub.org/2025/03/14/visualizing-research-in-the-age-of-ai/",
            "authors": [
                {
                    "name": "MIT News"
                }
            ],
            "author": "MIT News",
            "author_detail": {
                "name": "MIT News"
            },
            "published": "Fri, 14 Mar 2025 11:04:47 +0000",
            "published_parsed": [
                2025,
                3,
                14,
                11,
                4,
                47,
                4,
                73,
                0
            ],
            "tags": [
                {
                    "term": "opinions",
                    "scheme": null,
                    "label": null
                }
            ],
            "id": "https://aihub.org/?p=17103",
            "guidislink": false,
            "summary": "An original photograph taken by Felice Frankel (left) and an AI-generated image of the same content. Credit: Felice Frankel. Image on right was generated with DALL-E By Melanie M Kaufman For over 30 years, science photographer Felice Frankel has helped MIT professors, researchers, and students communicate their work visually. Throughout that time, she has seen [&#8230;]",
            "summary_detail": {
                "type": "text/html",
                "language": null,
                "base": "https://aihub.org/feed/",
                "value": "An original photograph taken by Felice Frankel (left) and an AI-generated image of the same content. Credit: Felice Frankel. Image on right was generated with DALL-E By Melanie M Kaufman For over 30 years, science photographer Felice Frankel has helped MIT professors, researchers, and students communicate their work visually. Throughout that time, she has seen [&#8230;]"
            },
            "content": [
                {
                    "type": "text/html",
                    "language": null,
                    "base": "https://aihub.org/feed/",
                    "value": "<p><img alt=\"\" class=\"aligncenter size-full wp-image-17109\" height=\"480\" src=\"https://aihub.org/wp-content/uploads/2025/03/felice-frankel-quantum-dots-real-and-ai-generated_720.png\" width=\"720\" /><br />\n<em>An original photograph taken by Felice Frankel (left) and an AI-generated image of the same content. Credit: Felice Frankel. Image on right was generated with DALL-E</em></p>\n<p><strong>By Melanie M Kaufman</strong></p>\n<p><em>For over 30 years, science photographer Felice Frankel has helped MIT professors, researchers, and students communicate their work visually. Throughout that time, she has seen the development of various tools to support the creation of compelling images: some helpful, and some antithetical to the effort of producing a trustworthy and complete representation of the research. In a <a href=\"https://www.nature.com/articles/d41586-025-00532-2\">recent opinion piece</a> published in Nature magazine, Frankel discusses the burgeoning use of generative artificial intelligence (GenAI) in images and the challenges and implications it has for communicating research. On a more personal note, she questions whether there will still be a place for a science photographer in the research community.</em></p>\n<p><strong>Q:</strong> You\u2019ve mentioned that as soon as a photo is taken, the image can be considered \u201cmanipulated.\u201d There are ways you\u2019ve manipulated your own images to create a visual that more successfully communicates the desired message. Where is the line between acceptable and unacceptable manipulation?</p>\n<p><strong>A:</strong> In the broadest sense, the decisions made on how to frame and structure the content of an image, along with which tools used to create the image, are already a manipulation of reality. We need to remember the image is merely a representation of the thing, and not the thing itself. Decisions have to be made when creating the image. The critical issue is not to manipulate the data, and in the case of most images, the data is the structure. For example, for an image I made some time ago, I digitally deleted the petri dish in which a yeast colony was growing, to bring attention to the stunning morphology of the colony. The data in the image is the morphology of the colony. I did not manipulate that data. However, I always indicate in the text if I have done something to an image. I discuss the idea of image enhancement in my handbook, <a href=\"https://news.mit.edu/2023/eyes-have-it-frankel-1204\">&#8220;The Visual Elements, Photography&#8221;</a>.</p>\n<p><img alt=\"\" class=\"aligncenter size-full wp-image-17110\" height=\"600\" src=\"https://aihub.org/wp-content/uploads/2025/03/gerryfink.png\" width=\"595\" /><em>An image of a growing yeast colony where the petri dish has been digitally deleted. This type of manipulation could be acceptable because the actual data has not been manipulated, Frankel says. Image credit: Felice Frankel</em></p>\n<p><strong>Q:</strong> What can researchers do to make sure their research is communicated correctly and ethically?</p>\n<p><strong>A:</strong> With the advent of AI, I see three main issues concerning visual representation: the difference between illustration and documentation, the ethics around digital manipulation, and a continuing need for researchers to be trained in visual communication. For years, I have been trying to develop a visual literacy program for the present and upcoming classes of science and engineering researchers. MIT has a communication requirement which mostly addresses writing, but what about the visual, which is no longer tangential to a journal submission? I will bet that most readers of scientific articles go right to the figures, after they read the abstract. </p>\n<p>We need to require students to learn how to critically look at a published graph or image and decide if there is something weird going on with it. We need to discuss the ethics of \u201cnudging\u201d an image to look a certain predetermined way. I describe in the article an incident when a student altered one of my images (without asking me) to match what the student wanted to visually communicate. I didn\u2019t permit it, of course, and was disappointed that the ethics of such an alteration were not considered. We need to develop, at the very least, conversations on campus and, even better, create a visual literacy requirement along with the writing requirement.</p>\n<p><strong>Q:</strong> Generative AI is not going away. What do you see as the future for communicating science visually?</p>\n<p><strong>A:</strong> For the Nature article, I decided that a powerful way to question the use of AI in generating images was by example. I used one of the diffusion models to create an image using the following prompt:</p>\n<p>\u201cCreate a photo of Moungi Bawendi\u2019s nano crystals in vials against a black background, fluorescing at different wavelengths, depending on their size, when excited with UV light.\u201d</p>\n<p>The results of my AI experimentation were often cartoon-like images that could hardly pass as reality \u2014 let alone documentation \u2014 but there will be a time when they will be. In conversations with colleagues in research and computer-science communities, all agree that we should have clear standards on what is and is not allowed. And most importantly, a GenAI visual should never be allowed as documentation.</p>\n<p>But AI-generated visuals will, in fact, be useful for illustration purposes. If an AI-generated visual is to be submitted to a journal (or, for that matter, be shown in a presentation), I believe the researcher MUST:</p>\n<ul>\n<li>clearly label if an image was created by an AI model;</li>\n<li>indicate what model was used;</li>\n<li>include what prompt was used; and</li>\n<li>include the image, if there is one, that was used to help the prompt.</li>\n</ul>"
                }
            ]
        },
        {
            "title": "#IJCAI panel on communicating about AI with the public",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "https://aihub.org/feed/",
                "value": "#IJCAI panel on communicating about AI with the public"
            },
            "links": [
                {
                    "rel": "alternate",
                    "type": "text/html",
                    "href": "https://aihub.org/2025/03/13/ijcai-panel-on-communicating-about-ai-with-the-public/"
                }
            ],
            "link": "https://aihub.org/2025/03/13/ijcai-panel-on-communicating-about-ai-with-the-public/",
            "authors": [
                {
                    "name": "AIhub"
                }
            ],
            "author": "AIhub",
            "author_detail": {
                "name": "AIhub"
            },
            "published": "Thu, 13 Mar 2025 12:07:44 +0000",
            "published_parsed": [
                2025,
                3,
                13,
                12,
                7,
                44,
                3,
                72,
                0
            ],
            "tags": [
                {
                    "term": "education",
                    "scheme": null,
                    "label": null
                },
                {
                    "term": "opinions",
                    "scheme": null,
                    "label": null
                },
                {
                    "term": "IJCAI",
                    "scheme": null,
                    "label": null
                },
                {
                    "term": "IJCAI2024",
                    "scheme": null,
                    "label": null
                }
            ],
            "id": "https://aihub.org/?p=17097",
            "guidislink": false,
            "summary": "Science communication is an invaluable skill for researchers. It can help demystify AI for a broad range of people including policy makers, business leaders, and the public. In a panel session at the 33rd International Joint Conference on Artificial Intelligence (IJCAI-24), Michael Wooldridge and Toby Walsh talked with Peter Stone about lessons they&#8217;ve learnt from [&#8230;]",
            "summary_detail": {
                "type": "text/html",
                "language": null,
                "base": "https://aihub.org/feed/",
                "value": "Science communication is an invaluable skill for researchers. It can help demystify AI for a broad range of people including policy makers, business leaders, and the public. In a panel session at the 33rd International Joint Conference on Artificial Intelligence (IJCAI-24), Michael Wooldridge and Toby Walsh talked with Peter Stone about lessons they&#8217;ve learnt from [&#8230;]"
            },
            "content": [
                {
                    "type": "text/html",
                    "language": null,
                    "base": "https://aihub.org/feed/",
                    "value": "<img alt=\"\" class=\"aligncenter size-full wp-image-15605\" height=\"633\" src=\"https://aihub.org/wp-content/uploads/2024/07/ijcai-logo-2024.jpg\" width=\"1695\" />\n<p>Science communication is an invaluable skill for researchers. It can help demystify AI for a broad range of people including policy makers, business leaders, and the public. In a panel session at the <a href=\"https://ijcai24.org/\">33rd International Joint Conference on Artificial Intelligence (IJCAI-24)</a>, Michael Wooldridge and Toby Walsh talked with Peter Stone about lessons they&#8217;ve learnt from communicating about AI with different audiences. They gave advice on how to talk to media, how you should tailor your communication for various audiences, and how to tackle different methods of communication. They drew on their personal experiences to provide hints and tips for anyone thinking about engaging in outreach.</p>\n<p>You can watch the recording <a href=\"https://ijcai24.org/video/?id=39022520\">here</a>.</p>\n<a href=\"https://ijcai24.org/video/?id=39022520\"><img alt=\"\" class=\"aligncenter size-full wp-image-17098\" height=\"553\" src=\"https://aihub.org/wp-content/uploads/2025/03/panel-screenshot.jpg\" width=\"1785\" /></a>"
                }
            ]
        },
        {
            "title": "Interview with Tunazzina Islam: Understand microtargeting and activity patterns on social media",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "https://aihub.org/feed/",
                "value": "Interview with Tunazzina Islam: Understand microtargeting and activity patterns on social media"
            },
            "links": [
                {
                    "rel": "alternate",
                    "type": "text/html",
                    "href": "https://aihub.org/2025/03/11/interview-with-tunazzina-islam-understand-microtargeting-and-activity-patterns-on-social-media/"
                }
            ],
            "link": "https://aihub.org/2025/03/11/interview-with-tunazzina-islam-understand-microtargeting-and-activity-patterns-on-social-media/",
            "authors": [
                {
                    "name": "Lucy Smith"
                }
            ],
            "author": "Lucy Smith",
            "author_detail": {
                "name": "Lucy Smith"
            },
            "published": "Tue, 11 Mar 2025 08:16:06 +0000",
            "published_parsed": [
                2025,
                3,
                11,
                8,
                16,
                6,
                1,
                70,
                0
            ],
            "tags": [
                {
                    "term": "opinions",
                    "scheme": null,
                    "label": null
                },
                {
                    "term": "AAAI",
                    "scheme": null,
                    "label": null
                },
                {
                    "term": "AAAI Doctoral Consortium",
                    "scheme": null,
                    "label": null
                },
                {
                    "term": "AAAI2025",
                    "scheme": null,
                    "label": null
                },
                {
                    "term": "ACM SIGAI",
                    "scheme": null,
                    "label": null
                }
            ],
            "id": "https://aihub.org/?p=17074",
            "guidislink": false,
            "summary": "In this interview series, we\u2019re meeting some of the AAAI/SIGAI Doctoral Consortium participants to find out more about their research. The Doctoral Consortium provides an opportunity for a group of PhD students to discuss and explore their research interests and career objectives in an interdisciplinary workshop together with a panel of established researchers. In the [&#8230;]",
            "summary_detail": {
                "type": "text/html",
                "language": null,
                "base": "https://aihub.org/feed/",
                "value": "In this interview series, we\u2019re meeting some of the AAAI/SIGAI Doctoral Consortium participants to find out more about their research. The Doctoral Consortium provides an opportunity for a group of PhD students to discuss and explore their research interests and career objectives in an interdisciplinary workshop together with a panel of established researchers. In the [&#8230;]"
            },
            "content": [
                {
                    "type": "text/html",
                    "language": null,
                    "base": "https://aihub.org/feed/",
                    "value": "<img alt=\"\" class=\"aligncenter size-full wp-image-17084\" height=\"1705\" src=\"https://aihub.org/wp-content/uploads/2025/03/Tunaz.jpg\" width=\"2484\" />\n<p>In this interview series, we\u2019re meeting some of the <a href=\"https://aaai.org/conference/aaai/aaai-25/doctoral-consortium/\">AAAI/SIGAI Doctoral Consortium</a> participants to find out more about their research. The Doctoral Consortium provides an opportunity for a group of PhD students to discuss and explore their research interests and career objectives in an interdisciplinary workshop together with a panel of established researchers. </p>\n<p>In the third of our interviews with the 2025 cohort, we heard from Tunazzina Islam who has recently completed her PhD in Computer Science at Purdue University, advised by Dr Dan Goldwasser. Her primary research interests lie in computational social science (CSS), natural language processing (NLP), and social media mining and analysis.</p>\n<h4>Could you give us an overview of the research you carried out during your PhD?</h4>\n<p>We now live in a world where we can reach people directly through social media, without relying on traditional media such as television and radio. On the other hand, social media platforms collect vast amounts of data and create very specific profiles of different users through targeted advertising. Various interest groups, including politicians, advertisers, and stakeholders, utilize these platforms to target potential users to advance their interests by adapting their messaging. This process, known as microtargeting, relies on data-driven techniques that exploit the rich information collected by social networks about their users. I am giving an example of microtargeting on COVID-19 vaccine topic: The same ad source, when targeting the older population, emphasizes the message &#8220;vaccine passport is oppression&#8221;. Conversely, while targeting women of reproductive age, it claims &#8220;vaccine is dangerous for pregnant women&#8221;. The same ad source tailors its messaging based on different demographics. </p>\n<p>Microtargeting is a double-edged sword. It enhances the relevance and efficiency of targeted content and can influence people to take action based on personal beliefs. On the one hand, this could be great in increasing the relevance based on users to help guide people in making better health decisions and offering them opportunities for career growth. On the other hand, it can manipulate people to make decisions against their own interests, foster echo chambers, and increase polarization. </p>\n<p>My research is motivated by the fact that some of these risks can be mitigated by providing transparency, identifying conflicting or harmful messaging choices, and indicating bias introduced in messaging in a nuanced way. My research vision is to understand microtargeting and activity patterns on social media by developing computational approaches and frameworks blending computational social science (CSS), natural language processing (NLP), and artificial intelligence (AI).</p>\n<p>A significant challenge lies in understanding the messaging and how it changes depending on the targeted user groups. Another challenge arises when we do not know who the users are and what their motivations are for engaging with content. My research is driven by characterizing users and messaging on social media. I address the challenges by developing computational approaches for (1) characterizing user types and their motivations for engaging with content [<a href=\"https://ojs.aaai.org/index.php/ICWSM/article/view/19298\">ICWSM&#8217;22</a>, <a href=\"https://ojs.aaai.org/index.php/ICWSM/article/view/18057\">ICWSM&#8217;21</a>, <a href=\"https://ieeexplore.ieee.org/document/9364605\">ICSC&#8217;21</a>, <a href=\"https://ieeexplore.ieee.org/document/9378461\">IEEE BigData&#8217;20</a>], (2) analyzing the messaging based on topics relevant to the users and their responses to it [<a href=\"https://ojs.aaai.org/index.php/ICWSM/article/view/22156\">ICWSM&#8217;23</a>, <a href=\"https://dl.acm.org/doi/10.1145/3600211.3604665\">AIES&#8217;23</a>, <a href=\"https://ieeexplore.ieee.org/document/10021123\">IEEE BigData&#8217;22</a>], and (3) delving into the deeper understanding of the themes and arguments involved in the content [<a href=\"https://arxiv.org/pdf/2404.10259\">NAACL&#8217;25</a>, <a href=\"https://arxiv.org/pdf/2403.10707\">ICWSM&#8217;25</a>, <a href=\"https://aclanthology.org/2023.findings-acl.313/\">ACL&#8217;23</a>, <a href=\"https://aclanthology.org/2022.naacl-main.427.pdf\">NAACL&#8217;22</a>, <a href=\"https://aclanthology.org/2022.dash-1.13.pdf\">DaSH&#8217;22</a>]</p>\n<p><img alt=\"\" class=\"aligncenter size-full wp-image-17078\" height=\"1707\" src=\"https://aihub.org/wp-content/uploads/2025/03/research_image_Tunazzina_Islam-scaled.jpeg\" width=\"2560\" /><em>Tunazzina&#8217;s poster at the 2025 AAAI/SIGAI Doctoral Consortium.</em></p>\n<h4>Is there an aspect of your research that has been particularly interesting?</h4>\n<p>One particularly interesting aspect of my research is uncovering how messaging strategies adapt to different user groups and the implications this has for public opinion and decision-making. The way that the same source can craft vastly different narratives for distinct audiences is both fascinating and concerning. For example, in the case of COVID-19 vaccine-related messaging, seeing how the same entity tailors its argument\u2014framing the vaccine as an oppressive mandate for older populations while portraying it as a health risk for pregnant women\u2014highlights the power and potential risks of microtargeting.</p>\n<p>From a methodological perspective, developing computational techniques that blend NLP+CSS to detect nuanced messaging patterns is intellectually stimulating. It involves not only identifying what is being said but also contextualizing it within larger narratives and understanding the strategic intent behind different messaging styles. These insights can be used to enhance transparency in online communication, mitigate harmful effects of microtargeting, and develop interventions that promote more balanced and informed public discourse.</p>\n<p>Overall, what makes my research particularly interesting is its real-world relevance\u2014unpacking how digital communication shapes public perception and decision-making, and exploring ways to ensure these processes are more transparent.</p>\n<p>My PhD thesis proposal won a best poster award at the 2025 AAAI/SIGAI Doctoral Consortium.</p>\n<p><img alt=\"\" class=\"aligncenter size-full wp-image-17092\" height=\"1333\" src=\"https://aihub.org/wp-content/uploads/2025/03/best-poster-presentation.jpg\" width=\"1856\" /><em>Tunazzina receiving the best poster award.</em></p>\n<h4>What are your plans for building on your research during the PhD &#8211; what aspects will you be investigating next?</h4>\n<p>A major challenge is understanding the harmful effects of messaging choices when it comes to reinforcing bias and stereotypes. Doing that requires us to scale up this analysis and adapt to ongoing continuous changing messaging; large language models (LLMs) provide us an opportunity to reason about it and deal with how this analysis can scale up. Currently, I am working on leveraging LLMs to analyze societal opinions, biases in microtargeting to ensure equitable digital practices, and foster human-AI collaboration in complex psycho-linguistic tasks, i.e., identifying morality frame on vaccine debate [ACM WebSci&#8217;25], create AI-driven insights that inform policymaking and promote positive societal change. This integrated approach ensures that artificial intelligence (AI) serves as a catalyst for understanding and improving human experiences within diverse social contexts. My future research will utilize advanced AI technologies to bridge the gap between societal needs and technological solutions.</p>\n<h4>What made you want to study NLP, and in particular the application to computational social science and social media analysis?</h4>\n<p>My interest in NLP, CSS and social media mining stemmed from a deep curiosity about how language shapes human interactions and influences societal outcomes. Additionally, I was drawn to the interdisciplinary nature of computational social science as it allows for the integration of AI and machine learning with theories from psychology, sociology, and political science.</p>\n<p>The rise of social media as a dominant communication platform has fundamentally changed how information spreads, how people form opinions, and how different interest groups engage with the public. Unlike traditional media, where messaging is largely uniform, social media allows for highly personalized and dynamic communication. This intrigued me, as it introduced both opportunities and challenges\u2014on one hand, enabling more relevant and targeted content, but on the other, increasing the risk of manipulation, misinformation, and polarization. Witnessing the growing role of data-driven messaging in shaping public discourse, I became interested in developing computational methods to better understand and analyze these dynamics.</p>\n<h4>What advice would you give to someone thinking of doing a PhD in the field?</h4>\n<p>A PhD is not a sprint; it&#8217;s a marathon. There will be many paper rejections, ideas that don&#8217;t work, and phases where you feel stuck for a long time. Some research questions will be harder to formulate than others, but my advice is simple: hang in there\u2014don&#8217;t give up. Keep communicating with your advisor, stay engaged by reading papers, and actively discuss your ideas. Attend conferences, workshops, and tutorials to broaden your perspective. Seek support from your peers and colleagues\u2014it&#8217;s a journey best navigated with a strong network.</p>\n<h4>Could you tell us an interesting (non-AI related) fact about you?</h4>\n<p>An interesting (and deeply personal) fact about me is that I became a mom of two during my PhD journey! My daughter was born in 2021, and my son was born in 2023. Balancing a PhD while navigating two pregnancies, two childbirths, and the challenges of raising young children\u2014alongside my husband, who was also a PhD student back then\u2014was an incredibly demanding yet rewarding experience. Adding to the complexity, this all happened during a global pandemic. This journey has given me a profound appreciation for resilience, time management, and the strength of academic parents. It&#8217;s been challenging, but also a testament to perseverance and passion!</p>\n<p>I am a first-generation PhD, yogi, and travel enthusiast.</p>\n<p><img alt=\"\" class=\"aligncenter size-full wp-image-17077\" height=\"1920\" src=\"https://aihub.org/wp-content/uploads/2025/03/AAAI_DC_Poster-scaled.jpeg\" width=\"2560\" /><em>Tunazzina with her poster at AAAI 2025.</em></p>\n<h4>About Tunazzina</h4>\n<p><a href=\"https://tunazislam.github.io/\">Tunazzina Islam</a> has recently completed her PhD in Computer Science from Purdue University. She was advised by Dr Dan Goldwasser. Her research vision is to understand microtargeting and activity patterns on social media by developing computational approaches and frameworks blending computational social science (CSS), natural language processing (NLP), and artificial intelligence (AI). Her work has been recognized by her publications in prominent conferences including AAAI ICWSM, NAACL, ACL, AIES, ACM WebSci, IEEE BigData, and awards (Purdue Graduate School Summer Research Grant: 3 times). Her PhD thesis proposal was accepted at the AAAI-25 Doctoral Consortium where she won the best poster award. Beyond research, she has nine years of teaching experience in various roles such as teaching assistant, guest lecturer, mentor, and trainer. For her teaching contributions, she received the Graduate Teaching Award from Purdue CS Department. To support the CSS research community, she became an ICWSM ambassador, introducing the conference to interested researchers and individuals from underrepresented groups. She has served as Tutorial Co-chair of ICWSM 2025 and Associate Chair for CSCW 2024, CSCW 2025. Additionally, she has been a reviewer for numerous NLP, CSS, HCI, and AI conferences and workshops since 2020. She organized a tutorial on &#8220;Analyzing Microtargeting on Social Media&#8221; at 2024 Academic Data Science Alliance (ADSA) Annual Meeting. She also served as a Vice President of the Computer Science Graduate Student Association (CSGSA), Purdue University, from 2022 to 2023.</p>"
                }
            ]
        },
        {
            "title": "Microsoft cuts data centre plans and hikes prices in push to make users carry AI costs",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "https://aihub.org/feed/",
                "value": "Microsoft cuts data centre plans and hikes prices in push to make users carry AI costs"
            },
            "links": [
                {
                    "rel": "alternate",
                    "type": "text/html",
                    "href": "https://aihub.org/2025/03/10/microsoft-cuts-data-centre-plans-and-hikes-prices-in-push-to-make-users-carry-ai-costs/"
                }
            ],
            "link": "https://aihub.org/2025/03/10/microsoft-cuts-data-centre-plans-and-hikes-prices-in-push-to-make-users-carry-ai-costs/",
            "authors": [
                {
                    "name": "The Conversation"
                }
            ],
            "author": "The Conversation",
            "author_detail": {
                "name": "The Conversation"
            },
            "published": "Mon, 10 Mar 2025 10:15:59 +0000",
            "published_parsed": [
                2025,
                3,
                10,
                10,
                15,
                59,
                0,
                69,
                0
            ],
            "tags": [
                {
                    "term": "articles",
                    "scheme": null,
                    "label": null
                }
            ],
            "id": "https://aihub.org/?p=17068",
            "guidislink": false,
            "summary": "Fritzchens Fritz / Better Images of AI / GPU shot etched 2 / Licenced by CC-BY 4.0 By Kevin Witzenberger, Queensland University of Technology and Michael Richardson, UNSW Sydney After a year of shoehorning generative AI into its flagship products, Microsoft is trying to recoup the costs by raising prices, putting ads in products, and [&#8230;]",
            "summary_detail": {
                "type": "text/html",
                "language": null,
                "base": "https://aihub.org/feed/",
                "value": "Fritzchens Fritz / Better Images of AI / GPU shot etched 2 / Licenced by CC-BY 4.0 By Kevin Witzenberger, Queensland University of Technology and Michael Richardson, UNSW Sydney After a year of shoehorning generative AI into its flagship products, Microsoft is trying to recoup the costs by raising prices, putting ads in products, and [&#8230;]"
            },
            "content": [
                {
                    "type": "text/html",
                    "language": null,
                    "base": "https://aihub.org/feed/",
                    "value": "<p><img alt=\"\" class=\"aligncenter size-full wp-image-17071\" height=\"720\" src=\"https://aihub.org/wp-content/uploads/2025/03/FritzchensFritz-GPUshot-etched-2-1280x720-1.jpg\" width=\"1280\" /><span><a href=\"https://www.flickr.com/photos/130561288@N04/\">Fritzchens Fritz</a> / <a href=\"https://www.betterimagesofai.org\">Better Images of AI</a> / GPU shot etched 2 / <a href=\"https://creativecommons.org/licenses/by/4.0/\">Licenced by CC-BY 4.0</a></span></p>\n<p><strong>By <a href=\"https://theconversation.com/profiles/kevin-witzenberger-2332896\">Kevin Witzenberger</a>, <em><a href=\"https://theconversation.com/institutions/queensland-university-of-technology-847\">Queensland University of Technology</a></em> and <a href=\"https://theconversation.com/profiles/michael-richardson-303526\">Michael Richardson</a>, <em><a href=\"https://theconversation.com/institutions/unsw-sydney-1414\">UNSW Sydney</a></em></strong></p>\n<p>After a year of <a href=\"https://au.pcmag.com/ai/105783/what-is-copilot-microsofts-ai-assistant-explained\">shoehorning generative AI into its flagship products</a>, Microsoft is trying to recoup the costs by raising prices, putting ads in products, and <a href=\"https://www.forbes.com/sites/esatdedezade/2025/02/24/beyond-apples-500-billion-techs-diverging-ai-strategies/\">cancelling data centre leases</a>. Google is making similar moves, adding unavoidable AI features to its Workspace service while <a href=\"https://9to5google.com/2025/01/15/google-workspace-price-increase-2025/\">increasing prices</a>.</p>\n<p>Is the tide finally turning on investments into generative AI? The situation is not quite so simple. Tech companies are fully committed to the new technology \u2013 but are struggling to find ways to make people pay for it.</p>\n<h2>Shifting costs</h2>\n<p>Last month, Microsoft unceremoniously pulled back on some planned <a href=\"https://www.reuters.com/technology/microsoft-shelves-ai-data-center-deals-sign-potential-oversupply-analyst-says-2025-02-24/\">data centre leases</a>. The move came after the company <a href=\"https://www.abc.net.au/news/2025-02-25/microsoft-365-subscription-price-hike-consumer-complaints-accc/104965682\">increased subscription prices</a> for its flagship 365 software by up to 45%, and quietly released an <a href=\"https://www.theregister.com/2025/02/25/adsupported_microsoft_office/\">ad-supported version</a> of some products.</p>\n<p>The tech giant\u2019s CEO, Satya Nadella, also recently <a href=\"https://futurism.com/microsoft-ceo-hesitation-ai-expensive-data-centers\">suggested</a> AI has so far not produced much value.</p>\n<p>Microsoft\u2019s actions may seem odd in the current wave of AI hype, coming amid splashy announcements such as OpenAI\u2019s US$500 billion <a href=\"https://www.forbes.com/sites/moorinsights/2025/01/30/the-stargate-project-trump-touts-500-billion-bid-for-ai-dominance/\">Stargate data centre project</a>.</p>\n<p>But if we look closely, nothing in Microsoft\u2019s decisions indicates a retreat from AI itself. Rather, we are seeing a change in strategy to make AI profitable by shifting the cost in non-obvious ways onto consumers.</p>\n<h2>The cost of generative AI</h2>\n<p>Generative AI is expensive. OpenAI, the market leader with a claimed <a href=\"https://www.cnbc.com/2025/02/20/openai-tops-400-million-users-despite-deepseeks-emergence.html\">400 million active monthly users</a>, is burning money. </p>\n<p>Last year, OpenAI brought in US$3.7 billion in revenue \u2013 but spent almost US$9 billion, for a net loss of around <a href=\"https://www.cnbc.com/2024/09/27/openai-sees-5-billion-loss-this-year-on-3point7-billion-in-revenue.html\">US$5 billion</a>.</p>\n<p>Microsoft is OpenAI\u2019s biggest investor and currently provides the company with cloud computing services, so OpenAI\u2019s spending also costs Microsoft.</p>\n<p>What makes generative AI so expensive? Human labour aside, two costs are associated with AI models: training (building the model) and inference (using the model).</p>\n<p>While training is an (often large) up-front expense, the costs of inference grow with the user base. And the bigger the model, the more it costs to run. </p>\n<h2>Smaller, cheaper alternatives</h2>\n<p>A single query on OpenAI\u2019s most advanced models can <a href=\"https://futurism.com/the-byte/openai-o3-cost-per-query\">cost up to US$1,000</a> in compute power alone. In January, OpenAI CEO Sam Altman said even the company\u2019s <a href=\"https://futurism.com/the-byte/openai-chatgpt-pro-subscription-losing-money\">US$200 per month subscription is not profitable</a>. This signals the company is not only losing money through use of its free models, but through its subscription models as well.</p>\n<p>Both training and inference typically take place in data centres. Costs are high because the chips needed to run them are expensive, but so too are electricity, cooling, and the depreciation of hardware. </p>\n<p>To date, much AI progress has been achieved by using more of everything. OpenAI <a href=\"https://www.cnbc.com/2025/02/27/openai-launching-gpt-4point5-general-purpose-large-language-model.html\">describes</a> its latest upgrade as a \u201cgiant, expensive model\u201d. However, there are now plenty of signs this scale-at-all-costs approach might not even be necessary.</p>\n<p>Chinese company <a href=\"https://www.admscentre.org.au/open-source-and-under-control-the-deepseek-paradox/\">DeepSeek</a> made waves earlier this year when it revealed it had built models comparable to OpenAI\u2019s flagship products for a tiny fraction of the training cost. Likewise, researchers from Seattle\u2019s Allen Institute for AI (Ai2) and Stanford University claim to have trained a model for <a href=\"https://arxiv.org/abs/2501.19393\">as little as US$50</a>.</p>\n<p>In short, AI systems developed and delivered by tech giants might not be profitable. The costs of building and running data centres are a big reason why.</p>\n<h2>What is Microsoft doing?</h2>\n<p>Having sunk billions into generative AI, Microsoft is trying to find the business model that will make the technology profitable. </p>\n<p>Over the past year, the tech giant has integrated the Copilot generative AI chatbot into its products geared towards consumers and businesses. </p>\n<p>It is no longer possible to purchase any Microsoft 365 subscription without Copilot. As a result subscribers are <a href=\"https://www.abc.net.au/news/2025-02-25/microsoft-365-subscription-price-hike-consumer-complaints-accc/104965682\">seeing significant price hikes</a>.</p>\n<p>As we have seen, running generative AI models in data centres is expensive. So Microsoft is likely seeking ways to do more of the work on users\u2019 own devices \u2013 where the user pays for the hardware and its running costs.</p>\n<p>A strong clue for this strategy is <a href=\"https://www.theverge.com/2024/1/4/24023809/microsoft-copilot-key-keyboard-windows-laptops-pcs\">a small button</a> Microsoft began to put on its devices last year. In the precious real estate of the QWERTY keyboard, Microsoft dedicated a key to Copilot on its PCs and laptops capable of processing AI on the device.</p>\n<p>Apple is pursuing <a href=\"https://www.apple.com/au/newsroom/2024/06/introducing-apple-intelligence-for-iphone-ipad-and-mac/\">a similar strategy</a>. The iPhone manufacturer is not offering most of its AI services in the cloud. Instead, only new devices offer AI capabilities, with on-device processing marketed as a privacy feature that prevents your data travelling elsewhere.</p>\n<h2>Pushing costs to the edge</h2>\n<p>There are benefits to the push to do the work of generative AI inference on the computing devices in our pockets, on our desks, or even on smart watches on our wrists (so-called \u201c<a href=\"https://azure.microsoft.com/en-ca/resources/cloud-computing-dictionary/what-is-edge-computing\">edge computing</a>\u201d, because it occurs at the \u201cedge\u201d of the network).</p>\n<p>It can reduce the energy, resources and waste of data centres, lowering generative AI\u2019s carbon, heat and water footprint. It could also reduce bandwidth demands and increase user privacy.</p>\n<p>But there are downsides too. Edge computing shifts computation costs to consumers, driving demand for new devices despite economic and environmental concerns that discourage frequent upgrades. This could intensify with newer, bigger generative AI models.</p>\n<p>And there are more problems. Distributed e-waste makes <a href=\"https://www.youtube.com/playlist?list=PLE_y90GftjpZbr0HN3dZZ9eJ36LtyHzXQ\">recycling much harder</a>. What\u2019s more, the playing field for users won\u2019t be level if a device dictates how good your AI can be, particularly in educational settings. </p>\n<p>And while edge computing may seem more \u201cdecentralised\u201d, it may also lead to hardware monopolies. If only a handful of companies control this transition, decentralisation may not be as open as it appears.</p>\n<p>As AI infrastructure costs rise and model development evolves, shifting the costs to consumers becomes an appealing strategy for AI companies. While big enterprises such as government departments and universities may manage these costs, many small businesses and individual consumers may struggle.<!-- Below is The Conversation's page counter tag. Please DO NOT REMOVE. --><img alt=\"The Conversation\" height=\"1\" src=\"https://counter.theconversation.com/content/250932/count.gif?distributor=republish-lightbox-basic\" style=\"border: none !important; margin: 0 !important; padding: 0 !important;\" width=\"1\" /><!-- End of code. If you don't see any code above, please get new code from the Advanced tab after you click the republish button. The page counter does not collect any personal data. More info: https://theconversation.com/republishing-guidelines --></p>\n<p><span><a href=\"https://theconversation.com/profiles/kevin-witzenberger-2332896\">Kevin Witzenberger</a>, Research Fellow, GenAI Lab, <em><a href=\"https://theconversation.com/institutions/queensland-university-of-technology-847\">Queensland University of Technology</a></em> and <a href=\"https://theconversation.com/profiles/michael-richardson-303526\">Michael Richardson</a>, Associate Professor of Media, <em><a href=\"https://theconversation.com/institutions/unsw-sydney-1414\">UNSW Sydney</a></em></span></p>\n<p>This article is republished from <a href=\"https://theconversation.com\">The Conversation</a> under a Creative Commons license. Read the <a href=\"https://theconversation.com/microsoft-cuts-data-centre-plans-and-hikes-prices-in-push-to-make-users-carry-ai-costs-250932\">original article</a>.</p>"
                }
            ]
        },
        {
            "title": "Report on the future of AI research",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "https://aihub.org/feed/",
                "value": "Report on the future of AI research"
            },
            "links": [
                {
                    "rel": "alternate",
                    "type": "text/html",
                    "href": "https://aihub.org/2025/03/07/report-on-the-future-of-ai-research/"
                }
            ],
            "link": "https://aihub.org/2025/03/07/report-on-the-future-of-ai-research/",
            "authors": [
                {
                    "name": "Lucy Smith"
                }
            ],
            "author": "Lucy Smith",
            "author_detail": {
                "name": "Lucy Smith"
            },
            "published": "Fri, 07 Mar 2025 08:58:21 +0000",
            "published_parsed": [
                2025,
                3,
                7,
                8,
                58,
                21,
                4,
                66,
                0
            ],
            "tags": [
                {
                    "term": "education",
                    "scheme": null,
                    "label": null
                },
                {
                    "term": "AAAI",
                    "scheme": null,
                    "label": null
                },
                {
                    "term": "AAAI2025",
                    "scheme": null,
                    "label": null
                }
            ],
            "id": "https://aihub.org/?p=17054",
            "guidislink": false,
            "summary": "Image taken from the front cover of the Future of AI Research report. The Association for the Advancement of Artificial Intelligence (AAAI), has published a report on the Future of AI Research. The report, which was announced by outgoing AAAI President Francesca Rossi during the AAAI 2025 conference, covers 17 different AI topics and aims [&#8230;]",
            "summary_detail": {
                "type": "text/html",
                "language": null,
                "base": "https://aihub.org/feed/",
                "value": "Image taken from the front cover of the Future of AI Research report. The Association for the Advancement of Artificial Intelligence (AAAI), has published a report on the Future of AI Research. The report, which was announced by outgoing AAAI President Francesca Rossi during the AAAI 2025 conference, covers 17 different AI topics and aims [&#8230;]"
            },
            "content": [
                {
                    "type": "text/html",
                    "language": null,
                    "base": "https://aihub.org/feed/",
                    "value": "<p><img alt=\"\" class=\"aligncenter size-full wp-image-17056\" height=\"629\" src=\"https://aihub.org/wp-content/uploads/2025/03/futureofAI.jpg\" width=\"818\" /><em>Image taken from the front cover of the Future of AI Research report.</em></p>\n<p>The Association for the Advancement of Artificial Intelligence (AAAI), has <a href=\"https://aaai.org/about-aaai/presidential-panel-on-the-future-of-ai-research/\">published</a> a report on the <a href=\"https://aaai.org/wp-content/uploads/2025/03/AAAI-2025-PresPanel-Report_FINAL.pdf\">Future of AI Research</a>. The report, which was announced by outgoing AAAI President Francesca Rossi during the <a href=\"https://aaai.org/conference/aaai/aaai-25/\">AAAI 2025 conference</a>, covers 17 different AI topics and aims to clearly identify the trajectory of AI research in a structured way. </p>\n<p>The report is the result of a Presidential Panel, chaired by Francesca Rossi, and comprising of 24 experienced AI researchers, who worked on the project between summer 2024 and spring 2025. As well as the views of the panel members, the report also draws on community feedback, which was received from 475 AI researchers via a survey. </p>\n<p>The 17 topics, each with a dedicated chapter, are as follows. </p>\n<ul>\n<li>AI Reasoning</li>\n<li>AI Factuality &#038; Trustworthiness</li>\n<li>AI Agents</li>\n<li>AI Evaluation</li>\n<li>AI Ethics &#038; Safety</li>\n<li>Embodied AI</li>\n<li>AI &#038; Cognitive Science</li>\n<li>Hardware &#038; AI</li>\n<li>AI for Social Good</li>\n<li>AI &#038; Sustainability</li>\n<li>AI for Scientific Discovery</li>\n<li>Artificial General Intelligence (AGI)</li>\n<li>AI Perception vs. Reality</li>\n<li>Diversity of AI Research Approaches</li>\n<li>Research Beyond the AI Research Community</li>\n<li>Role of Academia</li>\n<li>Geopolitical Aspects &#038; Implications of AI</li>\n</ul>\n<p>Each chapter includes a list of main takeaways, context and history, current state and trends, research challenges, and community opinion. You can read the report in full <a href=\"https://aaai.org/wp-content/uploads/2025/03/AAAI-2025-PresPanel-Report_FINAL.pdf\">here</a>.</p>"
                }
            ]
        },
        {
            "title": "Andrew Barto and Richard Sutton win 2024 Turing Award",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "https://aihub.org/feed/",
                "value": "Andrew Barto and Richard Sutton win 2024 Turing Award"
            },
            "links": [
                {
                    "rel": "alternate",
                    "type": "text/html",
                    "href": "https://aihub.org/2025/03/06/andrew-barto-and-richard-sutton-win-2024-turing-award/"
                }
            ],
            "link": "https://aihub.org/2025/03/06/andrew-barto-and-richard-sutton-win-2024-turing-award/",
            "authors": [
                {
                    "name": "AIhub"
                }
            ],
            "author": "AIhub",
            "author_detail": {
                "name": "AIhub"
            },
            "published": "Thu, 06 Mar 2025 10:00:11 +0000",
            "published_parsed": [
                2025,
                3,
                6,
                10,
                0,
                11,
                3,
                65,
                0
            ],
            "tags": [
                {
                    "term": "news",
                    "scheme": null,
                    "label": null
                },
                {
                    "term": "quick read",
                    "scheme": null,
                    "label": null
                }
            ],
            "id": "https://aihub.org/?p=17060",
            "guidislink": false,
            "summary": "Andrew Barto and Richard Sutton. Image credit: Association for Computing Machinery. The Association for Computing Machinery, has named Andrew Barto and Richard Sutton as the recipients of the 2024 ACM A.M. Turing Award. The pair have received the honour for &#8220;developing the conceptual and algorithmic foundations of reinforcement learning&#8221;. In a series of papers beginning [&#8230;]",
            "summary_detail": {
                "type": "text/html",
                "language": null,
                "base": "https://aihub.org/feed/",
                "value": "Andrew Barto and Richard Sutton. Image credit: Association for Computing Machinery. The Association for Computing Machinery, has named Andrew Barto and Richard Sutton as the recipients of the 2024 ACM A.M. Turing Award. The pair have received the honour for &#8220;developing the conceptual and algorithmic foundations of reinforcement learning&#8221;. In a series of papers beginning [&#8230;]"
            },
            "content": [
                {
                    "type": "text/html",
                    "language": null,
                    "base": "https://aihub.org/feed/",
                    "value": "<p><img alt=\"\" class=\"aligncenter size-full wp-image-17064\" height=\"1436\" src=\"https://aihub.org/wp-content/uploads/2025/03/Barto-and-Sutton-scaled.jpg\" width=\"2560\" /><em>Andrew Barto and Richard Sutton. Image credit: Association for Computing Machinery.</em></p>\n<p>The <a href=\"https://www.acm.org/\">Association for Computing Machinery</a>, has named Andrew Barto and Richard Sutton as the recipients of the <a href=\"https://awards.acm.org/about/2024-turing\">2024 ACM A.M. Turing Award</a>. The pair have received the honour for <em>&#8220;developing the conceptual and algorithmic foundations of reinforcement learning&#8221;</em>. In a series of papers beginning in the 1980s, Barto and Sutton introduced the main ideas, constructed the mathematical foundations, and developed important algorithms for reinforcement learning.</p>\n<p>The Turing Award comes with a $1 million prize, to be split between the recipients. Since its inception in 1966, the award has honoured computer scientists and engineers on a yearly basis. The prize was last given for AI research in 2018, when Yoshua Bengio, Yann LeCun and Geoffrey Hinton were recognised for their contribution to the field of deep neural networks. </p>\n<p>Andrew Barto is Professor Emeritus, Department of Information and Computer Sciences, University of Massachusetts, Amherst. He began his career at UMass Amherst as a postdoctoral Research Associate in 1977, and has subsequently held various positions including Associate Professor, Professor, and Department Chair. Barto received a BS degree in Mathematics (with distinction) from the University of Michigan, where he also earned his MS and PhD degrees in Computer and Communication Sciences.</p>\n<p>Richard Sutton is a Professor in Computing Science at the University of Alberta, a Research Scientist at Keen Technologies (an artificial general intelligence company based in Dallas, Texas) and Chief Scientific Advisor of the Alberta Machine Intelligence Institute (Amii). Sutton was a Distinguished Research Scientist at Deep Mind from 2017 to 2023. Prior to joining the University of Alberta, he served as a Principal Technical Staff Member in the Artificial Intelligence Department at the AT&#038;T Shannon Laboratory in Florham Park, New Jersey, from 1998 to 2002. Sutton received his BA in Psychology from Stanford University and earned his MS and PhD degrees in Computer and Information Science from the University of Massachusetts at Amherst.</p>\n<p>The two researchers began collaborating in 1978, at the University of Massachusetts at Amherst, where Barto was Sutton\u2019s PhD and postdoctoral advisor. </p>\n<h4>Find out more</h4>\n<ul>\n<li><a href=\"https://awards.acm.org/about/2024-turing\">ACM announcement</a></li>\n<li><a href=\"https://aihub.org/2021/10/14/what-is-ai-stephen-hanson-in-conversation-with-richard-sutton/\">Richard Sutton in conversation with Stephen Hanson</a></li>\n</ul>"
                }
            ]
        },
        {
            "title": "#AAAI2025 social media round-up: part two",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "https://aihub.org/feed/",
                "value": "#AAAI2025 social media round-up: part two"
            },
            "links": [
                {
                    "rel": "alternate",
                    "type": "text/html",
                    "href": "https://aihub.org/2025/03/05/aaai2025-social-media-round-up-part-two/"
                }
            ],
            "link": "https://aihub.org/2025/03/05/aaai2025-social-media-round-up-part-two/",
            "authors": [
                {
                    "name": "Lucy Smith"
                }
            ],
            "author": "Lucy Smith",
            "author_detail": {
                "name": "Lucy Smith"
            },
            "published": "Wed, 05 Mar 2025 10:36:34 +0000",
            "published_parsed": [
                2025,
                3,
                5,
                10,
                36,
                34,
                2,
                64,
                0
            ],
            "tags": [
                {
                    "term": "opinions",
                    "scheme": null,
                    "label": null
                },
                {
                    "term": "AAAI",
                    "scheme": null,
                    "label": null
                },
                {
                    "term": "AAAI2025",
                    "scheme": null,
                    "label": null
                },
                {
                    "term": "quick read",
                    "scheme": null,
                    "label": null
                }
            ],
            "id": "https://aihub.org/?p=17034",
            "guidislink": false,
            "summary": "The 39th Annual AAAI Conference on Artificial Intelligence (AAAI 2025), which took place in Philadelphia, drew to a close on Tuesday 4 March. We take a look at what attendees got up to during the second half of the event, which featured invited talks, technical sessions, demos, posters, and the workshops. Outgoing AAAI President Francesca [&#8230;]",
            "summary_detail": {
                "type": "text/html",
                "language": null,
                "base": "https://aihub.org/feed/",
                "value": "The 39th Annual AAAI Conference on Artificial Intelligence (AAAI 2025), which took place in Philadelphia, drew to a close on Tuesday 4 March. We take a look at what attendees got up to during the second half of the event, which featured invited talks, technical sessions, demos, posters, and the workshops. Outgoing AAAI President Francesca [&#8230;]"
            },
            "content": [
                {
                    "type": "text/html",
                    "language": null,
                    "base": "https://aihub.org/feed/",
                    "value": "<p><img alt=\"\" class=\"aligncenter size-full wp-image-17039\" height=\"1920\" src=\"https://aihub.org/wp-content/uploads/2025/03/IMG_20250228_110255-scaled.jpg\" width=\"2560\" /><br />\nThe <a href=\"https://aaai.org/conference/aaai/aaai-25/\">39th Annual AAAI Conference on Artificial Intelligence (AAAI 2025)</a>, which took place in Philadelphia, drew to a close on Tuesday 4 March. We take a look at what attendees got up to during the second half of the event, which featured invited talks, technical sessions, demos, posters, and the workshops. Outgoing AAAI President Francesca Rossi also announced the released of a report on the <a href=\"https://aaai.org/wp-content/uploads/2025/03/AAAI-2025-PresPanel-Report_FINAL.pdf\">Future of AI research</a>.</p>\n<blockquote class=\"twitter-tweet\">\n<p dir=\"ltr\" lang=\"en\">I had the great pleasure and privilege of participating in this \ud83d\udc47 Presidential Panel report on &quot;Future of <a href=\"https://twitter.com/hashtag/AI?src=hash&amp;ref_src=twsrc%5Etfw\">#AI</a> Research&quot;&#8211;now available from <a href=\"https://twitter.com/RealAAAI?ref_src=twsrc%5Etfw\">@realaaai</a> at \ud83d\udc49<a href=\"https://t.co/DPghoYgneq\">https://t.co/DPghoYgneq</a> (More on it at today's <a href=\"https://twitter.com/hashtag/AAAI2025?src=hash&amp;ref_src=twsrc%5Etfw\">#AAAI2025</a> panel discussion ) <a href=\"https://t.co/dNwPDKlQh5\">pic.twitter.com/dNwPDKlQh5</a></p>\n<p>&mdash; Subbarao Kambhampati (\u0c15\u0c02\u0c2d\u0c02\u0c2a\u0c3e\u0c1f\u0c3f \u0c38\u0c41\u0c2c\u0c4d\u0c2c\u0c3e\u0c30\u0c3e\u0c35\u0c41) (@rao2z) <a href=\"https://twitter.com/rao2z/status/1895850342241247438?ref_src=twsrc%5Etfw\">March 1, 2025</a></p></blockquote>\n<p> </p>\n<blockquote class=\"bluesky-embed\">\n<p lang=\"en\">Second #AAAI2025 demo complete! Image featuring the verbal and non-verbal engagement of Dr. Ken Forbus</p>\n<p><a href=\"https://bsky.app/profile/did:plc:jpc7ukh2vroea2zxtfaaci5f/post/3ljdmnvyegs2v?ref_src=embed\">[image or embed]</a></p>\n<p>&mdash; Nikhil Krishnaswamy (<a href=\"https://bsky.app/profile/did:plc:jpc7ukh2vroea2zxtfaaci5f?ref_src=embed\">@nikhilkrishnaswamy.bsky.social</a>) <a href=\"https://bsky.app/profile/did:plc:jpc7ukh2vroea2zxtfaaci5f/post/3ljdmnvyegs2v?ref_src=embed\">1 March 2025 at 14:09</a></p></blockquote>\n<p></p>\n<blockquote class=\"twitter-tweet\">\n<p dir=\"ltr\" lang=\"en\">\u2728 Honored to receive the <a href=\"https://twitter.com/hashtag/BestPaper?src=hash&amp;ref_src=twsrc%5Etfw\">#BestPaper</a> Award at <a href=\"https://twitter.com/hashtag/AAAI2025?src=hash&amp;ref_src=twsrc%5Etfw\">#AAAI2025</a> Good-Data Workshop among 25 accepted papers<br />Grateful to my incredible collaborators <a href=\"https://twitter.com/YIJIA_XIAO_?ref_src=twsrc%5Etfw\">@YIJIA_XIAO_</a> , <a href=\"https://twitter.com/DianaYiyangWang?ref_src=twsrc%5Etfw\">@DianaYiyangWang</a>, and <a href=\"https://twitter.com/jd92wang?ref_src=twsrc%5Etfw\">@jd92wang</a><br />\ud83d\ude80SciEvo: A 2 Million, 30-Year Cross-disciplinary Dataset for Temporal Scientometric Analysis <a href=\"https://t.co/Md8OI4IDty\">pic.twitter.com/Md8OI4IDty</a></p>\n<p>&mdash; Yiqiao Jin @EMNLP2024 (@AhrenJin) <a href=\"https://twitter.com/AhrenJin/status/1896955263548277075?ref_src=twsrc%5Etfw\">March 4, 2025</a></p></blockquote>\n<p> </p>\n<blockquote class=\"twitter-tweet\">\n<p dir=\"ltr\" lang=\"en\">Happy to be here at <a href=\"https://twitter.com/RealAAAI?ref_src=twsrc%5Etfw\">@RealAAAI</a> with folks from <a href=\"https://twitter.com/KStateEngg?ref_src=twsrc%5Etfw\">@KStateEngg</a> to meet up with our research partners from <a href=\"https://twitter.com/imageomics?ref_src=twsrc%5Etfw\">@imageomics</a>, colleagues new to us such as <a href=\"https://twitter.com/mohitban47?ref_src=twsrc%5Etfw\">@mohitban47</a>, and longtime mentors such as the great Maria Gini! Good to see work by other <a href=\"https://twitter.com/KState?ref_src=twsrc%5Etfw\">@kstate</a> researchers here too. <a href=\"https://twitter.com/hashtag/AAAI2025?src=hash&amp;ref_src=twsrc%5Etfw\">#AAAI2025</a> <a href=\"https://twitter.com/hashtag/AAAI25?src=hash&amp;ref_src=twsrc%5Etfw\">#AAAI25</a> <a href=\"https://t.co/iOBP1CxROP\">pic.twitter.com/iOBP1CxROP</a></p>\n<p>&mdash; William Hsu @ AAAI 2025 (@banazir) <a href=\"https://twitter.com/banazir/status/1896570373342470569?ref_src=twsrc%5Etfw\">March 3, 2025</a></p></blockquote>\n<p> </p>\n<blockquote class=\"bluesky-embed\">\n<p lang=\"en\">Learning in games usually assumes small action spaces. This afternoon at #AAAI2025 we give an oral presentation showing that the PDCoEA co-evolutionary algorithm finds the Nash Equilibrium of the game below (2^n actions) in expected poly(n) time. Joint work with Shishen Lin.</p>\n<p><a href=\"https://bsky.app/profile/did:plc:o6q4olofb6bdpcnr4fdfxoue/post/3ljb6424xnk27?ref_src=embed\">[image or embed]</a></p>\n<p>&mdash; Per Kristian Lehre (<a href=\"https://bsky.app/profile/did:plc:o6q4olofb6bdpcnr4fdfxoue?ref_src=embed\">@pklehre.bsky.social</a>) <a href=\"https://bsky.app/profile/did:plc:o6q4olofb6bdpcnr4fdfxoue/post/3ljb6424xnk27?ref_src=embed\">28 February 2025 at 14:43</a></p></blockquote>\n<p></p>\n<blockquote class=\"twitter-tweet\">\n<p dir=\"ltr\" lang=\"fr\"><a href=\"https://twitter.com/hashtag/AAAI2025?src=hash&amp;ref_src=twsrc%5Etfw\">#AAAI2025</a> </p>\n<p>\ud83d\udce2 Deployable AI <a href=\"https://twitter.com/RealAAAI?ref_src=twsrc%5Etfw\">@RealAAAI</a><br />\u2b50 <a href=\"https://twitter.com/dai_workshop?ref_src=twsrc%5Etfw\">@dai_workshop</a> <br />\ud83d\uddd3\ufe0f March 3, 2025<br />\ud83d\udccdRoom 120A, Pennsylvania Convention Center <br />\ud83d\udd17<a href=\"https://t.co/fTqbOyi1c8\">https://t.co/fTqbOyi1c8</a><a href=\"https://twitter.com/ravi_iitm?ref_src=twsrc%5Etfw\">@ravi_iitm</a><br /> <a href=\"https://twitter.com/RAHULVASH?ref_src=twsrc%5Etfw\">@rahulvash</a><br /> <a href=\"https://twitter.com/danish037?ref_src=twsrc%5Etfw\">@danish037</a><br /> <a href=\"https://twitter.com/AdtRaghunathan?ref_src=twsrc%5Etfw\">@AdtRaghunathan</a><br /> <a href=\"https://twitter.com/KrishnaPillutla?ref_src=twsrc%5Etfw\">@KrishnaPillutla</a><a href=\"https://twitter.com/rbc_dsai_iitm?ref_src=twsrc%5Etfw\">@rbc_dsai_iitm</a><br /> <a href=\"https://twitter.com/hashtag/AI?src=hash&amp;ref_src=twsrc%5Etfw\">#AI</a> <a href=\"https://twitter.com/hashtag/ML?src=hash&amp;ref_src=twsrc%5Etfw\">#ML</a> <a href=\"https://twitter.com/hashtag/LLMs?src=hash&amp;ref_src=twsrc%5Etfw\">#LLMs</a> <a href=\"https://twitter.com/hashtag/AIEthics?src=hash&amp;ref_src=twsrc%5Etfw\">#AIEthics</a> <a href=\"https://twitter.com/hashtag/AIForSocialImpact?src=hash&amp;ref_src=twsrc%5Etfw\">#AIForSocialImpact</a> <a href=\"https://t.co/K3vNNUQQYH\">pic.twitter.com/K3vNNUQQYH</a></p>\n<p>&mdash; Arpita Biswas (@arpitabiswas777) <a href=\"https://twitter.com/arpitabiswas777/status/1896197538132447346?ref_src=twsrc%5Etfw\">March 2, 2025</a></p></blockquote>\n<p> </p>\n<blockquote class=\"bluesky-embed\">\n<p lang=\"en\">If you&#x27;re at #AAAI2025, come check out our demo on neurosymbolic reinforcement learning with probabilistic logic shields \ud83e\udd16 Tomorrow (Sat, March 1) from 12:30\u20132:30 PM during the poster session \ud83d\udcbb</p>\n<p><a href=\"https://bsky.app/profile/did:plc:giqvriil6vden6v5wrtw72jd/post/3ljbiqjexy22r?ref_src=embed\">[image or embed]</a></p>\n<p>&mdash; Gabriele Venturato (<a href=\"https://bsky.app/profile/did:plc:giqvriil6vden6v5wrtw72jd?ref_src=embed\">@gabventurato.bsky.social</a>) <a href=\"https://bsky.app/profile/did:plc:giqvriil6vden6v5wrtw72jd/post/3ljbiqjexy22r?ref_src=embed\">28 February 2025 at 17:53</a></p></blockquote>\n<p></p>\n<blockquote class=\"twitter-tweet\">\n<p dir=\"ltr\" lang=\"en\">Honored to have participated in <a href=\"https://twitter.com/hashtag/AAAI2025?src=hash&amp;ref_src=twsrc%5Etfw\">#AAAI2025</a> and to have met the inspiring <a href=\"https://twitter.com/AndrewYNg?ref_src=twsrc%5Etfw\">@AndrewYNg</a> and many other AI pioneers. Grateful for the insightful discussions and exciting collaborations ahead! <a href=\"https://twitter.com/hashtag/AI?src=hash&amp;ref_src=twsrc%5Etfw\">#AI</a> <a href=\"https://twitter.com/hashtag/AAAI2025?src=hash&amp;ref_src=twsrc%5Etfw\">#AAAI2025</a> <a href=\"https://t.co/ljkSQ4z0OR\">pic.twitter.com/ljkSQ4z0OR</a></p>\n<p>&mdash; Ali Alqahtani (@AliAlqahtani14) <a href=\"https://twitter.com/AliAlqahtani14/status/1895712171956584767?ref_src=twsrc%5Etfw\">March 1, 2025</a></p></blockquote>\n<p> </p>\n<blockquote class=\"twitter-tweet\">\n<p dir=\"ltr\" lang=\"en\">I'll be giving an invited talk on our <a href=\"https://twitter.com/hashtag/LearnLM?src=hash&amp;ref_src=twsrc%5Etfw\">#LearnLM</a> efforts to improve <a href=\"https://twitter.com/hashtag/Gemini?src=hash&amp;ref_src=twsrc%5Etfw\">#Gemini</a> for learning at the iRAISE workshop <a href=\"https://t.co/xCVg9DbtOD\">https://t.co/xCVg9DbtOD</a> tomorrow, come stop by if you are at <a href=\"https://twitter.com/hashtag/AAAI2025?src=hash&amp;ref_src=twsrc%5Etfw\">#AAAI2025</a> in Philadelphia!<br />Read more in our latest tech report: <a href=\"https://t.co/3kqwG3TbQD\">https://t.co/3kqwG3TbQD</a> <a href=\"https://t.co/OXo432SQZO\">pic.twitter.com/OXo432SQZO</a></p>\n<p>&mdash; Lisa Wang (@lisawang1010) <a href=\"https://twitter.com/lisawang1010/status/1896306574416884042?ref_src=twsrc%5Etfw\">March 2, 2025</a></p></blockquote>\n<p> </p>\n<blockquote class=\"bluesky-embed\">\n<p lang=\"en\">Thanks to everyone who came to my #AAAI2025 award talk on Saturday. I was gratified to see so many of the people I know and respect in the audience.. \ud83d\ude4f\ud83e\udd17 </p>\n<p>Here is a recording if you are interested.. \ud83d\udc49<br />\nwww.youtube.com/watch?v=CQ5J&#8230;</p>\n<p><a href=\"https://bsky.app/profile/did:plc:pug4wfnm4cmjosacpcveur5x/post/3ljimzeyh5c2u?ref_src=embed\">[image or embed]</a></p>\n<p>&mdash;  Subbarao Kambhampati (\u0c15\u0c02\u0c2d\u0c02\u0c2a\u0c3e\u0c1f\u0c3f \u0c38\u0c41\u0c2c\u0c4d\u0c2c\u0c3e\u0c30\u0c3e\u0c35\u0c41) (<a href=\"https://bsky.app/profile/did:plc:pug4wfnm4cmjosacpcveur5x?ref_src=embed\">@rao2z.bsky.social</a>) <a href=\"https://bsky.app/profile/did:plc:pug4wfnm4cmjosacpcveur5x/post/3ljimzeyh5c2u?ref_src=embed\">3 March 2025 at 18:58</a></p></blockquote>\n<p></p>\n<blockquote class=\"twitter-tweet\">\n<p dir=\"ltr\" lang=\"en\">At <a href=\"https://twitter.com/adjiboussodieng?ref_src=twsrc%5Etfw\">@adjiboussodieng</a>\u2019s talk \u201cVendi-RAG: Adaptively Trading-Off Diversity And Quality Significantly Improves Retrieval Augmented Generation With LLMs\u201d in 2nd <a href=\"https://twitter.com/imageomics?ref_src=twsrc%5Etfw\">@imageomics</a> workshop at <a href=\"https://twitter.com/RealAAAI?ref_src=twsrc%5Etfw\">@RealAAAI</a> <a href=\"https://twitter.com/hashtag/AAAI2025?src=hash&amp;ref_src=twsrc%5Etfw\">#AAAI2025</a> <a href=\"https://twitter.com/hashtag/AAAI25?src=hash&amp;ref_src=twsrc%5Etfw\">#AAAI25</a> W40:<a href=\"https://twitter.com/hashtag/AnomalyDetection?src=hash&amp;ref_src=twsrc%5Etfw\">#AnomalyDetection</a>, Rm 118C. <a href=\"https://twitter.com/NSF?ref_src=twsrc%5Etfw\">@NSF</a> <a href=\"https://twitter.com/hashtag/HDR?src=hash&amp;ref_src=twsrc%5Etfw\">#HDR</a> page: <a href=\"https://t.co/HzY9avIrEv\">https://t.co/HzY9avIrEv</a> <a href=\"https://t.co/ZuONPBohbB\">https://t.co/ZuONPBohbB</a> <a href=\"https://t.co/hjw7UF5Pqb\">pic.twitter.com/hjw7UF5Pqb</a></p>\n<p>&mdash; William Hsu @ AAAI 2025 (@banazir) <a href=\"https://twitter.com/banazir/status/1896976161600889089?ref_src=twsrc%5Etfw\">March 4, 2025</a></p></blockquote>\n<p> </p>\n<blockquote class=\"bluesky-embed\">\n<p lang=\"en\">\n<p><a href=\"https://bsky.app/profile/did:plc:fqiqm5sa27qwkkl5kdkdn5mp/post/3ljdcirqm422q?ref_src=embed\">[image or embed]</a></p>\n<p>&mdash; AIhub.org (<a href=\"https://bsky.app/profile/did:plc:fqiqm5sa27qwkkl5kdkdn5mp?ref_src=embed\">@aihub.org</a>) <a href=\"https://bsky.app/profile/did:plc:fqiqm5sa27qwkkl5kdkdn5mp/post/3ljdcirqm422q?ref_src=embed\">1 March 2025 at 11:07</a></p></blockquote>\n<p></p>\n<blockquote class=\"twitter-tweet\">\n<p dir=\"ltr\" lang=\"en\">Just attended Multi-Agent Workshop at AAAI 2025 and it's hands down the best workshop I've been to at AAAI! It was buzzing and truly inspiring.<br />Huge shoutout to the organizers (<a href=\"https://twitter.com/shi_weiyan?ref_src=twsrc%5Etfw\">@shi_weiyan</a> <a href=\"https://twitter.com/raphaelshu?ref_src=twsrc%5Etfw\">@raphaelshu</a>) for putting together such an unforgettable experience! <a href=\"https://twitter.com/hashtag/AAAI2025?src=hash&amp;ref_src=twsrc%5Etfw\">#AAAI2025</a> <a href=\"https://t.co/pPQyRIMe8z\">pic.twitter.com/pPQyRIMe8z</a></p>\n<p>&mdash; Rob Tang (@XiangruTang) <a href=\"https://twitter.com/XiangruTang/status/1897040414240280757?ref_src=twsrc%5Etfw\">March 4, 2025</a></p></blockquote>\n<p> </p>\n<blockquote class=\"bluesky-embed\">\n<p lang=\"en\">@rebeccasaxe.bsky.social giving an informative and thought-provoking talk on theory of mind at the #aaai2025 workshop on Advancing Artificial Intelligence through Theory of Mind (ToM4AI).</p>\n<p><a href=\"https://bsky.app/profile/did:plc:pztd2hhwdferc2idb2zf7bz2/post/3lji7s3jubc2a?ref_src=embed\">[image or embed]</a></p>\n<p>&mdash; Elena Zheleva (<a href=\"https://bsky.app/profile/did:plc:pztd2hhwdferc2idb2zf7bz2?ref_src=embed\">@elenadata.bsky.social</a>) <a href=\"https://bsky.app/profile/did:plc:pztd2hhwdferc2idb2zf7bz2/post/3lji7s3jubc2a?ref_src=embed\">3 March 2025 at 15:02</a></p></blockquote>\n<p></p>\n<blockquote class=\"bluesky-embed\">\n<p lang=\"en\">Congratulations to our DTAI researchers for presenting their work at #AAAI2025 #AAAI25 Lennert De Smet, Dimos Tsouros, Liesbeth Allein, Jaron Maene, David Depot,<br />\nIgnace Bleukx.</p>\n<p><a href=\"https://bsky.app/profile/did:plc:c7iwhsfd2zremzdzeoty2hqo/post/3ljlmi766gs2u?ref_src=embed\">[image or embed]</a></p>\n<p>&mdash; DTAI &#8211; KU Leuven (<a href=\"https://bsky.app/profile/did:plc:c7iwhsfd2zremzdzeoty2hqo?ref_src=embed\">@dtai-kuleuven.bsky.social</a>) <a href=\"https://bsky.app/profile/did:plc:c7iwhsfd2zremzdzeoty2hqo/post/3ljlmi766gs2u?ref_src=embed\">4 March 2025 at 23:27</a></p></blockquote>\n<p></p>\n<blockquote class=\"twitter-tweet\">\n<p dir=\"ltr\" lang=\"en\">the first of (hopefully) many conference presentations \ud83d\ude42\u200d\u2194\ufe0f <a href=\"https://twitter.com/hashtag/AAAI25?src=hash&amp;ref_src=twsrc%5Etfw\">#AAAI25</a> <a href=\"https://t.co/8l62KB4Moc\">pic.twitter.com/8l62KB4Moc</a></p>\n<p>&mdash; Akshit (@akshitwt) <a href=\"https://twitter.com/akshitwt/status/1896020992876847408?ref_src=twsrc%5Etfw\">March 2, 2025</a></p></blockquote>\n<p> </p>\n<blockquote class=\"twitter-tweet\">\n<p dir=\"ltr\" lang=\"en\">Absolutely thrilled to be able host this alumni dinner for our Teamcore research group at <a href=\"https://twitter.com/hashtag/AAAI2025?src=hash&amp;ref_src=twsrc%5Etfw\">#AAAI2025</a>. It was (and it continues to be) an honor to have mentored so many professors! And it is fantastic to see everyone's progress in their careers. <a href=\"https://t.co/UZtpvKXWLd\">pic.twitter.com/UZtpvKXWLd</a></p>\n<p>&mdash; Milind Tambe (@MilindTambe_AI) <a href=\"https://twitter.com/MilindTambe_AI/status/1896390548615012841?ref_src=twsrc%5Etfw\">March 3, 2025</a></p></blockquote>\n<p> </p>"
                }
            ]
        },
        {
            "title": "Visualizing nanoparticle dynamics using AI-based method",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "https://aihub.org/feed/",
                "value": "Visualizing nanoparticle dynamics using AI-based method"
            },
            "links": [
                {
                    "rel": "alternate",
                    "type": "text/html",
                    "href": "https://aihub.org/2025/03/04/visualizing-nanoparticle-dynamics-using-ai-based-method/"
                }
            ],
            "link": "https://aihub.org/2025/03/04/visualizing-nanoparticle-dynamics-using-ai-based-method/",
            "authors": [
                {
                    "name": "Cornell University"
                }
            ],
            "author": "Cornell University",
            "author_detail": {
                "name": "Cornell University"
            },
            "published": "Tue, 04 Mar 2025 13:46:01 +0000",
            "published_parsed": [
                2025,
                3,
                4,
                13,
                46,
                1,
                1,
                63,
                0
            ],
            "tags": [
                {
                    "term": "articles",
                    "scheme": null,
                    "label": null
                },
                {
                    "term": "quick read",
                    "scheme": null,
                    "label": null
                }
            ],
            "id": "https://aihub.org/?p=17041",
            "guidislink": false,
            "summary": "Static image taken from video (shown below). Left: a platinum nanoparticle imaged via electron microscopy. Right: using AI-based method to remove the noise. By Patricia Waldron A team of scientists has developed a method to illuminate the dynamic behavior of nanoparticles. The work, reported in Visualizing Nanoparticle Surface Dynamics and Instabilities Enabled by Deep Denoising, [&#8230;]",
            "summary_detail": {
                "type": "text/html",
                "language": null,
                "base": "https://aihub.org/feed/",
                "value": "Static image taken from video (shown below). Left: a platinum nanoparticle imaged via electron microscopy. Right: using AI-based method to remove the noise. By Patricia Waldron A team of scientists has developed a method to illuminate the dynamic behavior of nanoparticles. The work, reported in Visualizing Nanoparticle Surface Dynamics and Instabilities Enabled by Deep Denoising, [&#8230;]"
            },
            "content": [
                {
                    "type": "text/html",
                    "language": null,
                    "base": "https://aihub.org/feed/",
                    "value": "<p><img alt=\"\" class=\"aligncenter size-full wp-image-17046\" height=\"332\" src=\"https://aihub.org/wp-content/uploads/2025/03/nanoparticles.png\" width=\"672\" /><em>Static image taken from video (shown below). Left: a platinum nanoparticle imaged via electron microscopy. Right: using AI-based method to remove the noise.</em></p>\n<p><strong>By Patricia Waldron</strong></p>\n<p>A team of scientists has developed a method to illuminate the dynamic behavior of nanoparticles. The work, reported in <a href=\"https://www.science.org/doi/10.1126/science.ads2688\"><em>Visualizing Nanoparticle Surface Dynamics and Instabilities Enabled by Deep Denoising</em></a>, in the journal <em>Science</em>, combines artificial intelligence with electron microscopy to render visuals of how these tiny bits of matter respond to stimuli. </p>\n<p>\u201cThe nature of changes in the particle is exceptionally diverse, including fluxional periods, manifesting as rapid changes in atomic structure, particle shape, and orientation; understanding these dynamics requires new statistical tools,\u201d said <a href=\"https://davidsmatteson.com/\">David S. Matteson</a> (Cornell University), one of the paper\u2019s authors. \u201cThis study introduces a new statistic that utilizes topological data analysis to both quantify fluxionality and to track the stability of particles as they transition between ordered and disordered states.\u201d </p>\n<div class=\"keep-aspect\"></div>\n<p>\n<em>On the left, a platinum nanoparticle imaged via electron microscopy displays individual atoms but is heavily corrupted by noise. The image on the right shows the results of an AI system that effectively removes the noise to reveal the atomic structure of the nanoparticle.</em></p>\n<p>The work, which also included researchers from New York University, Arizona State University and the University of Iowa, blends electron microscopy with AI to enable scientists to see the structures and movements of molecules that are one-billionth of a meter in size at an unprecedented time resolution. </p>\n<p>\u201cNanoparticle-based catalytic systems have a tremendous impact on society,\u201d said co-author Carlos Fernandez-Granda (NYU). \u201cIt is estimated that 90 percent of all manufactured products involve catalytic processes somewhere in their production chain. We have developed an artificial-intelligence method that opens a new window for the exploration of atomic-level structural dynamics in materials.\u201d </p>\n<p>Observing the movement of atoms on a nanoparticle is crucial to understand functionality in industrial applications. The problem is that the atoms are barely visible in the data, so scientists cannot be sure how they are behaving\u2014the equivalent of tracking objects in a video taken at night with an old camera. To address this challenge, the paper\u2019s authors trained a deep neural network that is able to \u201clight up\u201d the electron-microscope images, revealing the underlying atoms and their dynamic behavior. </p>\n<p>\u201cElectron microscopy can capture images at a high spatial resolution, but because of the velocity at which the atomic structure of nanoparticles changes during chemical reactions, we need to gather data at a very high speed to understand their functionality,\u201d said co-author Peter A. Crozier (Arizona State University). </p>\n<p>\u201cThis results in extremely noisy measurements. We have developed an artificial-intelligence method that learns how to remove this noise\u2014automatically\u2014enabling the visualization of key atomic-level dynamics.\u201d </p>\n<p>The research was supported by grants from the National Science Foundation.</p>"
                }
            ]
        },
        {
            "title": "Forthcoming machine learning and AI seminars: March 2025 edition",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "https://aihub.org/feed/",
                "value": "Forthcoming machine learning and AI seminars: March 2025 edition"
            },
            "links": [
                {
                    "rel": "alternate",
                    "type": "text/html",
                    "href": "https://aihub.org/2025/03/03/forthcoming-machine-learning-and-ai-seminars-march-2025-edition/"
                }
            ],
            "link": "https://aihub.org/2025/03/03/forthcoming-machine-learning-and-ai-seminars-march-2025-edition/",
            "authors": [
                {
                    "name": "Lucy Smith"
                }
            ],
            "author": "Lucy Smith",
            "author_detail": {
                "name": "Lucy Smith"
            },
            "published": "Mon, 03 Mar 2025 12:11:46 +0000",
            "published_parsed": [
                2025,
                3,
                3,
                12,
                11,
                46,
                0,
                62,
                0
            ],
            "tags": [
                {
                    "term": "education",
                    "scheme": null,
                    "label": null
                },
                {
                    "term": "seminars",
                    "scheme": null,
                    "label": null
                }
            ],
            "id": "https://aihub.org/?p=17019",
            "guidislink": false,
            "summary": "This post contains a list of the AI-related seminars that are scheduled to take place between 3 March and 30 April 2025. All events detailed here are free and open for anyone to attend virtually. 3 March 2025 Pareto sensitivity, most-changing sub-fronts, and optimal knee solutions Speaker: Luis Nunes Vicente (Lehigh University) Organised by: Association [&#8230;]",
            "summary_detail": {
                "type": "text/html",
                "language": null,
                "base": "https://aihub.org/feed/",
                "value": "This post contains a list of the AI-related seminars that are scheduled to take place between 3 March and 30 April 2025. All events detailed here are free and open for anyone to attend virtually. 3 March 2025 Pareto sensitivity, most-changing sub-fronts, and optimal knee solutions Speaker: Luis Nunes Vicente (Lehigh University) Organised by: Association [&#8230;]"
            },
            "content": [
                {
                    "type": "text/html",
                    "language": null,
                    "base": "https://aihub.org/feed/",
                    "value": "<img alt=\"laptop and notebook\" class=\"alignnone size-full wp-image-3904\" height=\"853\" src=\"https://aihub.org/wp-content/uploads/2020/10/laptop-2558666_1280.jpg\" width=\"1280\" />\n<p>This post contains a list of the AI-related seminars that are scheduled to take place between 3 March and 30 April 2025. All events detailed here are free and open for anyone to attend virtually.</p>\n<h5>3 March 2025</h5>\n<p><strong><a href=\"https://euroorml.euro-online.org/\">Pareto sensitivity, most-changing sub-fronts, and optimal knee solutions</a></strong><br />\n<em>Speaker:</em> Luis Nunes Vicente (Lehigh University)<br />\n<em>Organised by:</em> Association of European Operational Research Societies<br />\nTo receive the seminar link, sign up to the <a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfogMhfxX_2P0Jr1mDLnGi6vjkqY2iEg7-74SnQcUF10BgTjA/viewform\">mailing list</a>.</p>\n<p><strong><a href=\"https://vanderbiltml.github.io/\">Title to be confirmed</a></strong><br />\n<em>Speaker:</em> Maximilian Nickel (Meta AI)<br />\n<em>Organised by:</em> Vanderbilt University<br />\nCheck the <a href=\"https://groups.google.com/forum/#!forum/vanderbiltmlss/join\">Google group</a> for Zoom instructions.</p>\n<p><strong><a href=\"https://memento.epfl.ch/event/ic-colloquium-unsupervised-discovery-of-interpre-2/\">Unsupervised Discovery of Interpretable Structure in Complex Systems</a></strong><br />\n<em>Speaker:</em> Mark Hamilton (MIT/Microsoft)<br />\n<em>Organised by:</em> EPFL<br />\nZoom link is <a href=\"https://epfl.zoom.us/j/68600056278\">here</a>.</p>\n<h5>4 March 2025</h5>\n<p><strong><a href=\"https://memento.epfl.ch/event/seminar-by-derek-van-tilborg-molecular-deep-learni/\">Unsupervised Discovery of Interpretable Structure in Complex Systems</a></strong><br />\n<em>Speaker:</em> Derek van Tilborg (Eindhoven University of Technology)<br />\n<em>Organised by:</em> EPFL<br />\nZoom link is <a href=\"https://epfl.zoom.us/j/68447908297?pwd=OU5JUGJUSUhZc0ZNYjQ2WENvYINRdz09\">here</a>.</p>\n<p><strong><a href=\"https://cse.umn.edu/ima/data-science-seminars\">Ridge analysis of time-frequency representations in the presence of Noise</a></strong><br />\n<em>Speaker:</em> Hau-Tieng Wu (New York University)<br />\n<em>Organised by:</em> University of Minnesota<br />\nZoom registration is <a href=\"https://umn.zoom.us/webinar/register/WN_rMEuZUmeQCOUFCCxsY_aGA\">here</a>.</p>\n<h5>5 March 2025</h5>\n<p><strong><a href=\"https://www.oxford-aiethics.ox.ac.uk/event/ethics-ai-lunchtime-research-seminars-hybrid-oxford-remote\">Online Public Shaming, the Duties of Social Media Platforms, and the Case for Regulation</a></strong><br />\n<em>Speaker:</em> Paul Billingham<br />\n<em>Organised by:</em> Institute for Ethics in AI, University of Oxford<br />\nRegister <a href=\"https://forms.office.com/Pages/ResponsePage.aspx?id=G96VzPWXk0-0uv5ouFLPkUbXexlJuMhCiksodiLwh4ZUMTkwUU5ZQk0xVEJKQUQ5REhDWTdWM0dQSi4u\">here</a></p>\n<h5>6 March 2025</h5>\n<p><strong><a href=\"https://sml-fin.github.io/\">Rethinking Mutual Fund Performance: From Traditional Alpha to Achievable Alpha</a></strong><br />\n<em>Speaker:</em> Alberto Mart\u00edn-Utrera (Iowa State University)<br />\n<em>Organised by:</em> Statistics and Machine Learning in Finance, University of Oxford<br />\nJoin the <a href=\"mailto:smlfin-subscribe@maillist.ox.ac.uk\">mailing list</a> to receive notifications about the seminar series.</p>\n<p><strong><a href=\"https://www.ri.se/en/learningmachinesseminars/learning-machines-seminars-upcoming-seminars\">Title to be confirmed</a></strong><br />\n<em>Speaker:</em> Atakan Aral (University of Vienna)<br />\n<em>Organised by:</em> RISE (Research Institutes of Sweden)<br />\nRegister <a href=\"https://www.ri.se/en/learningmachinesseminars/learning-machines-seminars-upcoming-seminars\">here</a> nearer the time.</p>\n<h5>10 March 2025</h5>\n<p><strong><a href=\"https://euroorml.euro-online.org/\">Concepts from cooperative game theory for feature selection</a></strong><br />\n<em>Speaker:</em> Marleen Balvert (Tilburg University)<br />\n<em>Organised by:</em> Association of European Operational Research Societies<br />\nTo receive the seminar link, sign up to the <a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfogMhfxX_2P0Jr1mDLnGi6vjkqY2iEg7-74SnQcUF10BgTjA/viewform\">mailing list</a>.</p>\n<h5>11 March 2025</h5>\n<p><strong><a href=\"https://www.raspberrypi.org/research/seminars\">Developing data awareness: Understanding and navigating the data-driven world</a></strong><br />\n<em>Speakers:</em> Lukas H\u00f6per and Carsten Schulte (Paderborn University)<br />\n<em>Organised by:</em> Raspberry PI<br />\nSign up <a href=\"https://form.raspberrypi.org/f/research-seminar-sign-up\">here</a> to join.</p>\n<h5>12 March 2025</h5>\n<p><strong><a href=\"https://xaiseminars.doc.ic.ac.uk/\">Title to be confirmed</a></strong><br />\n<em>Speaker:</em> Elena Musi<br />\n<em>Organised by:</em> Imperial College London<br />\nSign up <a href=\"https://xaiseminars.doc.ic.ac.uk/\">here</a>.</p>\n<h5>13 March 2025</h5>\n<p><strong><a href=\"https://psolsson.github.io/AI4ScienceSeminar\">Explaining and controlling turbulent flows through deep learning</a></strong><br />\n<em>Speaker:</em> Ricardo Vinuesa (KTH)<br />\n<em>Organised by:</em> Chalmers AI4Science<br />\nZoom link is <a href=\"https://chalmers.zoom.us/j/69511234676\">here</a>. Password: ai4science.</p>\n<p><strong><a href=\"https://www.ri.se/en/learningmachinesseminars/learning-machines-seminars-upcoming-seminars\">Title to be confirmed</a></strong><br />\n<em>Speaker:</em> Sherrie Wang (MIT)<br />\n<em>Organised by:</em> RISE (Research Institutes of Sweden)<br />\nRegister <a href=\"https://www.ri.se/en/learningmachinesseminars/learning-machines-seminars-upcoming-seminars\">here</a> nearer the time.</p>\n<p><strong><a href=\"https://sml-fin.github.io/\">Assessing Market Beta Estimates</a></strong><br />\n<em>Speaker:</em> Matthijs Lof (Aalto University)<br />\n<em>Organised by:</em> Statistics and Machine Learning in Finance, University of Oxford<br />\nJoin the <a href=\"mailto:smlfin-subscribe@maillist.ox.ac.uk\">mailing list</a> to receive notifications about the seminar series.</p>\n<h5>17 March 2025</h5>\n<p><strong><a href=\"https://vanderbiltml.github.io/\">Title to be confirmed</a></strong><br />\n<em>Speaker:</em> Eric Nalisnick (Johns Hopkins University)<br />\n<em>Organised by:</em> Vanderbilt University<br />\nCheck the <a href=\"https://groups.google.com/forum/#!forum/vanderbiltmlss/join\">Google group</a> for Zoom instructions.</p>\n<p><strong><a href=\"https://euroorml.euro-online.org/\">Offline Reinforcement Learning for Combinatorial Optimization: A Data-Driven End-to-End Approach to Job Shop Scheduling</a></strong><br />\n<em>Speaker:</em> Yingqian Zhang (Eindhoven University of Technology)<br />\n<em>Organised by:</em> Association of European Operational Research Societies<br />\nTo receive the seminar link, sign up to the <a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfogMhfxX_2P0Jr1mDLnGi6vjkqY2iEg7-74SnQcUF10BgTjA/viewform\">mailing list</a>.</p>\n<h5>18 March 2025</h5>\n<p><strong><a href=\"https://cse.umn.edu/ima/data-science-seminars\">Title to be confirmed</a></strong><br />\n<em>Speaker:</em> Misha Belkin (UCSD)<br />\n<em>Organised by:</em> University of Minnesota<br />\nCheck the <a href=\"https://cse.umn.edu/ima/data-science-seminars\">website</a> nearer the time for the Zoom link.</p>\n<p><strong><a href=\"https://www.cs.cmu.edu/~aiseminar/\">Title to be confirmed</a></strong><br />\n<em>Speaker:</em> Alexander Goldberg (Carnegie Mellon University)<br />\n<em>Organised by:</em> Carnegie Mellon University<br />\nZoom link is <a href=\"https://cmu.zoom.us/j/99510233317?pwd=ZGx4aExNZ1FNaGY4SHI3Qlh0YjNWUT09\">here</a>.</p>\n<p><strong><a href=\"https://memento.epfl.ch/event/ai-center-x-lsi-lab-seminar-artificial-intelligenc/\">Artificial Intelligence for Musicians</a></strong><br />\n<em>Speaker:</em> Kristen Yeon-Ji Yun and Yung-Hsiang Lu (Purdue University)<br />\n<em>Organised by:</em> EPFL<br />\nZoom link is <a href=\"https://epfl.zoom.us/j/66775348578\">here</a>.</p>\n<h5>21 March 2025</h5>\n<p><strong><a href=\"https://aixia.it/incontri/spotlight-seminars-on-ai-winter-2025/\">Title to be confirmed</a></strong><br />\n<em>Speaker:</em> Alessio Lomuscio (Imperial College London)<br />\n<em>Organised by:</em> Italian Association for Artificial Intelligence<br />\nWatch live on YouTube <a href=\"https://www.youtube.com/c/AIxIAit\">here</a>.</p>\n<h5>24 March 2025</h5>\n<p><strong><a href=\"https://euroorml.euro-online.org/\">Linear and nonlinear learning of optimization problems</a></strong><br />\n<em>Speaker:</em> Coralia Cartis (University of Oxford)<br />\n<em>Organised by:</em> Association of European Operational Research Societies<br />\nTo receive the seminar link, sign up to the <a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfogMhfxX_2P0Jr1mDLnGi6vjkqY2iEg7-74SnQcUF10BgTjA/viewform\">mailing list</a>.</p>\n<h5>25 March 2025</h5>\n<p><strong><a href=\"https://cse.umn.edu/ima/data-science-seminars\">Reduced-order moment closure models for uncertainty quantification and data assimilation</a></strong><br />\n<em>Speaker:</em> Di Qi (Purdue)<br />\n<em>Organised by:</em> University of Minnesota<br />\nZoom registration is <a href=\"https://umn.zoom.us/webinar/register/WN_NWbnzuzIQ52NwWWsnB_aTg\">here</a>.</p>\n<p><strong><a href=\"https://www.chalmers.se/en/current/calendar/\">AI Ethics: AI Alignment vs. AI Ethical Treatment \u2013 Ten Challenges</a></strong><br />\n<em>Speaker:</em> Bradford Saad<br />\n<em>Organised by:</em> Chalmers University of Technology<br />\nZoom registration link is <a href=\"https://ui.ungpd.com/Surveys/e92da180-9095-4c6c-9c27-1b6cdfcc4338\">here</a>.</p>\n<h5>26 March 2025</h5>\n<p><strong><a href=\"https://xaiseminars.doc.ic.ac.uk/\">Title to be confirmed</a></strong><br />\n<em>Speaker:</em> Andr\u00e9 Freitas<br />\n<em>Organised by:</em> Imperial College London<br />\nSign up <a href=\"https://xaiseminars.doc.ic.ac.uk/\">here</a>.</p>\n<h5>27 March 2025</h5>\n<p><strong><a href=\"https://www.ri.se/en/learningmachinesseminars/learning-machines-seminars-upcoming-seminars\">Title to be confirmed</a></strong><br />\n<em>Speaker:</em> Mar\u00eda J. Molina (University of Maryland)<br />\n<em>Organised by:</em> RISE (Research Institutes of Sweden)<br />\nRegister <a href=\"https://www.ri.se/en/learningmachinesseminars/learning-machines-seminars-upcoming-seminars\">here</a> nearer the time.</p>\n<h5>31 March 2025</h5>\n<p><strong><a href=\"https://euroorml.euro-online.org/\">Feature selection in linear Support Vector Machines via a hard cardinality constraint: a scalable conic decomposition approach</a></strong><br />\n<em>Speaker:</em> Laura Palagi (Sapienza University of Rome)<br />\n<em>Organised by:</em> Association of European Operational Research Societies<br />\nTo receive the seminar link, sign up to the <a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfogMhfxX_2P0Jr1mDLnGi6vjkqY2iEg7-74SnQcUF10BgTjA/viewform\">mailing list</a>.</p>\n<p><strong><a href=\"https://vanderbiltml.github.io/\">Title to be confirmed</a></strong><br />\n<em>Speaker:</em> Nuno Moniz (University of Notre Dame)<br />\n<em>Organised by:</em> Vanderbilt University<br />\nCheck the <a href=\"https://groups.google.com/forum/#!forum/vanderbiltmlss/join\">Google group</a> for Zoom instructions.</p>\n<h5>1 April 2025</h5>\n<p><strong><a href=\"https://cse.umn.edu/ima/data-science-seminars\">Title to be confirmed</a></strong><br />\n<em>Speaker:</em> Vakhtang Poutkaradze (University of Alberta)<br />\n<em>Organised by:</em> University of Minnesota<br />\nCheck the <a href=\"https://cse.umn.edu/ima/data-science-seminars\">website</a> nearer the time for Zoom registration.</p>\n<h5>3 April 2025</h5>\n<p><strong><a href=\"https://www.ri.se/en/learningmachinesseminars/learning-machines-seminars-upcoming-seminars\">Title to be confirmed</a></strong><br />\n<em>Speaker:</em> Abdul Shaamala (Queensland University of Technology)<br />\n<em>Organised by:</em> RISE (Research Institutes of Sweden)<br />\nRegister <a href=\"https://www.ri.se/en/learningmachinesseminars/learning-machines-seminars-upcoming-seminars\">here</a> nearer the time.</p>\n<h5>7 April 2025</h5>\n<p><strong><a href=\"https://xaiseminars.doc.ic.ac.uk/\">Title to be confirmed</a></strong><br />\n<em>Speaker:</em> Lei You<br />\n<em>Organised by:</em> Imperial College London<br />\nSign up <a href=\"https://xaiseminars.doc.ic.ac.uk/\">here</a>.</p>\n<p><strong><a href=\"https://euroorml.euro-online.org/\">Deep generative models in stochastic optimization</a></strong><br />\n<em>Speaker:</em> David Pisinger (Technical University of Denmark)<br />\n<em>Organised by:</em> Association of European Operational Research Societies<br />\nTo receive the seminar link, sign up to the <a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfogMhfxX_2P0Jr1mDLnGi6vjkqY2iEg7-74SnQcUF10BgTjA/viewform\">mailing list</a>.</p>\n<h5>8 April 2025</h5>\n<p><strong><a href=\"https://memento.epfl.ch/event/pcsl-x-ai-center-seminar-ai-for-science-series-d-4/\">AI for Science series</a></strong><br />\n<em>Speaker:</em> Oliver Dicks (University of British Columbia)<br />\n<em>Organised by:</em> EPFL<br />\nZoom link is <a href=\"https://epfl.zoom.us/j/65942852644?pwd=yqwO8MbnDAw59TwqCeZ0gMKEaA2cli.1\">here</a>.</p>\n<p><strong><a href=\"https://cse.umn.edu/ima/data-science-seminars\">Title to be confirmed</a></strong><br />\n<em>Speaker:</em> Joan Bruna (NYU Courant Institute)<br />\n<em>Organised by:</em> University of Minnesota<br />\nCheck the <a href=\"https://cse.umn.edu/ima/data-science-seminars\">website</a> nearer the time for Zoom registration.</p>\n<p><strong><a href=\"https://www.raspberrypi.org/research/seminars\">Situating high school data science in the lives of students</a></strong><br />\n<em>Speakers:</em> David Weintrop, Rotem Israel-Fishelson and Peter F. Moon (University of Maryland)<br />\n<em>Organised by:</em> Raspberry PI<br />\nSign up <a href=\"https://form.raspberrypi.org/f/research-seminar-sign-up\">here</a> to join.</p>\n<h5>10 April 2025</h5>\n<p><strong><a href=\"https://psolsson.github.io/AI4ScienceSeminar\">Controlling Diffusion Models at Inference Time</a></strong><br />\n<em>Speaker:</em> Kirill Neklyudov (MILA and Universit\u00e9 de Montr\u00e9al)<br />\n<em>Organised by:</em> Chalmers AI4Science<br />\nZoom link is <a href=\"https://chalmers.zoom.us/j/68110757499\">here</a>. Password: ai4science.</p>\n<h5>15 April 2025</h5>\n<p><strong><a href=\"https://cse.umn.edu/ima/data-science-seminars\">Title to be confirmed</a></strong><br />\n<em>Speaker:</em> Yuejie Chi (Carnegie Mellon University)<br />\n<em>Organised by:</em> University of Minnesota<br />\nCheck the <a href=\"https://cse.umn.edu/ima/data-science-seminars\">website</a> nearer the time for Zoom registration.</p>\n<h5>22 April 2025</h5>\n<p><strong><a href=\"https://cse.umn.edu/ima/data-science-seminars\">Title to be confirmed</a></strong><br />\n<em>Speaker:</em> Matt Jacobs (UC Santa Barbara)<br />\n<em>Organised by:</em> University of Minnesota<br />\nCheck the <a href=\"https://cse.umn.edu/ima/data-science-seminars\">website</a> nearer the time for Zoom registration.</p>\n<h5>24 April 2025</h5>\n<p><strong><a href=\"https://www.ri.se/en/learningmachinesseminars/learning-machines-seminars-upcoming-seminars\">Title to be confirmed</a></strong><br />\n<em>Speaker:</em> John Martinsson (RISE and Lund University)<br />\n<em>Organised by:</em> RISE (Research Institutes of Sweden)<br />\nRegister <a href=\"https://www.ri.se/en/learningmachinesseminars/learning-machines-seminars-upcoming-seminars\">here</a> nearer the time.</p>\n<h5>29 April 2025</h5>\n<p><strong><a href=\"https://euroorml.euro-online.org/\">Title to be confirmed</a></strong><br />\n<em>Speaker:</em> Jean-Michel Loubes<br />\n<em>Organised by:</em> Association of European Operational Research Societies<br />\nTo receive the seminar link, sign up to the <a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfogMhfxX_2P0Jr1mDLnGi6vjkqY2iEg7-74SnQcUF10BgTjA/viewform\">mailing list</a>.</p>\n<p><strong><a href=\"https://cse.umn.edu/ima/data-science-seminars\">Title to be confirmed</a></strong><br />\n<em>Speaker:</em> Gal Mishne (UCSD)<br />\n<em>Organised by:</em> University of Minnesota<br />\nCheck the <a href=\"https://cse.umn.edu/ima/data-science-seminars\">website</a> nearer the time for Zoom registration.</p>\n<h5>30 April 2025</h5>\n<p><strong><a href=\"https://xaiseminars.doc.ic.ac.uk/\">Title to be confirmed</a></strong><br />\n<em>Speaker:</em> Jesus Renero<br />\n<em>Organised by:</em> Imperial College London<br />\nSign up <a href=\"https://xaiseminars.doc.ic.ac.uk/\">here</a>.</p>\n<hr />\n<p>To see past and forthcoming events for 2024 and 2025, please see our dedicated <a href=\"https://aihub.org/seminars-2024/\">2024 and 2025 seminar page</a>.</p>\n<p>If you&#8217;d like to visit the webpages of the universities and other organisations that are running regular programmes of seminars, then <a href=\"https://aihub.org/seminar-series/\">click here</a> to see our list. </p>\n<p>If you are aware of any seminars (both standalone and series) that we\u2019ve missed then please just <a href=\"mailto:aihuborg@gmail.com\">send us an email</a> and we\u2019ll add them to the list. </p>"
                }
            ]
        },
        {
            "title": "Congratulations to the #AAAI2025 outstanding paper award winners",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "https://aihub.org/feed/",
                "value": "Congratulations to the #AAAI2025 outstanding paper award winners"
            },
            "links": [
                {
                    "rel": "alternate",
                    "type": "text/html",
                    "href": "https://aihub.org/2025/03/01/congratulations-to-the-aaai2025-outstanding-paper-award-winners/"
                }
            ],
            "link": "https://aihub.org/2025/03/01/congratulations-to-the-aaai2025-outstanding-paper-award-winners/",
            "authors": [
                {
                    "name": "Lucy Smith"
                }
            ],
            "author": "Lucy Smith",
            "author_detail": {
                "name": "Lucy Smith"
            },
            "published": "Sat, 01 Mar 2025 16:05:48 +0000",
            "published_parsed": [
                2025,
                3,
                1,
                16,
                5,
                48,
                5,
                60,
                0
            ],
            "tags": [
                {
                    "term": "news",
                    "scheme": null,
                    "label": null
                },
                {
                    "term": "AAAI",
                    "scheme": null,
                    "label": null
                },
                {
                    "term": "AAAI2025",
                    "scheme": null,
                    "label": null
                },
                {
                    "term": "quick read",
                    "scheme": null,
                    "label": null
                }
            ],
            "id": "https://aihub.org/?p=17010",
            "guidislink": false,
            "summary": "The AAAI 2025 outstanding paper awards were announced during the opening ceremony of the 39th Annual AAAI Conference on Artificial Intelligence on Thursday 27 February. These awards honour papers that &#8220;exemplify the highest standards in technical contribution and exposition&#8221;. Papers are recommended for consideration during the review process by members of the Program Committee. This [&#8230;]",
            "summary_detail": {
                "type": "text/html",
                "language": null,
                "base": "https://aihub.org/feed/",
                "value": "The AAAI 2025 outstanding paper awards were announced during the opening ceremony of the 39th Annual AAAI Conference on Artificial Intelligence on Thursday 27 February. These awards honour papers that &#8220;exemplify the highest standards in technical contribution and exposition&#8221;. Papers are recommended for consideration during the review process by members of the Program Committee. This [&#8230;]"
            },
            "content": [
                {
                    "type": "text/html",
                    "language": null,
                    "base": "https://aihub.org/feed/",
                    "value": "<img alt=\"\" class=\"aligncenter size-full wp-image-17011\" height=\"1920\" src=\"https://aihub.org/wp-content/uploads/2025/02/IMG_20250225_112855-scaled.jpg\" width=\"2560\" />\n<p>The <a href=\"https://aaai.org/conference/aaai/aaai-25/\">AAAI 2025</a> outstanding paper awards were announced during the opening ceremony of the <a href=\"https://aaai.org/conference/aaai/aaai-25/\">39th Annual AAAI Conference on Artificial Intelligence</a> on Thursday 27 February. These awards honour papers that <em>&#8220;exemplify the highest standards in technical contribution and exposition&#8221;</em>. Papers are recommended for consideration during the review process by members of the Program Committee. This year, three papers have been selected as <em>outstanding papers</em>, with a further paper being recognised in the special track on AI for social impact.</p>\n<h3>AAAI-25 outstanding papers</h3>\n<p><strong>Every Bit Helps: Achieving the Optimal Distortion with a Few Queries</strong><br />\n<em>Soroush Ebadian and Nisarg Shah</em></p>\n<p><strong>Abstract:</strong> A fundamental task in multi-agent systems is to match <img alt=\"&#110;\" class=\"ql-img-inline-formula quicklatex-auto-format\" height=\"8\" src=\"https://aihub.org/wp-content/ql-cache/quicklatex.com-b170995d512c659d8668b4e42e1fef6b_l3.png\" style=\"vertical-align: 0px;\" title=\"Rendered by QuickLaTeX.com\" width=\"11\" /> agents to <img alt=\"&#110;\" class=\"ql-img-inline-formula quicklatex-auto-format\" height=\"8\" src=\"https://aihub.org/wp-content/ql-cache/quicklatex.com-b170995d512c659d8668b4e42e1fef6b_l3.png\" style=\"vertical-align: 0px;\" title=\"Rendered by QuickLaTeX.com\" width=\"11\" /> alternatives (e.g., resources or tasks). Often, this is accomplished by eliciting agents&#8217; ordinal rankings over the alternatives instead of their exact numerical utilities. While this simplifies elicitation, the incomplete information leads to inefficiency, captured by a worst-case measure called <em>distortion</em>. A recent line of work shows that making just a few queries to each agent regarding their cardinal utility for an alternative can significantly improve the distortion, with [1] achieving <img alt=\"&#79;&#40;&#92;&#115;&#113;&#114;&#116;&#123;&#110;&#125;&#41;\" class=\"ql-img-inline-formula quicklatex-auto-format\" height=\"19\" src=\"https://aihub.org/wp-content/ql-cache/quicklatex.com-5acb50a62ea598682039b672c14075a9_l3.png\" title=\"Rendered by QuickLaTeX.com\" width=\"52\" /> distortion with two queries per agent. We generalize their result by achieving <img alt=\"&#79;&#40;&#110;&#94;&#123;&#49;&#47;&#92;&#108;&#97;&#109;&#98;&#100;&#97;&#125;&#41;\" class=\"ql-img-inline-formula quicklatex-auto-format\" height=\"21\" src=\"https://aihub.org/wp-content/ql-cache/quicklatex.com-0341b1681687fd06438464c37485c074_l3.png\" title=\"Rendered by QuickLaTeX.com\" width=\"60\" /> distortion with <img alt=\"&#92;&#108;&#97;&#109;&#98;&#100;&#97;\" class=\"ql-img-inline-formula quicklatex-auto-format\" height=\"12\" src=\"https://aihub.org/wp-content/ql-cache/quicklatex.com-2b5c45836864531b8e37025dabadd24a_l3.png\" style=\"vertical-align: 0px;\" title=\"Rendered by QuickLaTeX.com\" width=\"10\" /> queries per agent, for any constant <img alt=\"&#92;&#108;&#97;&#109;&#98;&#100;&#97;\" class=\"ql-img-inline-formula quicklatex-auto-format\" height=\"12\" src=\"https://aihub.org/wp-content/ql-cache/quicklatex.com-2b5c45836864531b8e37025dabadd24a_l3.png\" style=\"vertical-align: 0px;\" title=\"Rendered by QuickLaTeX.com\" width=\"10\" />, which is optimal given a previous lower bound by [2]. We also extend our finding to the general social choice problem, where one of <img alt=\"&#109;\" class=\"ql-img-inline-formula quicklatex-auto-format\" height=\"8\" src=\"https://aihub.org/wp-content/ql-cache/quicklatex.com-6b41df788161942c6f98604d37de8098_l3.png\" style=\"vertical-align: 0px;\" title=\"Rendered by QuickLaTeX.com\" width=\"15\" /> alternatives must be chosen based on the preferences of <img alt=\"&#110;\" class=\"ql-img-inline-formula quicklatex-auto-format\" height=\"8\" src=\"https://aihub.org/wp-content/ql-cache/quicklatex.com-b170995d512c659d8668b4e42e1fef6b_l3.png\" style=\"vertical-align: 0px;\" title=\"Rendered by QuickLaTeX.com\" width=\"11\" /> agents, and show that <img alt=\"&#79;&#40;&#40;&#92;&#109;&#105;&#110;&#92;&#123;&#110;&#44;&#109;&#92;&#125;&#41;&#94;&#123;&#49;&#47;&#92;&#108;&#97;&#109;&#98;&#100;&#97;&#125;&#41;\" class=\"ql-img-inline-formula quicklatex-auto-format\" height=\"21\" src=\"https://aihub.org/wp-content/ql-cache/quicklatex.com-8284e096356f52655253f265fab2f0f4_l3.png\" title=\"Rendered by QuickLaTeX.com\" width=\"145\" /> distortion can be achieved with <img alt=\"&#92;&#108;&#97;&#109;&#98;&#100;&#97;\" class=\"ql-img-inline-formula quicklatex-auto-format\" height=\"12\" src=\"https://aihub.org/wp-content/ql-cache/quicklatex.com-2b5c45836864531b8e37025dabadd24a_l3.png\" style=\"vertical-align: 0px;\" title=\"Rendered by QuickLaTeX.com\" width=\"10\" /> queries per agent, for any constant <img alt=\"&#92;&#108;&#97;&#109;&#98;&#100;&#97;\" class=\"ql-img-inline-formula quicklatex-auto-format\" height=\"12\" src=\"https://aihub.org/wp-content/ql-cache/quicklatex.com-2b5c45836864531b8e37025dabadd24a_l3.png\" style=\"vertical-align: 0px;\" title=\"Rendered by QuickLaTeX.com\" width=\"10\" />, which is also optimal given prior results. Thus, for both problems, our work settles open questions regarding the optimal distortion achievable using a fixed number of cardinal value queries.</p>\n<p>Read the paper in full <a href=\"https://www.cs.toronto.edu/~nisarg/papers/value-queries.pdf\">here</a>.</p>\n<hr />\n<p><strong>Efficient Rectification of Neuro-Symbolic Reasoning Inconsistencies by Abductive Reflection</strong><br />\n<em>Wen-Chao Hu, Yuan Jiang, Zhi-Hua Zhou, Wang-Zhou Dai</em></p>\n<p><strong>Abstract:</strong> Neuro-Symbolic (NeSy) AI could be regarded as an analogy to human dual-process cognition, modeling the intuitive System 1 with neural networks and the algorithmic System 2 with symbolic reasoning. However, for complex learning targets, NeSy systems often generate outputs inconsistent with domain knowledge and it is challenging to rectify them. Inspired by the human Cognitive Reflection, which promptly detects errors in our intuitive response and revises them by invoking the System 2 reasoning, we propose to improve NeSy systems by introducing Abductive Reflection (ABL-Refl) based on the Abductive Learning (ABL) framework. ABL-Refl leverages domain knowledge to abduce a reflection vector during training, which can then flag potential errors in the neural network outputs and invoke abduction to rectify them and generate consistent outputs during inference. ABL-Refl is highly efficient in contrast to previous ABL implementations. Experiments show that ABL-Refl outperforms state-of-the-art NeSy methods, achieving excellent accuracy with fewer training resources and enhanced efficiency.</p>\n<p>Read the paper in full <a href=\"https://arxiv.org/abs/2412.08457\">here</a>.</p>\n<hr />\n<p><strong>Revelations: A Decidable Class of POMDPs with Omega-Regular Objectives</strong><br />\n<em>Marius Belly, Nathana&euml;l Fijalkow, Hugo Gimbert, Florian Horn, Guillermo Perez, Pierre Vandenhove</em></p>\n<p><strong>Abstract:</strong> Partially observable Markov decision processes (POMDPs) form a prominent model for uncertainty in sequential decision making. We are interested in constructing algorithms with theoretical guarantees to determine whether the agent has a strategy ensuring a given specification with probability 1. This well-studied problem is known to be undecidable already for very simple omega-regular objectives, because of the difficulty of reasoning on uncertain events. We introduce a revelation mechanism which restricts information loss by requiring that almost surely the agent has eventually full information of the current state. Our main technical results are to construct exact algorithms for two classes of POMDPs called weakly and strongly revealing. Importantly, the decidable cases reduce to the analysis of a finite belief-support Markov decision process. This yields a conceptually simple and exact algorithm for a large class of POMDPs.</p>\n<p>Read the paper in full <a href=\"https://arxiv.org/abs/2412.12063\">here</a>.</p>\n<hr />\n<h3>AAAI-25 outstanding paper &#8211; special track on AI for social impact (AISI)</h3>\n<p><strong>DivShift: Exploring Domain-Specific Distribution Shifts in Large-Scale, Volunteer-Collected Biodiversity Datasets</strong><br />\n<em> Elena Sierra, Teja Katterborn, Salim Soltani, Lauren Gillespie, Mois\u00e9s Exp\u00f3sito-Alonso</em></p>\n<p><strong>Abstract:</strong> Large-scale, volunteer-collected datasets of community-identified natural world imagery like iNaturalist have enabled marked performance gains for fine-grained visual classification of plant species using deep learning models. However, such datasets are opportunistic and lack a structured sampling strategy. Resulting geographic, temporal, observation quality, and socioeconomic biases inherent to this volunteer-based participatory data collection process are stymieing the wide uptake of these models for downstream biodiversity monitoring tasks, especially in the Global South. While widely documented in biodiversity modeling literature, the impact of these biases&#8217; downstream distribution shift on deep learning models have not been rigorously quantified. Here we introduce Diversity Shift (DivShift), a framework for quantifying the effects of biodiversity domain-specific distribution shifts on deep learning model performance. We also introduce DivShift &#8211; West Coast Plant (DivShift-WCP), a new curated dataset of almost 8 million iNaturalist plant observations across the western coast of North America, for diagnosing the effects of these biases in a controlled case study. Using this new dataset, we contrast computer vision model performance across a variety of these shifts and observe that these biases indeed confound model performance across observation quality, spatial location, and political boundaries. Interestingly, we find for all partitions that accuracy is lower than expected by chance from estimates of dataset shift from the data themselves, implying the structure within natural world images provides significant generalization improvements. From these observations, we suggest recommendations training computer vision models on natural world imagery biodiversity collections.</p>\n<p>Read the paper in full <a href=\"https://arxiv.org/abs/2410.19816\">here</a>. </p>\n<hr />"
                }
            ]
        },
        {
            "title": "#AAAI2025 social media round-up: part one",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "https://aihub.org/feed/",
                "value": "#AAAI2025 social media round-up: part one"
            },
            "links": [
                {
                    "rel": "alternate",
                    "type": "text/html",
                    "href": "https://aihub.org/2025/02/28/aaai2025-social-media-round-up-part-one/"
                }
            ],
            "link": "https://aihub.org/2025/02/28/aaai2025-social-media-round-up-part-one/",
            "authors": [
                {
                    "name": "Lucy Smith"
                }
            ],
            "author": "Lucy Smith",
            "author_detail": {
                "name": "Lucy Smith"
            },
            "published": "Fri, 28 Feb 2025 18:40:22 +0000",
            "published_parsed": [
                2025,
                2,
                28,
                18,
                40,
                22,
                4,
                59,
                0
            ],
            "tags": [
                {
                    "term": "opinions",
                    "scheme": null,
                    "label": null
                },
                {
                    "term": "AAAI",
                    "scheme": null,
                    "label": null
                },
                {
                    "term": "AAAI2025",
                    "scheme": null,
                    "label": null
                },
                {
                    "term": "quick read",
                    "scheme": null,
                    "label": null
                }
            ],
            "id": "https://aihub.org/?p=16986",
            "guidislink": false,
            "summary": "The 39th Annual AAAI Conference on Artificial Intelligence (AAAI 2025) is currently in full swing in Philadelphia. So far, delegates have been treated to tutorials, the first few of the invited talks, and an exciting variety of oral and poster presentations. We take a look at what attendees have been getting up to during the [&#8230;]",
            "summary_detail": {
                "type": "text/html",
                "language": null,
                "base": "https://aihub.org/feed/",
                "value": "The 39th Annual AAAI Conference on Artificial Intelligence (AAAI 2025) is currently in full swing in Philadelphia. So far, delegates have been treated to tutorials, the first few of the invited talks, and an exciting variety of oral and poster presentations. We take a look at what attendees have been getting up to during the [&#8230;]"
            },
            "content": [
                {
                    "type": "text/html",
                    "language": null,
                    "base": "https://aihub.org/feed/",
                    "value": "<img alt=\"\" class=\"aligncenter size-full wp-image-17002\" height=\"1920\" src=\"https://aihub.org/wp-content/uploads/2025/02/IMG_20250226_095217-scaled.jpg\" width=\"2560\" />\n<p>The <a href=\"https://aaai.org/conference/aaai/aaai-25/\">39th Annual AAAI Conference on Artificial Intelligence (AAAI 2025)</a> is currently in full swing in Philadelphia. So far, delegates have been treated to tutorials, the first few of the invited talks, and an exciting variety of oral and poster presentations. We take a look at what attendees have been getting up to during the opening days of the event.</p>\n<blockquote class=\"twitter-tweet\">\n<p dir=\"ltr\" lang=\"en\">I'll be presenting our <a href=\"https://twitter.com/hashtag/AAAI2025?src=hash&amp;ref_src=twsrc%5Etfw\">#AAAI2025</a> tutorial tomorrow on &quot;Symbolic Regression: Towards Interpretability and Automated Scientific Discovery&quot;! <a href=\"https://t.co/UcSNYyrkAe\">https://t.co/UcSNYyrkAe</a></p>\n<p>If you're attending AAAI-25 and are interested to learn more about symbolic regression and its potential in\u2026 <a href=\"https://t.co/yaeCpcPoQI\">pic.twitter.com/yaeCpcPoQI</a></p>\n<p>&mdash; Parshin Shojaee (@ParshinShojaee) <a href=\"https://twitter.com/ParshinShojaee/status/1894579768059703743?ref_src=twsrc%5Etfw\">February 26, 2025</a></p></blockquote>\n<p> </p>\n<blockquote class=\"bluesky-embed\">\n<p lang=\"en\">I am at @realaaai.bsky.social #AAAI25 in sunny #Philadelphia \ud83c\udf1e </p>\n<p>reach out if you want to grab coffee and chat about #probabilistic #ML #AI #nesy #neurosymbolic #tensor #lowrank models!</p>\n<p>check out our tutorial<br />\n\ud83d\udc49 april-tools.github.io/aaai25-tf-pc&#8230;</p>\n<p>and workshop<br />\n\ud83d\udc49 april-tools.github.io/colorai/</p>\n<p><a href=\"https://bsky.app/profile/did:plc:tjz32e76br3krn4qnuznklpi/post/3liz6qwku5s2n?ref_src=embed\">[image or embed]</a></p>\n<p>&mdash; antonio vergari \ud83e\udd68 hiring PhD students (<a href=\"https://bsky.app/profile/did:plc:tjz32e76br3krn4qnuznklpi?ref_src=embed\">@nolovedeeplearning.bsky.social</a>) <a href=\"https://bsky.app/profile/did:plc:tjz32e76br3krn4qnuznklpi/post/3liz6qwku5s2n?ref_src=embed\">25 February 2025 at 10:33</a></p></blockquote>\n<p></p>\n<blockquote class=\"twitter-tweet\">\n<p dir=\"ltr\" lang=\"en\">Poster sessions are underway at <a href=\"https://twitter.com/RealAAAI?ref_src=twsrc%5Etfw\">@RealAAAI</a>. Lots of great conversations between attendees and potential collaborations for the future! <a href=\"https://twitter.com/hashtag/AAAI2025?src=hash&amp;ref_src=twsrc%5Etfw\">#AAAI2025</a> <a href=\"https://t.co/kMEot4SWSY\">pic.twitter.com/kMEot4SWSY</a></p>\n<p>&mdash; CAIHu (@CAIHuAAAI) <a href=\"https://twitter.com/CAIHuAAAI/status/1894504616529662086?ref_src=twsrc%5Etfw\">February 25, 2025</a></p></blockquote>\n<p> </p>\n<blockquote class=\"bluesky-embed\">\n<p lang=\"en\">Very excited about this tutorial at #AAAI2025 on inducing privacy, fairness or robustness to distribution shifts when data is imperfect (e.g. unlabeled, noisy)! You can check out the slides at amartya18x.github.io/files/Tutori&#8230;</p>\n<p><a href=\"https://bsky.app/profile/did:plc:k6xxiqhktz64irdddxqjqpbl/post/3liyv6fi4as2q?ref_src=embed\">[image or embed]</a></p>\n<p>&mdash; alext2.bsky.social (<a href=\"https://bsky.app/profile/did:plc:k6xxiqhktz64irdddxqjqpbl?ref_src=embed\">@alext2.bsky.social</a>) <a href=\"https://bsky.app/profile/did:plc:k6xxiqhktz64irdddxqjqpbl/post/3liyv6fi4as2q?ref_src=embed\">25 February 2025 at 07:42</a></p></blockquote>\n<p></p>\n<blockquote class=\"bluesky-embed\">\n<p lang=\"en\">Off to #AAAI25! We&#x27;re presenting #SatCLIP (w/ @marccoru.bsky.social, @estherrolf.bsky.social, @calebrob6.bsky.social &amp; @lestermackey.bsky.social) at the 12.30-2.30pm poster session on Feb 28! Let me know if you&#x27;re around &amp; want to chat #GeoAI!\ud83d\udef0\ufe0f</p>\n<p>Paper: tinyurl.com/5eejz5kw<br />\nCode: tinyurl.com/2zm64967</p>\n<p><a href=\"https://bsky.app/profile/did:plc:i6ejjgko5amsycq3mijevya5/post/3lj3lmhi2ac2r?ref_src=embed\">[image or embed]</a></p>\n<p>&mdash; Konstantin Klemmer (<a href=\"https://bsky.app/profile/did:plc:i6ejjgko5amsycq3mijevya5?ref_src=embed\">@kklmmr.bsky.social</a>) <a href=\"https://bsky.app/profile/did:plc:i6ejjgko5amsycq3mijevya5/post/3lj3lmhi2ac2r?ref_src=embed\">26 February 2025 at 09:29</a></p></blockquote>\n<p></p>\n<blockquote class=\"bluesky-embed\">\n<p lang=\"en\">Thrilled to be at #AAAI2025 for our tutorial, \u201cAI Data Transparency: The Past, Present, and Beyond.\u201d </p>\n<p>We\u2019re presenting the state of transparency, tooling, and policy, from the Foundation Model Transparency Index, Factsheets, the the EU AI Act to new frameworks like @MLCommons\u2019 Croissant.</p>\n<p>1/</p>\n<p><a href=\"https://bsky.app/profile/did:plc:evvussoazdkvsld475dfbuci/post/3lj3ybtxdmk2p?ref_src=embed\">[image or embed]</a></p>\n<p>&mdash; Shayne Longpre (<a href=\"https://bsky.app/profile/did:plc:evvussoazdkvsld475dfbuci?ref_src=embed\">@shaynelongpre.bsky.social</a>) <a href=\"https://bsky.app/profile/did:plc:evvussoazdkvsld475dfbuci/post/3lj3ybtxdmk2p?ref_src=embed\">26 February 2025 at 13:15</a></p></blockquote>\n<p></p>\n<blockquote class=\"bluesky-embed\">\n<p lang=\"en\">\ud83d\udd25 Can AI reason over time while following logical rules in relational domains? We will present Relational Neurosymbolic Markov Models (NeSy-MMs) next week at #AAAI2025! \ud83c\udf89</p>\n<p>\ud83d\udcdc Paper: arxiv.org/pdf/2412.13023<br />\n\ud83d\udcbb Code: github.com/ML-KULeuven/&#8230;</p>\n<p>\ud83e\uddf5\u2b07\ufe0f</p>\n<p><a href=\"https://bsky.app/profile/did:plc:giqvriil6vden6v5wrtw72jd/post/3liypjywfjk27?ref_src=embed\">[image or embed]</a></p>\n<p>&mdash; Gabriele Venturato (<a href=\"https://bsky.app/profile/did:plc:giqvriil6vden6v5wrtw72jd?ref_src=embed\">@gabventurato.bsky.social</a>) <a href=\"https://bsky.app/profile/did:plc:giqvriil6vden6v5wrtw72jd/post/3liypjywfjk27?ref_src=embed\">25 February 2025 at 06:01</a></p></blockquote>\n<p></p>\n<blockquote class=\"bluesky-embed\">\n<p lang=\"en\">Thank you AAAI &amp; EAAI for this honor..\ud83d\ude4f (my talk at #AAAI2025 will be on Saturday 2pm..)</p>\n<p><a href=\"https://bsky.app/profile/did:plc:pug4wfnm4cmjosacpcveur5x/post/3lj6d6otosc2k?ref_src=embed\">[image or embed]</a></p>\n<p>&mdash;  Subbarao Kambhampati (\u0c15\u0c02\u0c2d\u0c02\u0c2a\u0c3e\u0c1f\u0c3f \u0c38\u0c41\u0c2c\u0c4d\u0c2c\u0c3e\u0c30\u0c3e\u0c35\u0c41) (<a href=\"https://bsky.app/profile/did:plc:pug4wfnm4cmjosacpcveur5x?ref_src=embed\">@rao2z.bsky.social</a>) <a href=\"https://bsky.app/profile/did:plc:pug4wfnm4cmjosacpcveur5x/post/3lj6d6otosc2k?ref_src=embed\">27 February 2025 at 11:36</a></p></blockquote>\n<p></p>\n<blockquote class=\"bluesky-embed\">\n<p lang=\"en\">We&#x27;re delighted to launch our series meeting the 2025 AAAI Fellows. In the first interview, we spoke to @nsriraam.bsky.social about his career path, research on human-allied AI, reflections on changes to the AI landscape, and passion for cricket. #AAAI2025</p>\n<p><a href=\"https://bsky.app/profile/did:plc:fqiqm5sa27qwkkl5kdkdn5mp/post/3lj3m2irwz22r?ref_src=embed\">[image or embed]</a></p>\n<p>&mdash; AIhub.org (<a href=\"https://bsky.app/profile/did:plc:fqiqm5sa27qwkkl5kdkdn5mp?ref_src=embed\">@aihub.org</a>) <a href=\"https://bsky.app/profile/did:plc:fqiqm5sa27qwkkl5kdkdn5mp/post/3lj3m2irwz22r?ref_src=embed\">26 February 2025 at 09:36</a></p></blockquote>\n<p> </p>\n<blockquote class=\"bluesky-embed\">\n<p lang=\"en\">Here&#x27;s my student Sheikh Mannan drawing an audience demonstrating real-time AI task guidance in disoriented balancing. If you&#x27;re at #AAAI2025 stop by tomorrow for another (different) demo!</p>\n<p><a href=\"https://bsky.app/profile/did:plc:jpc7ukh2vroea2zxtfaaci5f/post/3lj7itx4cys26?ref_src=embed\">[image or embed]</a></p>\n<p>&mdash; Nikhil Krishnaswamy (<a href=\"https://bsky.app/profile/did:plc:jpc7ukh2vroea2zxtfaaci5f?ref_src=embed\">@nikhilkrishnaswamy.bsky.social</a>) <a href=\"https://bsky.app/profile/did:plc:jpc7ukh2vroea2zxtfaaci5f/post/3lj7itx4cys26?ref_src=embed\">27 February 2025 at 22:50</a></p></blockquote>\n<p></p>\n<blockquote class=\"bluesky-embed\">\n<p lang=\"en\">Tomorrow at #AAAI25 we are presenting our paper \u201cWhy AI is W.E.I.R.D. (Western Educated Industrialized Rich Democratic\u2014a concept from psychology) and why it shouldn\u2019t be\u201d\u2014a position paper on challenges &amp; opportunities in developing AI that works equally well for everyone\ud83c\udf0d\ud83c\udf0e\ud83c\udf0f</p>\n<p>arxiv.org/pdf/2410.16315</p>\n<p><a href=\"https://bsky.app/profile/did:plc:2da47m6ns6brz3awvwsfv55p/post/3lj4tzcrp4s24?ref_src=embed\">[image or embed]</a></p>\n<p>&mdash; Rada Mihalcea (<a href=\"https://bsky.app/profile/did:plc:2da47m6ns6brz3awvwsfv55p?ref_src=embed\">@radamihalcea.bsky.social</a>) <a href=\"https://bsky.app/profile/did:plc:2da47m6ns6brz3awvwsfv55p/post/3lj4tzcrp4s24?ref_src=embed\">26 February 2025 at 21:32</a></p></blockquote>\n<p></p>\n<blockquote class=\"bluesky-embed\">\n<p lang=\"en\">I have presented the tutorial yesterday. Thank you everyone for all your interest. I will add the slides quite soon. In the mean time you can find the papers I have discussed in my page. #AAAI2025 #AAAI25</p>\n<p>Link: ezgikorkmaz.github.io</p>\n<p><a href=\"https://bsky.app/profile/did:plc:ao7h7cm6slhpogmkoircj2ih/post/3lj6gokpmtk2j?ref_src=embed\">[image or embed]</a></p>\n<p>&mdash; Ezgi Korkmaz (<a href=\"https://bsky.app/profile/did:plc:ao7h7cm6slhpogmkoircj2ih?ref_src=embed\">@ezgikorkmaz.bsky.social</a>) <a href=\"https://bsky.app/profile/did:plc:ao7h7cm6slhpogmkoircj2ih/post/3lj6gokpmtk2j?ref_src=embed\">27 February 2025 at 12:38</a></p></blockquote>\n<p></p>\n<blockquote class=\"twitter-tweet\">\n<p dir=\"ltr\" lang=\"en\">I'm excited to announce that we'll be presenting our latest research form MIT on &quot;Co-Dream: Collaborative Dream Synthesis over Decentralized Models.&quot; at <a href=\"https://twitter.com/hashtag/AAAI2025?src=hash&amp;ref_src=twsrc%5Etfw\">#AAAI2025</a> today! <br />Check out our work and stop by our poster to discuss more!<a href=\"https://t.co/iNbZD5BCFy\">https://t.co/iNbZD5BCFy</a></p>\n<p>&mdash; Gauri Gupta (@gauri__gupta) <a href=\"https://twitter.com/gauri__gupta/status/1895208578295939165?ref_src=twsrc%5Etfw\">February 27, 2025</a></p></blockquote>\n<p> </p>\n<blockquote class=\"twitter-tweet\">\n<p dir=\"ltr\" lang=\"en\">Attending AAAI 2025 in Philly this week! We\u2019ll be presenting our work on symbolic music evaluation on Monday. Come say hi if you\u2019re here! <a href=\"https://twitter.com/RealAAAI?ref_src=twsrc%5Etfw\">@RealAAAI</a> <a href=\"https://twitter.com/hashtag/AAAI25?src=hash&amp;ref_src=twsrc%5Etfw\">#AAAI25</a> <a href=\"https://twitter.com/hashtag/AAAI?src=hash&amp;ref_src=twsrc%5Etfw\">#AAAI</a> <a href=\"https://t.co/1MlGs7HxvE\">pic.twitter.com/1MlGs7HxvE</a></p>\n<p>&mdash; Mateusz Modrzejewski @ AAAI (@mamodrzejewski) <a href=\"https://twitter.com/mamodrzejewski/status/1895507281741324540?ref_src=twsrc%5Etfw\">February 28, 2025</a></p></blockquote>\n<p> </p>\n<blockquote class=\"twitter-tweet\">\n<p dir=\"ltr\" lang=\"en\">It was lovely meeting <a href=\"https://twitter.com/feedkoko?ref_src=twsrc%5Etfw\">@feedkoko</a> \ud83d\udc9c\ud83d\udc83 at <a href=\"https://twitter.com/hashtag/AAAI2025?src=hash&amp;ref_src=twsrc%5Etfw\">#AAAI2025</a> <a href=\"https://t.co/5msozHFxfa\">pic.twitter.com/5msozHFxfa</a></p>\n<p>&mdash; Anku Rani (@anku__rani) <a href=\"https://twitter.com/anku__rani/status/1895307596422357311?ref_src=twsrc%5Etfw\">February 28, 2025</a></p></blockquote>\n<p> </p>\n<blockquote class=\"twitter-tweet\">\n<p dir=\"ltr\" lang=\"en\">Many congratulations to <a href=\"https://twitter.com/hashtag/AAAIFellow?src=hash&amp;ref_src=twsrc%5Etfw\">#AAAIFellow</a> Prof <a href=\"https://twitter.com/ravi_iitm?ref_src=twsrc%5Etfw\">@ravi_iitm</a> ! \ud83d\ude0a\ud83c\udf89<br />Proud to be working with you \ud83d\ude0a\ud83d\ude4f<a href=\"https://twitter.com/RealAAAI?ref_src=twsrc%5Etfw\">@RealAAAI</a> <a href=\"https://twitter.com/cerai_iitm?ref_src=twsrc%5Etfw\">@cerai_iitm</a> <a href=\"https://twitter.com/WSAI_IITM?ref_src=twsrc%5Etfw\">@WSAI_IITM</a> <a href=\"https://twitter.com/iitmadras?ref_src=twsrc%5Etfw\">@iitmadras</a> <a href=\"https://twitter.com/hashtag/AAAI2025?src=hash&amp;ref_src=twsrc%5Etfw\">#AAAI2025</a> <a href=\"https://twitter.com/hashtag/AAAI25?src=hash&amp;ref_src=twsrc%5Etfw\">#AAAI25</a> <a href=\"https://twitter.com/hashtag/Philadelphia?src=hash&amp;ref_src=twsrc%5Etfw\">#Philadelphia</a> <a href=\"https://t.co/XX3xuAL9iG\">pic.twitter.com/XX3xuAL9iG</a></p>\n<p>&mdash; Gokul S Krishnan (@gsk1992) <a href=\"https://twitter.com/gsk1992/status/1895281571701420510?ref_src=twsrc%5Etfw\">February 28, 2025</a></p></blockquote>\n<p> </p>\n<blockquote class=\"twitter-tweet\">\n<p dir=\"ltr\" lang=\"en\">Surprising guest at <a href=\"https://twitter.com/hashtag/AAAI25?src=hash&amp;ref_src=twsrc%5Etfw\">#AAAI25</a> at Andrew Ng\u2019s talk <a href=\"https://twitter.com/AndrewYNg?ref_src=twsrc%5Etfw\">@AndrewYNg</a> <a href=\"https://twitter.com/hashtag/agents?src=hash&amp;ref_src=twsrc%5Etfw\">#agents</a> <a href=\"https://twitter.com/hashtag/bev?src=hash&amp;ref_src=twsrc%5Etfw\">#bev</a> <a href=\"https://twitter.com/hashtag/birdseyebiew?src=hash&amp;ref_src=twsrc%5Etfw\">#birdseyebiew</a> <a href=\"https://twitter.com/hashtag/ai?src=hash&amp;ref_src=twsrc%5Etfw\">#ai</a> <a href=\"https://twitter.com/hashtag/conference?src=hash&amp;ref_src=twsrc%5Etfw\">#conference</a> <a href=\"https://t.co/Tao4F7bQH4\">pic.twitter.com/Tao4F7bQH4</a></p>\n<p>&mdash; Andrew Zhao @ AAAI 2025 (@AndrewZ45732491) <a href=\"https://twitter.com/AndrewZ45732491/status/1895474590341890392?ref_src=twsrc%5Etfw\">February 28, 2025</a></p></blockquote>\n<p> </p>"
                }
            ]
        },
        {
            "title": "Congratulations to the #AAAI2025 award winners",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "https://aihub.org/feed/",
                "value": "Congratulations to the #AAAI2025 award winners"
            },
            "links": [
                {
                    "rel": "alternate",
                    "type": "text/html",
                    "href": "https://aihub.org/2025/02/27/congratulations-to-the-aaai2025-award-winners/"
                }
            ],
            "link": "https://aihub.org/2025/02/27/congratulations-to-the-aaai2025-award-winners/",
            "authors": [
                {
                    "name": "Lucy Smith"
                }
            ],
            "author": "Lucy Smith",
            "author_detail": {
                "name": "Lucy Smith"
            },
            "published": "Thu, 27 Feb 2025 15:10:31 +0000",
            "published_parsed": [
                2025,
                2,
                27,
                15,
                10,
                31,
                3,
                58,
                0
            ],
            "tags": [
                {
                    "term": "news",
                    "scheme": null,
                    "label": null
                },
                {
                    "term": "AAAI",
                    "scheme": null,
                    "label": null
                },
                {
                    "term": "AAAI2025",
                    "scheme": null,
                    "label": null
                },
                {
                    "term": "quick read",
                    "scheme": null,
                    "label": null
                }
            ],
            "id": "https://aihub.org/?p=16938",
            "guidislink": false,
            "summary": "A number of prestigious AAAI awards were presented during the official opening ceremony of the Thirty-Ninth AAAI Conference on Artificial Intelligence (AAAI 2025) on 27 February. Some of the winners will also be giving invited talks as part of the programme. 2025 AAAI Award for Artificial Intelligence for Humanity The AAAI Award for Artificial Intelligence [&#8230;]",
            "summary_detail": {
                "type": "text/html",
                "language": null,
                "base": "https://aihub.org/feed/",
                "value": "A number of prestigious AAAI awards were presented during the official opening ceremony of the Thirty-Ninth AAAI Conference on Artificial Intelligence (AAAI 2025) on 27 February. Some of the winners will also be giving invited talks as part of the programme. 2025 AAAI Award for Artificial Intelligence for Humanity The AAAI Award for Artificial Intelligence [&#8230;]"
            },
            "content": [
                {
                    "type": "text/html",
                    "language": null,
                    "base": "https://aihub.org/feed/",
                    "value": "<p><img alt=\"trophy\" class=\"aligncenter size-full wp-image-3115\" height=\"1018\" src=\"https://aihub.org/wp-content/uploads/2020/07/trophy-3037778_1280.jpg\" width=\"1280\" /><br />\nA number of prestigious <a href=\"https://aaai.org/about-aaai/aaai-awards/\">AAAI awards</a> were presented during the official opening ceremony of the <a href=\"https://aaai.org/conference/aaai/aaai-25/\">Thirty-Ninth AAAI Conference on Artificial Intelligence (AAAI 2025)</a> on 27 February. Some of the winners will also be giving invited talks as part of the programme.</p>\n<h3><a href=\"https://aaai.org/about-aaai/aaai-awards/aaai-award-for-artificial-intelligence-for-the-benefit-of-humanity/\">2025 AAAI Award for Artificial Intelligence for Humanity</a></h3>\n<p>The AAAI Award for Artificial Intelligence for Humanity recognises the positive impacts of artificial intelligence to protect, enhance, and improve human life in meaningful ways with long-lived effects.</p>\n<p>The winner of this year\u2019s award is <strong>Stuart J. Russell</strong> (University of California, Berkeley, USA). Stuart has been recognised for <em>\u201cwork on the conceptual and theoretical foundations of provably beneficial AI and his leadership in creating the field of AI safety\u201d</em>.</p>\n<h3><a href=\"https://aaai.org/about-aaai/aaai-awards/robert-s-engelmore-memorial-lecture-award/\">2025 Robert S. Engelmore Memorial Award</a></h3>\n<p>The Robert S. Engelmore Memorial Award recognises outstanding contributions to automated planning, machine learning and robotics, their application to real-world problems and extensive service to the AI community.</p>\n<p>This year\u2019s award goes to <strong>Christoph Schuhmann</strong> (Laion e.V.) for <em>\u201cthe outstanding contribution to the AI community as the initiator and founder of LAION, the non-profit organization that provides open and free datasets, tools and models\u201d</em>.</p>\n<h3><a href=\"https://aaai.org/about-aaai/aaai-awards/aaai-feigenbaum-prize/\">AAAI Feigenbaum Prize</a></h3>\n<p>The AAAI Feigenbaum Prize is awarded biennially to recognize and encourage outstanding artificial intelligence research advances that are made by using experimental methods of computer science. </p>\n<p>The 2025 prize has been awarded to: </p>\n<ul>\n<li><strong>Thomas G. Dietterich</strong> (Oregon State University) for <em>&#8220;high-impact contributions to the field of artificial intelligence through innovations in machine learning and sequential decision-making with applications in environmental sustainability, ecosystem informatics, drug design, and intelligent desktop assistants&#8221;</em>.</li>\n<li><strong>James Hendler</strong> (Rensselaer Polytechnic Institute) for <em>&#8220;ground-breaking contributions to knowledge representation, planning, and the Semantic Web&#8221;</em>.</li>\n</ul>\n<h3><a href=\"https://aaai.org/about-aaai/aaai-awards/aaai-eaai-patrick-henry-winston-outstanding-educator-award/\">2025 AAAI/EAAI Patrick Henry Winston Outstanding Educator Award</a></h3>\n<p>The annual AAAI/EAAI Outstanding Educator award was created to honour a person (or group of people) who has made major contributions to AI education that provide long-lasting benefits to the AI community and society as a whole.</p>\n<p>The 2025 winner is <strong>Subbarao Kambhampati</strong> (Arizona State University) for <em>\u201cbroad and sustained engagement with the public on AI and its societal impact, developing widely used AI teaching materials, and being an inspirational educator, mentor and thought leader in AI.\u201d</em>.</p>\n<h3><a href=\"https://aaai.org/about-aaai/aaai-awards/aaai-distinguished-service-award/\">2025 AAAI Distinguished Service Award</a></h3>\n<p>The AAAI Distinguished Service award recognizes one individual each year for extraordinary service to the AI community.</p>\n<p>The winner this year is <strong>Yolanda Gil</strong> (University of Southern California, USA), for <em>\u201coutstanding contributions to the field of artificial intelligence through sustained service to the Association for the Advancement of Artificial Intelligence and significant leadership in broadening the research community\u201d</em>.</p>\n<h3><a href=\"https://aaai.org/about-aaai/aaai-awards/aaai-classic-paper-award/\">2025 AAAI Classic Paper Award</a></h3>\n<p>The AAAI Classic Paper award honours the author(s) of paper(s) deemed most influential, chosen from a specific conference year. The 2025 award is given to the most influential paper from the Twenty-Fourth AAAI Conference on Artificial Intelligence.</p>\n<p>The winners this year are <strong>Tom Mitchell, Andrew Carlson, Justin Betteridge, Bryan Kisiel, Burr Settles</strong> and <strong>Estevam Hruschka</strong> for their paper <em>\u201cToward an Architecture for Never-Ending Language Learning\u201d</em>.</p>\n<p>Congratulations to all of the winners! You can find out more about these awards, and the other awards that AAAI bestows <a href=\"https://aaai.org/about-aaai/aaai-awards/\">here</a>.</p>"
                }
            ]
        },
        {
            "title": "Interview with AAAI Fellow Sriraam Natarajan: Human-allied AI",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "https://aihub.org/feed/",
                "value": "Interview with AAAI Fellow Sriraam Natarajan: Human-allied AI"
            },
            "links": [
                {
                    "rel": "alternate",
                    "type": "text/html",
                    "href": "https://aihub.org/2025/02/26/interview-with-aaai-fellow-sriraam-natarajan-human-allied-ai/"
                }
            ],
            "link": "https://aihub.org/2025/02/26/interview-with-aaai-fellow-sriraam-natarajan-human-allied-ai/",
            "authors": [
                {
                    "name": "Lucy Smith"
                }
            ],
            "author": "Lucy Smith",
            "author_detail": {
                "name": "Lucy Smith"
            },
            "published": "Wed, 26 Feb 2025 14:22:07 +0000",
            "published_parsed": [
                2025,
                2,
                26,
                14,
                22,
                7,
                2,
                57,
                0
            ],
            "tags": [
                {
                    "term": "opinions",
                    "scheme": null,
                    "label": null
                },
                {
                    "term": "AAAI",
                    "scheme": null,
                    "label": null
                },
                {
                    "term": "AAAI Fellows 2025",
                    "scheme": null,
                    "label": null
                }
            ],
            "id": "https://aihub.org/?p=16944",
            "guidislink": false,
            "summary": "Each year the AAAI recognizes a group of individuals who have made significant, sustained contributions to the field of artificial intelligence by appointing them as Fellows. Over the course of the next few months, we\u2019ll be talking to some of the 2025 AAAI Fellows. In this interview we hear from Sriraam Natarajan, Professor at the [&#8230;]",
            "summary_detail": {
                "type": "text/html",
                "language": null,
                "base": "https://aihub.org/feed/",
                "value": "Each year the AAAI recognizes a group of individuals who have made significant, sustained contributions to the field of artificial intelligence by appointing them as Fellows. Over the course of the next few months, we\u2019ll be talking to some of the 2025 AAAI Fellows. In this interview we hear from Sriraam Natarajan, Professor at the [&#8230;]"
            },
            "content": [
                {
                    "type": "text/html",
                    "language": null,
                    "base": "https://aihub.org/feed/",
                    "value": "<img alt=\"\" class=\"aligncenter size-full wp-image-16946\" height=\"1366\" src=\"https://aihub.org/wp-content/uploads/2025/02/SN.jpg\" width=\"2048\" />\n<p>Each year the <a href=\"https://aaai.org/\">AAAI</a> recognizes a group of individuals who have made significant, sustained contributions to the field of artificial intelligence by appointing them as Fellows. Over the course of the next few months, we\u2019ll be talking to some of the <a href=\"https://aaai.org/about-aaai/aaai-awards/the-aaai-fellows-program/elected-aaai-fellows/\">2025 AAAI Fellows</a>. In this interview we hear from Sriraam Natarajan, Professor at the University of Texas at Dallas, who was elected as a Fellow for <em>\u201csignificant contributions to statistical relational AI, healthcare adaptations and service to the AAAI community\u201d</em>. We find out about his career path, research on human-allied AI, reflections on changes to the AI landscape, and passion for cricket.  </p>\n<p><strong>Could you start by telling us about your career so far, where you work and your broad area of research?</strong><br />\nI grew up in the southern part of India, in Chennai. It was called Madras back then, and in 2001, I graduated from the University of Madras. I moved to Oregon State University in 2001 with the goal of doing a master\u2019s in computer networking. In my first year, I was trying to explore theoretical computer science connected to networking. Then I took a grad course in artificial intelligence with Prasad Tadepalli, a Bayesian networks course with Bruce D\u2019 Ambrosio, and machine learning with Tom Dietterich, and I just fell in love with the subjects of artificial intelligence, machine learning, probabilistic models, and knowledge representation. I started taking more courses and Prasad asked me if I wanted to do a PhD in machine learning. Of course, I said yes. I finished my PhD at the end of December 2007, then moved to Wisconsin, Madison in 2008. If you read my PhD thesis, there is not a lot of reference to medicine or healthcare, but when I moved to Wisconsin, I was fortunate to work with Jude Shavlik and David Page. They were stalwarts in machine learning, but they were also looking at machine learning for medicine. I was funded from a DARPA grant, so most of my time was spent on inductive logic programming, and statistical relational learning,  but I also decided that I was going to use my evenings and weekends to do machine learning for medicine. After three years of training there, I moved to a medical school, Wake Forest School of Medicine, because I wanted to actually get my hands dirty on healthcare data. That&#8217;s where I established a lot of collaborations. I worked there for nearly three years, and then I moved to Indiana University where I helped establish the Health Informatics program. And then, because of my wife&#8217;s job situation, we moved to Dallas in 2017, and I&#8217;ve been in Dallas since then.</p>\n<p>In terms of my areas of research, these are human-allied artificial intelligence, statistical relational AI, and probabilistic graphical models with a focus in healthcare.</p>\n<p><strong>In the area of human-allied AI, could you talk about some of the projects that you are currently working on?</strong><br />\nTo give some background, at a fairly high level, with human-allied AI, we are asking whether we can elicit constraints from human experts that go beyond the data. So, can we get some sort of domain knowledge into the learning system, and also output back to the human by explaining the findings of the model in a human-understandable way?</p>\n<p>For me, there are a few problems to solve.  One project is building explainable models that can take expert knowledge as constraints, particularly in probabilistic models. We are looking at deep, tractable probabilistic models where you can do inference in a tractable manner. We ask the question of learning from these domain constraints and have a unified way of giving these constraints to tractable probabilistic models.</p>\n<p>The second project that I&#8217;m working on in this direction is the integration of planning and reinforcement learning. So, you have relational planning at a high level, which allows you to generalize and be deliberative and think about the impacts of these tasks and subtasks, and then use that information to instantiate appropriate reinforcement learning (reactive) tasks. For example, if I&#8217;m planning to, let&#8217;s say, come to London, I&#8217;m just going to book my tickets and book a hotel, make sure the professor that I&#8217;m going to meet there is available, etc. Then, at the point of execution, I sit down in my car to go to the airport. That\u2019s when I think about what route I have to take, the speed I should drive at, the angle I should turn my car, etc. These kinds of lower-level actions are done at the execution level and then you have a deliberative reasoning level which says, \u201cOK, these are high level things that we need to do\u201d. So, what we are trying to do is come up with these combinations of planning and reinforcement learning paradigms, which explicitly reason about where you have to be deliberative, and where you have to be reactive. And we have figured out ways where the human experts can provide feedback, both at the higher level and at the lower level of reinforcement learning.</p>\n<p>The third direction that I&#8217;m working on with relation to this is building systems that continuously interact with physicians. An example domain is cardiovascular health \u2013 we\u2019ve been working on this one for about 15 years now. My passion for the last eight-nine years has been working on modelling and mitigating adverse pregnancy outcomes. We&#8217;ve been building systems to see if we can model adverse outcomes such as pre-term birth, preeclampsia, hypertension, gestational diabetes and so on. How can we build models that can predict and mitigate these outcomes? Our latest funded project is on looking at neurological injuries in children. We are doing all of this in the presence of domain experts, who in our case are physicians.</p>\n<p><strong>Have you been using any of these models in the field?</strong><br />\nYes, we have been working with the doctors. For instance, we developed a model that learned the interaction between the prior risk of having gestational diabetes and the level of exercise in predicting gestational diabetes. We are now talking to the doctors to see how we can translate the findings into actionable outcomes. The same with gestational diabetes and the risk of pre-term birth. What are the interventions that we should take to avoid this? So, once we establish these interactions across cohorts, then we can provide policy advice back to the domain experts who then take it to their associations, and present these results. Hopefully, this will allow us to  make changes in the recommendations for these doctors. Deployment in healthcare is going to be slow, but it\u2019s going to have a high impact once we get there. Before deployment you want to make sure that it&#8217;s generalizable, and it\u2019s correct, and that it&#8217;s as close to reality as possible.</p>\n<img alt=\"\" class=\"aligncenter size-full wp-image-16950\" height=\"1540\" src=\"https://aihub.org/wp-content/uploads/2025/02/HAAI.png\" width=\"2445\" />\n<p><strong>At AAAI 2025, you\u2019ll be presenting a blue sky paper entitled: <a href=\"https://aihub.org/feed/\"><em>\u201cHuman-in-the-loop or AI-in-the-loop? Automate or Collaborate?\u201d</em></a>.  Could you tell us a bit about that paper and the key ideas you put forward?</strong><br />\nThe key argument in that paper is to really understand who is in control of the decision-making. One of the fears that most people have is who&#8217;s making these decisions in these systems. And the claim we are trying to make here is, for these high-risk applications &#8211; healthcare, finance, defense, security, social decisions, and so on &#8211; I think it should be the human who makes the final decision, and the AI is there to make the human\u2019s life easier. Whereas if you take a system like movie recommendation, where it is basically of lower risk, that can be an AI that makes the decision, but the human can provide constraints. You can click and say \u201cI don&#8217;t like this movie\u201d or \u201cthis is inappropriate for my kids\u201d and then that becomes information for the AI system to use to improve its model. I believe that this distinction between who is in control, whether it&#8217;s a human or AI, is extremely important for developing appropriate evaluation techniques. The argument we are making in the paper is that the current machine learning evaluations overemphasize the machine component and overlook the experts\u2019 role. And we really need to understand in many systems, particularly if the human is in control, if we are providing these systems with the appropriate evaluation metrics &#8211; are they helping humans? Which component is the most useful one? Which component is the most risky? We need to understand the depth of these evaluations before we deploy these systems in the real world. For me, the paper highlights this aspect and motivates a holistic understanding of both the problem that you are trying to work on and the solution that you are trying to deploy. I think that once we understand both of them correctly, then we can deploy the appropriate system.</p>\n<p><strong>I was interested in some of the changes in the AI research landscape that you&#8217;ve seen throughout your career.</strong><br />\nThere have been a lot of changes, particularly in the adaptation of these techniques to real problems.  When we started doing machine learning and AI, you could use a synthetic data set and that would be enough, because it was just proof of concept that we were looking for. But now, the adaptations are just amazing. The scale at which these things are operating is huge. Back then, if you got 300 examples for a particular task it was great, but now 300 million is very easy to get for some of these tasks.  We need to understand the scale and appreciate it. The applications are very wide-reaching at this point too, all the way from dental issues to insole fitting of shoes to fashion design. Back in the day we were thinking about GPS or airline ticket pricing, etc, some of these standard things where AI made a dent, but now it&#8217;s pretty much everywhere. That, to me, is fantastic.</p>\n<p>The funny thing is, back in the day, we used to think overfitting was extremely important, and I still think it&#8217;s very, very important, by the way. But now you hear all this about grokking of transformers; that&#8217;s pretty interesting, and it&#8217;s a massive change. Having said that, I want to really emphasize that many of the fundamental questions inside machine learning are still the same or very, very relevant. Overfitting, as I mentioned, and generalization are still extremely relevant in several tasks and need to be carefully addressed. The notion of continual learning or active learning has been around for close to 30 years now, and that&#8217;s still an important problem. And the interaction between learning and reasoning is something that we&#8217;ve been thinking about for 40 years. Causal models have been around since the 1980s when Judea Pearl came up with these books. In my opinion, the holy grail of AI is figuring out how to build these casual models. More importantly, is there a way we can learn from data by using some domain knowledge and how can we do this? And of course, my pet problem is how can we elicit expert knowledge and how can we provide explanations to these experts?  So, there have been a lot of changes, particularly in the scale and in the adaptations, but the fundamental questions are still valid, and they are still important, and we still are looking at those as a community.</p>\n<p><strong>I was wondering if there&#8217;s any advice you would give to PhD students or early career researchers?</strong><br />\nFirstly, I would always advise PhD students to read deeply. Some ideas are necessarily old, but in my view, they are worth their weight in gold. So, you really have to understand that just because an idea is slightly old doesn&#8217;t mean it\u2019s not valuable. Don\u2019t assume that machine learning started in 2014 and don&#8217;t just cite papers from the last five years in your papers. Understand that, when you consider a problem, you have to figure out where it fits in this history of AI and figure out why some of these older formulations are also important.</p>\n<p>Secondly, I see a lot of mental health issues because papers get rejected. Do not get dejected because of a single paper rejection. The noise at this scale is unavoidable. We do not want our models to overfit, so we should not overfit to one reviewer, or one reviewer\u2019s views of your paper. You want to understand deeply where the mistakes are and how you can fix it and improve. My request all the time to students is to not overfit to one decision. </p>\n<p>Finally, I want to emphasize, and I tell this to my students all the time, a good review is not an aggressive review &#8211; a good review means you provide constructive feedback. I do this exercise with my students where I ask them to put themselves in the position of the author and ask if the review they\u2019ve written is just unnecessarily brutal or could be rewritten in a way that is more constructive.</p>\n<p><strong>Finally, have you got any interesting hobbies or interests outside of research?</strong><br />\nI grew up in India in the 1980s, when we won the Cricket World Cup (in 1983), so cricket has been in my blood since then. So, I am an avid cricket watcher, I play cricket, but more importantly, I analyze cricket deeply. I have read about 50 biographies and autobiographies of cricketers, I have read books on the history of cricket, I own two copies of the Encyclopedia of Cricket, and so I am fully into cricket. Cricket is something that fuels me, I think that&#8217;s my passion and hobby. If I was not a machine learning researcher, I want to believe that I would have been a cricket commentator or a cricket writer or something in that space.</p>\n<p>I also love music, but I didn\u2019t have the bandwidth to learn anything formally until about two years ago. For the last two years I\u2019ve been learning South Indian classical music. There is an instrument called mridangam that I am learning to play along with my kid. The two of us are learning together, and so I am growing with him in this music. Finally, I would love to kick back and watch nature/science documentaries with my wife and kid during Friday and Saturday nights!</p>\n<h4>About Sriraam</h4>\n<table border=\"0\" cellpadding=\"10\" cellspacing=\"0\" width=\"100%\">\n<tbody>\n<tr>\n<td align=\"left\" valign=\"top\" width=\"150\">\n<img alt=\"\" class=\"aligncenter size-full wp-image-16948\" height=\"605\" src=\"https://aihub.org/wp-content/uploads/2025/02/Sriraam-headshot.jpg\" width=\"507\" />\n</td>\n<td align=\"left\" valign=\"top\">\n<p>Sriraam Natarajan is a Professor and the Director for Center for ML at the Department of Computer Science at University of Texas Dallas. He is a AAAI fellow, a hessian.AI fellow at TU Darmstadt and a RBDSCAII Distinguished Faculty Fellow at IIT Madras. His research interests lie in the field of Artificial Intelligence, with emphasis on Machine Learning, Statistical Relational Learning and AI, Reinforcement Learning, Graphical Models and Biomedical Applications. He was the program chair of AAAI 2024, the general chair of CoDS-COMAD 2024, program co-chair of SDM 2020 and ACM CoDS-COMAD 2020 conferences. He was the specialty chief editor of Frontiers in ML and AI journal, and is an associate editor of JAIR, DAMI and Big Data journals.</p>\n</td>\n</tr>\n</tbody>\n</table>"
                }
            ]
        },
        {
            "title": "AIhub monthly digest: February 2025 \u2013 kernel representation learning, fairness in machine learning, and bad practice in the publication world",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "https://aihub.org/feed/",
                "value": "AIhub monthly digest: February 2025 \u2013 kernel representation learning, fairness in machine learning, and bad practice in the publication world"
            },
            "links": [
                {
                    "rel": "alternate",
                    "type": "text/html",
                    "href": "https://aihub.org/2025/02/25/aihub-monthly-digest-february-2025-kernel-representation-learning-fairness-in-machine-learning-and-bad-practice-in-the-publication-world/"
                }
            ],
            "link": "https://aihub.org/2025/02/25/aihub-monthly-digest-february-2025-kernel-representation-learning-fairness-in-machine-learning-and-bad-practice-in-the-publication-world/",
            "authors": [
                {
                    "name": "Lucy Smith"
                }
            ],
            "author": "Lucy Smith",
            "author_detail": {
                "name": "Lucy Smith"
            },
            "published": "Tue, 25 Feb 2025 12:07:14 +0000",
            "published_parsed": [
                2025,
                2,
                25,
                12,
                7,
                14,
                1,
                56,
                0
            ],
            "tags": [
                {
                    "term": "articles",
                    "scheme": null,
                    "label": null
                },
                {
                    "term": "AAAI",
                    "scheme": null,
                    "label": null
                },
                {
                    "term": "monthly digest",
                    "scheme": null,
                    "label": null
                }
            ],
            "id": "https://aihub.org/?p=16959",
            "guidislink": false,
            "summary": "Welcome to our monthly digest, where you can catch up with any AIhub stories you may have missed, peruse the latest news, recap recent events, and more. This month, we explore kernel representation learning for time series, learn about fairness in machine learning, and tackle bad practice in the publication world. Launching our 2025 interview [&#8230;]",
            "summary_detail": {
                "type": "text/html",
                "language": null,
                "base": "https://aihub.org/feed/",
                "value": "Welcome to our monthly digest, where you can catch up with any AIhub stories you may have missed, peruse the latest news, recap recent events, and more. This month, we explore kernel representation learning for time series, learn about fairness in machine learning, and tackle bad practice in the publication world. Launching our 2025 interview [&#8230;]"
            },
            "content": [
                {
                    "type": "text/html",
                    "language": null,
                    "base": "https://aihub.org/feed/",
                    "value": "<img alt=\"Panda and tiger reading\" class=\"alignnone size-full wp-image-5105\" height=\"489\" src=\"https://aihub.org/wp-content/uploads/2021/02/Monthly-digest-image2.jpg\" width=\"718\" />\n<p>Welcome to our monthly digest, where you can catch up with any AIhub stories you may have missed, peruse the latest news, recap recent events, and more. This month, we explore kernel representation learning for time series, learn about fairness in machine learning, and tackle bad practice in the publication world.</p>\n<h4>Launching our 2025 interview series with Doctoral Consortium participants</h4>\n<p>During 2024, we spoke to thirteen of the AAAI/SIGAI Doctoral Consortium participants to find out more about their research and PhD life. Following the success of <a href=\"https://aihub.org/2024/12/20/2024-aaai-acm-sigai-doctoral-consortium-interviews-compilation/\">that series</a>, we&#8217;re back in 2025 to talk to this year&#8217;s cohort. We began the series with two great interviews, hearing from Kunpeng Xu, a final-year PhD student at Universit\u00e9 de Sherbrooke, and Kayla Boggess, who is studying for her PhD at the University of Virginia. </p>\n<ul>\n<li><a href=\"https://aihub.org/2025/02/11/interview-with-kunpeng-xu-kernel-representation-learning-for-time-series/\">Interview with Kunpeng Xu: Kernel representation learning for time series</a></li>\n<li><a href=\"https://aihub.org/2025/02/14/interview-with-kayla-boggess-explainable-ai-for-more-accessible-and-understandable-technologies/\">Interview with Kayla Boggess: Explainable AI for more accessible and understandable technologies</a></li>\n</ul>\n<h4>AAAI 2025 is underway</h4>\n<p>The <a href=\"https://aaai.org/conference/aaai/aaai-25/\">39th Annual AAAI Conference on Artificial Intelligence (AAAI 2025)</a> kicks off today with two days of tutorials and labs. The main technical programme begins on Thursday. You can find out more about the events taking place <a href=\"https://aihub.org/2025/02/19/whats-coming-up-at-aaai2025/\">here</a>. Our Senior Managing Editor, Lucy Smith, is attending the conference, so please do <a href=\"mailto:aihuborg@gmail.com\">reach out</a> if you&#8217;d like to chat about communicating your research. We&#8217;ll also be running a science communication introductory training session on Wednesday 26 February &#8211; find out more <a href=\"https://aihub.org/science-communication-for-ai-researchers-an-introduction-at-aaai2025/\">here</a>. Keep an eye out for our AAAI 2025 content &#8211; new articles will be published <a href=\"https://aihub.org/tag/aaai2025/\">here</a>.</p>\n<h4>Interview with Nisarg Shah: Understanding fairness in AI and machine learning</h4>\n<p>AIhub ambassador Kumar Kshitij Patel <a href=\"https://aihub.org/2025/02/05/interview-with-nisarg-shah-understanding-fairness-in-ai-and-machine-learning/\">caught up with Nisarg Shah</a> at the International Joint Conference on Artificial Intelligence (IJCAI). In an <a href=\"https://aihub.org/2025/02/05/interview-with-nisarg-shah-understanding-fairness-in-ai-and-machine-learning/\">insightful interview</a>, they discussed Nisarg&#8217;s research, the role of theory in machine learning research, fairness and safety guarantees, regulation, conference reviews, and advice for those just starting out on their research journey.</p>\n<h4>Bad practice in the publication world</h4>\n<p>In our <a href=\"https://aihub.org/2025/02/07/aihub-coffee-corner-bad-practice-in-the-publication-world/\">February Coffee Corner discussion</a>, AIhub trustees tackled the topic of bad practice in the sphere of publication. They talked about different aspects of bad practice they&#8217;ve encountered, and what can be done about it. </p>\n<h4>EU launches InvestAI initiative</h4>\n<p>At the Artificial Intelligence (AI) Action Summit in Paris, Commission President Ursula von der Leyen launched <a href=\"https://ec.europa.eu/commission/presscorner/detail/en/ip_25_467\">InvestAI</a>, an initiative with the aim of mobilising \u20ac200 billion for investment in AI. The <a href=\"https://cairne.eu/\">Confederation of Laboratories for Artificial Intelligence Research in Europe (CAIRNE)</a> has welcomed the investment. You can read their full response <a href=\"https://cairne.eu/wp-content/uploads/2025/02/CAIRNE-Press-Release-CERN-for-AI_19Feb25.pdf\">here</a>.</p>\n<h4>The paradoxes of depicting diversity in AI history</h4>\n<p>As part of a collaboration between <a href=\"https://betterimagesofai.org/\">Better Images of AI</a> and <a href=\"https://www.race-equality.admin.cam.ac.uk/university-diversity-fund\">Cambridge University\u2019s Diversity Fund</a>, Hanna Barakat was commissioned to create a digital collage series to depict diverse images about the learning and education of AI at Cambridge. In <a href=\"https://blog.betterimagesofai.org/hanna-barakats-image-collection-the-paradoxes-of-depicting-diversity-in-ai-history/\">this blog post</a>, she talks about her artistic process and reflections upon contributing to this collection. Hanna provides her thoughts on the challenges of creating images that communicate about AI histories and the inherent contradictions that arise when engaging in this work.</p>\n<h4>\u00a310m for UK regulators to \u2018jumpstart\u2019 AI capabilities</h4>\n<p>AI-wise it was a busy start to the month in the UK, with the government publishing two reports and announcing millions of pounds of new investments. Writing in <em>Real World Data Science</em>, Brian Tarran <a href=\"https://realworlddatascience.net/viewpoints/editors-blog/posts/2024/02/08/llms-whitepaper-response.html\">picks out some key takeaways.</a></p>\n<h4>Michael Wooldridge to be next AAAI president elect</h4>\n<p>The Association for the Advancement of Artificial Intelligence (AAAI) <a href=\"https://x.com/RealAAAI/status/1884349479832133749\">have announced</a> that Michael Wooldridge (University of Oxford, UK) will be the next President-Elect. Four Executive councillor members have also been elected to serve three-year terms, and these are: Pin-Yu Chen (IBM Research), Bistra Dilkina (University of Southern California), Sriraam Natarajan (University of Texas at Dallas), and Rosina Weber (Drexel University).</p>\n<h4>Suffering is real. AI consciousness is not</h4>\n<p>In their recent article <a href=\"https://www.techpolicy.press/suffering-is-real-ai-consciousness-is-not/\">Suffering is Real. AI Consciousness is Not</a>, David McNeill and Emily Tucker dissect what&#8217;s behind a recent open letter claiming that future AI systems could become conscious and be \u2018caused to suffer\u2019. The authors conclude their essay by pointing out that <em>&#8220;fantasizing about the potential future suffering of a chatbot is one way to deny that difficult truth at a moment in history when to actually become conscious of the suffering that so many human beings are now enduring requires real courage&#8221;</em>.</p>\n<h4>&#8220;AI granny&#8221; driving scammers up the wall</h4>\n<p>Early this month, <em>The Guardian</em> <a href=\"https://www.theguardian.com/money/2025/feb/04/ai-granny-scammers-phone-fraud\">reported on</a> an AI chatbot designed to waste scammers\u2019 time. The bot, which was given the persona of a grandmother who chats about knitting patterns and recipes for scones, was rolled out for a brief period to show what could be done to counter scammers.</p>\n<hr />\n<p><a href=\"https://aihub.org/resources/\">Our resources page</a><br />\n<a href=\"https://aihub.org/events/\">Our events page</a><br />\n<a href=\"https://aihub.org/seminars-2024/\">Seminars in 2025</a><br />\n<a href=\"https://aihub.org/tag/aaai-doctoral-consortium/\">AAAI/ACM SIGAI Doctoral Consortium interview series</a><br />\n<a href=\"https://aihub.org/tag/ai-around-the-world/\">AI around the world focus series</a><br />\n<a href=\"https://aihub.org/tag/newvoicesinai/\">New voices in AI series</a></p>"
                }
            ]
        },
        {
            "title": "Generative AI, online platforms and compensation for content: the need for a new framework",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "https://aihub.org/feed/",
                "value": "Generative AI, online platforms and compensation for content: the need for a new framework"
            },
            "links": [
                {
                    "rel": "alternate",
                    "type": "text/html",
                    "href": "https://aihub.org/2025/02/24/generative-ai-online-platforms-and-compensation-for-content-the-need-for-a-new-framework/"
                }
            ],
            "link": "https://aihub.org/2025/02/24/generative-ai-online-platforms-and-compensation-for-content-the-need-for-a-new-framework/",
            "authors": [
                {
                    "name": "The Conversation"
                }
            ],
            "author": "The Conversation",
            "author_detail": {
                "name": "The Conversation"
            },
            "published": "Mon, 24 Feb 2025 09:56:59 +0000",
            "published_parsed": [
                2025,
                2,
                24,
                9,
                56,
                59,
                0,
                55,
                0
            ],
            "tags": [
                {
                    "term": "articles",
                    "scheme": null,
                    "label": null
                }
            ],
            "id": "https://aihub.org/?p=16979",
            "guidislink": false,
            "summary": "Janet Turra &#038; Cambridge Diversity Fund / Better Images of AI / Ground Up and Spat Out / Licenced by CC-BY 4.0 By Thomas Paris, HEC Paris Business School and Pierre-Jean Benghozi, \u00c9cole polytechnique The emergence of generative artificial intelligence has put the issue of compensation for content producers back on the table. Generative AI [&#8230;]",
            "summary_detail": {
                "type": "text/html",
                "language": null,
                "base": "https://aihub.org/feed/",
                "value": "Janet Turra &#038; Cambridge Diversity Fund / Better Images of AI / Ground Up and Spat Out / Licenced by CC-BY 4.0 By Thomas Paris, HEC Paris Business School and Pierre-Jean Benghozi, \u00c9cole polytechnique The emergence of generative artificial intelligence has put the issue of compensation for content producers back on the table. Generative AI [&#8230;]"
            },
            "content": [
                {
                    "type": "text/html",
                    "language": null,
                    "base": "https://aihub.org/feed/",
                    "value": "<p><img alt=\"The image features a silver meat grinder. Going into the grinder at the top are various culturally symbolic, historical, and fun icons \u2013\u00a0such as emojis, old statutes, a computer, newspapers, an aeroplane. At the other end of the meat grinder, coming out is a sea of blue and grey icons representing chat bot responses like &#039;Let me know if this aligns with your vision&#039; in a grey chat bot message symbol. \" class=\"aligncenter size-full wp-image-16982\" height=\"1810\" src=\"https://aihub.org/wp-content/uploads/2025/02/JanetTurra-CambridgeDiversity-Fund-GroundUp-and-Spat-Out-1280x1810-1.png\" width=\"1280\" /><em><a href=\"https://betterimagesofai.org/images\">Janet Turra </a> &#038; <a href=\"https://www.race-equality.admin.cam.ac.uk/university-diversity-fund\">Cambridge Diversity Fund </a> / <a href=\"https://www.betterimagesofai.org\">Better Images of AI</a> / Ground Up and Spat Out / <a href=\"https://creativecommons.org/licenses/by/4.0/\">Licenced by CC-BY 4.0</a></em></p>\n<p><strong>By <a href=\"https://theconversation.com/profiles/thomas-paris-940955\">Thomas Paris</a>, <em><a href=\"https://theconversation.com/institutions/hec-paris-business-school-2276\">HEC Paris Business School</a></em> and <a href=\"https://theconversation.com/profiles/pierre-jean-benghozi-260036\">Pierre-Jean Benghozi</a>, <em><a href=\"https://theconversation.com/institutions/ecole-polytechnique-1659\">\u00c9cole polytechnique</a></em></strong></p>\n<p><strong>The emergence of generative artificial intelligence has put the issue of compensation for content producers back on the table.</strong></p>\n<p><strong>Generative AI offers undeniable benefits but raises familiar fears tied to disruptive technologies. In the cultural and creative sectors, concerns are mounting over the potential replacement of human creators, the erosion of artistic authenticity and risks of copyright infringement. Legal battles are already emerging worldwide, with intellectual property owners and AI developers clashing over rights. Alongside these legal and ethical concerns lies the economic question: how should revenues generated by AI be fairly distributed?</strong></p>\n<p>Copyright law <a href=\"https://www.puf.com/le-droit-dauteur-lideologie-et-le-systeme\">(<em>droits d\u2019auteur</em>)</a>, which is traditionally based on the reproduction or representation of specific works, may not be a fit for this question. Individual contributions to AI-generated outputs are often too complex to quantify, making it difficult to apply the principle of proportional remuneration, which holds that payment for an individual work is tied to the revenue it generates.</p>\n<h2>An asymmetrical relationship</h2>\n<p>The disputes surrounding generative AI echo long-standing tensions between digital platforms and content creators. Platforms such as Spotify, YouTube and TikTok dominate the music industry; Netflix and Apple lead in film and television; Steam in gaming; and Google and Meta in news media.</p>\n<p>These platforms wield enormous power in reshaping industries, influencing consumption patterns and <a href=\"https://hal.science/hal-01381220/\">establishing new power dynamics</a>. On the one hand, they amplify the reach of creative works, but on the other, they rely on an inherently unequal relationship. For example, if Spotify removes a song, the artist\u2019s reach and revenue may decline sharply, but Spotify itself is unlikely to suffer significant consequences\u2013perhaps losing a few subscribers to competitors, at most.</p>\n<h2>A Nobel Prize for platform economics</h2>\n<p>The economics of digital platforms have been <a href=\"https://www.tandfonline.com/doi/full/10.1080/14479338.2021.1965888\">widely studied</a>. This includes platforms\u2019 two-sided market structure\u2013a concept for which <a href=\"https://www.tse-fr.eu/articles/platform-competition-two-sided-markets\">economist Jean Tirole won a Nobel prize in 2014</a>. In this model, platforms act as intermediaries between two groups that benefit from each other: the more content a platform offers, the larger its audience grows, and the larger audience, in turn, attracts more content creators. This dynamic often leads to market concentration, and to platform strategies that subsidise one side to grow the other.</p>\n<p>However, most research in this area has not fully addressed the complexities of platforms\u2019 relationships with different types of content. High-value \u201cpremium\u201d content, such as live sporting events, holds a singular status compared to more common offerings. These distinctions are often overlooked, particularly when assessing the value different types of content bring to a platform\u2019s economy.</p>\n<p>This question of value is central to the conflicts between platforms and content providers, as well as the emerging disputes between AI operators and content owners. The disputes underscore the need for a new framework, as traditional tools are proving inadequate for addressing these complex issues.</p>\n<h2>The challenge of valuing content</h2>\n<p>The <a href=\"https://link.springer.com/chapter/10.1057/9781137344250_10\">news industry</a> provides a clear example of the complex relationship between platforms and content providers. News publishers worldwide have long sought compensation from platforms such as Google and Meta for featuring their content. Google, for instance, indexes news articles alongside other types of content to enhance search relevance and platform value. However, the exact contribution of news content to Google\u2019s business model is difficult to determine due to its layered, interconnected nature.</p>\n<p>Google\u2019s ecosystem relies on indexing vast amounts of content, some of which is ad-supported, while other elements\u2013such as Google News\u2013do not generate direct revenue. Additionally, data collected across Google\u2019s services improve ad targeting and search accuracy, further complicating efforts to isolate the value of specific content. </p>\n<p>Depending on user behaviour, content may either appear as a hypertext link directing users to the original publisher, or as a summary that keeps users within Google\u2019s environment. In cases where users stay on Google, the platform effectively acts as a content provider, displaying excerpts in a crowded layout in which individual contributions are unclear. When users click through, Google serves as a traffic driver, sending readers to the publisher\u2019s site. As a recommender, Google <a href=\"https://hal.science/hal-00263198/\">adds value to content</a>; as a content provider, <a href=\"https://journals.openedition.org/rei/6460\">it extracts value from it</a>. This dual role blurs the lines of compensation and also complicates efforts to determine how much an individual piece of content contributes to a platform\u2019s overall success.</p>\n<h2>A new paradigm</h2>\n<p>Print media has been particularly affected by the rise of digital platforms, which <a href=\"https://shs.cairn.info/economie-de-la-presse-a-l-ere-numerique--9782707177919\">profit significantly from news content</a>. Disputes over how to measure the value of individual articles or publishers to platforms such as Google and Meta remain unresolved.</p>\n<p>These conflicts vary by country, with outcomes influenced by legal jurisdictions, power dynamics and negotiations. Some agreements are struck only to be later challenged, while in other cases, platforms respond by <a href=\"https://pubsonline.informs.org/doi/abs/10.1287/mksc.2019.1150\">removing news content altogether</a>. Courts often avoid setting explicit guidelines on revenue sharing, leaving many questions unanswered.</p>\n<p>This uncertainty reflects a broader shift. In the platform economy, individual content, or even entire categories of content, no longer has a clear, measurable contribution to overall value. Given the importance of platforms in the economies of cultural industries, developing a new framework to address these complexities is increasingly urgent.<!-- Below is The Conversation's page counter tag. Please DO NOT REMOVE. --><img alt=\"The Conversation\" height=\"1\" src=\"https://counter.theconversation.com/content/242847/count.gif?distributor=republish-lightbox-basic\" style=\"border: none !important; margin: 0 !important; padding: 0 !important;\" width=\"1\" /><!-- End of code. If you don't see any code above, please get new code from the Advanced tab after you click the republish button. The page counter does not collect any personal data. More info: https://theconversation.com/republishing-guidelines --></p>\n<p><span><a href=\"https://theconversation.com/profiles/thomas-paris-940955\">Thomas Paris</a>, Associate professor, HEC Paris, researcher at CNRS, <em><a href=\"https://theconversation.com/institutions/hec-paris-business-school-2276\">HEC Paris Business School</a></em> and <a href=\"https://theconversation.com/profiles/pierre-jean-benghozi-260036\">Pierre-Jean Benghozi</a>, Professeur \u00e9conomie-gestion, <em><a href=\"https://theconversation.com/institutions/ecole-polytechnique-1659\">\u00c9cole polytechnique</a></em></span></p>\n<p>This article is republished from <a href=\"https://theconversation.com\">The Conversation</a> under a Creative Commons license. Read the <a href=\"https://theconversation.com/generative-ai-online-platforms-and-compensation-for-content-the-need-for-a-new-framework-242847\">original article</a>.</p>"
                }
            ]
        },
        {
            "title": "Generative AI is already being used in journalism \u2013 here\u2019s how people feel about\u00a0it",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "https://aihub.org/feed/",
                "value": "Generative AI is already being used in journalism \u2013 here\u2019s how people feel about\u00a0it"
            },
            "links": [
                {
                    "rel": "alternate",
                    "type": "text/html",
                    "href": "https://aihub.org/2025/02/21/generative-ai-is-already-being-used-in-journalism-heres-how-people-feel-about-it/"
                }
            ],
            "link": "https://aihub.org/2025/02/21/generative-ai-is-already-being-used-in-journalism-heres-how-people-feel-about-it/",
            "authors": [
                {
                    "name": "The Conversation"
                }
            ],
            "author": "The Conversation",
            "author_detail": {
                "name": "The Conversation"
            },
            "published": "Fri, 21 Feb 2025 11:10:55 +0000",
            "published_parsed": [
                2025,
                2,
                21,
                11,
                10,
                55,
                4,
                52,
                0
            ],
            "tags": [
                {
                    "term": "articles",
                    "scheme": null,
                    "label": null
                }
            ],
            "id": "https://aihub.org/?p=16967",
            "guidislink": false,
            "summary": "By T.J. Thomson, RMIT University; Michelle Riedlinger, Queensland University of Technology; Phoebe Matich, Queensland University of Technology, and Ryan J. Thomas, Washington State University Generative artificial intelligence (AI) has taken off at lightning speed in the past couple of years, creating disruption in many industries. Newsrooms are no exception. A new report published this week [&#8230;]",
            "summary_detail": {
                "type": "text/html",
                "language": null,
                "base": "https://aihub.org/feed/",
                "value": "By T.J. Thomson, RMIT University; Michelle Riedlinger, Queensland University of Technology; Phoebe Matich, Queensland University of Technology, and Ryan J. Thomas, Washington State University Generative artificial intelligence (AI) has taken off at lightning speed in the past couple of years, creating disruption in many industries. Newsrooms are no exception. A new report published this week [&#8230;]"
            },
            "content": [
                {
                    "type": "text/html",
                    "language": null,
                    "base": "https://aihub.org/feed/",
                    "value": "<img alt=\"stack of newspapers\" class=\"aligncenter size-full wp-image-11702\" height=\"853\" src=\"https://aihub.org/wp-content/uploads/2023/03/newspapers-gb777f15eb_1280.jpg\" width=\"1280\" />\n<p><strong>By <a href=\"https://theconversation.com/profiles/t-j-thomson-503845\">T.J. Thomson</a>, <em><a href=\"https://theconversation.com/institutions/rmit-university-1063\">RMIT University</a></em>; <a href=\"https://theconversation.com/profiles/michelle-riedlinger-1177519\">Michelle Riedlinger</a>, <em><a href=\"https://theconversation.com/institutions/queensland-university-of-technology-847\">Queensland University of Technology</a></em>; <a href=\"https://theconversation.com/profiles/phoebe-matich-2295492\">Phoebe Matich</a>, <em><a href=\"https://theconversation.com/institutions/queensland-university-of-technology-847\">Queensland University of Technology</a></em>, and <a href=\"https://theconversation.com/profiles/ryan-j-thomas-218412\">Ryan J. Thomas</a>, <em><a href=\"https://theconversation.com/institutions/washington-state-university-1640\">Washington State University</a></em></strong></p>\n<p>Generative artificial intelligence (AI) has taken off at lightning speed in the past couple of years, creating disruption in many industries. Newsrooms are no exception.</p>\n<p><a href=\"https://apo.org.au/node/329601\">A new report</a> published this week finds that news audiences and journalists alike are concerned about how news organisations are \u2013 and could be \u2013 using generative AI such as chatbots, image, audio and video generators, and similar tools.</p>\n<p>The report draws on three years of interviews and focus group research into generative AI and journalism in Australia and six other countries (United States, United Kingdom, Norway, Switzerland, Germany and France).</p>\n<p>Only 25% of our news audience participants were confident they had encountered generative AI in journalism. About 50% were unsure or suspected they had.</p>\n<p>This suggests a potential lack of transparency from news organisations when they use generative AI. It could also reflect a <a href=\"https://www.abc.net.au/news/2023-02-08/trust-slump-as-division-rules/101939406\">lack of trust</a> between news outlets and audiences.</p>\n<p>Who or what makes your news \u2013 and how \u2013 matters for a host of reasons. </p>\n<p>Some outlets tend to use <a href=\"https://www.tandfonline.com/doi/full/10.1080/17512786.2023.2215237\">more or fewer sources</a>, for example. Or use certain kinds of sources \u2013 such as politicians or experts \u2013 more than others. </p>\n<p>Some outlets under-represent or misrepresent parts of the community. This is sometimes because the news outlet\u2019s staff themselves <a href=\"https://journals.sagepub.com/doi/10.1177/14648849241305363\">aren\u2019t representative</a> of their audience. </p>\n<p>Carelessly using AI to produce or edit journalism can reproduce some of these inequalities.</p>\n<p>Our report identifies dozens of ways journalists and news organisations can use generative AI. It also summarises how comfortable news audiences are with each. </p>\n<p>The news audiences we spoke to overall felt most comfortable with journalists using AI for behind-the-scenes tasks rather than for editing and creating. These include using AI to transcribe an interview or to provide ideas on how to cover a topic. </p>\n<p>But comfort is highly dependent on context. Audiences were quite comfortable with some editing and creating tasks when the perceived risks were lower.</p>\n<h2>The problem \u2013 and opportunity</h2>\n<p>Generative AI can be used in just about every part of journalism. </p>\n<p>For example, a photographer could cover an event. Then, a generative AI tool could select what it \u201cthinks\u201d are the best images, edit the images to optimise them, and add keywords to each. </p>\n<p><figure class=\"align-center zoomable\">\n            <a href=\"https://images.theconversation.com/files/648718/original/file-20250212-15-wxtm3f.jpg?ixlib=rb-4.1.0&amp;q=45&amp;auto=format&amp;w=1000&amp;fit=clip\"><img alt=\"An image of a field with towers in the distance and computer-generated labels superimposed that try to identify certain objects in the image.\" src=\"https://images.theconversation.com/files/648718/original/file-20250212-15-wxtm3f.jpg?ixlib=rb-4.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip\" /></a><em><figcaption><span class=\"caption\">Computer software can try to recognise objects in images and add keywords, leading to potentially more efficient image processing workflows.</span><span class=\"attribution\"><span class=\"source\">Elise Racine/Better Images of AI/Moon over Fields</span>, <a class=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\">CC BY</a></span><br />\n            </figcaption></em><br />\n          </figure>\n</p>\n<p>These might seem like relatively harmless applications. But what if the AI identifies something or someone incorrectly, and these keywords lead to mis-identifications in the photo captions? What if the criteria humans think make \u201cgood\u201d images are different to what a computer might think? These criteria may also change over time or in different contexts.</p>\n<p>AI can also <a href=\"https://www.tandfonline.com/doi/full/10.1080/21670811.2024.2331769\">make things up</a> completely. Images can appear photorealistic but show things that never happened. Videos can be entirely generated with AI, or edited with AI to change their context.</p>\n<p>Generative AI is also frequently used for writing headlines or summarising articles. These sound like helpful applications for time-poor individuals, but some news outlets are <a href=\"https://www.crikey.com.au/2024/02/05/worthview-group-toowoomba-minute-artificial-intelligence/\">using AI to rip off others\u2019 content</a>. </p>\n<p>AI-generated news alerts have also gotten the facts wrong. As an example, Apple recently <a href=\"https://www.theguardian.com/technology/2025/jan/17/apple-suspends-ai-generated-news-alert-service-after-bbc-complaint\">suspended</a> its automatically generated news notification feature. It did this after the feature falsely claimed US murder suspect Luigi Mangione had killed himself, with the source attributed as the BBC.</p>\n<h2>What do people think about journalists using AI?</h2>\n<p>Our research found news audiences seem to be more comfortable with journalists using AI for certain tasks when they themselves have used it for similar purposes.</p>\n<p>For example, the people interviewed were largely comfortable with journalists using AI to blur parts of an image. Our participants said they used similar tools on video conferencing apps or when using the \u201cportrait\u201d mode on smartphones.</p>\n<p>Likewise, when you insert an image into popular word processing or presentation software, it might automatically create a written description of the image for people with vision impairments. Those who\u2019d previously encountered such AI descriptions of images felt more comfortable with journalists using AI to add keywords to media.</p>\n<p><figure class=\"align-center zoomable\">\n            <a href=\"https://images.theconversation.com/files/643772/original/file-20250121-15-pdk5b4.png?ixlib=rb-4.1.0&amp;q=45&amp;auto=format&amp;w=1000&amp;fit=clip\"><img alt=\"A screenshot of an image with the alt-text description that reads A view of the beach from a stone arch.\" src=\"https://images.theconversation.com/files/643772/original/file-20250121-15-pdk5b4.png?ixlib=rb-4.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip\" /></a><em><figcaption>Popular word processing and presentation software can automatically generate alt-text descriptions for images that are inserted into documents or presentations. T.J. Thomson<br />\n            </figcaption></em><br />\n          </figure>\n</p>\n<p>The most frequent way our participants encountered generative AI in journalism was when journalists reported on AI content that had gone viral. </p>\n<p>For example, when an AI-generated image purported to show Princes William and Harry embracing at King Charles\u2019s coronation, news outlets <a href=\"https://uk.news.yahoo.com/fake-ai-images-keep-going-091300119.html\">reported on this false image</a>. </p>\n<p>Our news audience participants also saw notices that AI had been used to write, edit or translate news articles. They saw AI-generated images accompanying some of these. This is a popular approach at The Daily Telegraph, which uses AI-generated images to <a href=\"https://www.tandfonline.com/doi/full/10.1080/17512786.2025.2451677#d1e162\">illustrate many of its opinion columns</a>.</p>\n<p><figure class=\"align-center zoomable\">\n            <a href=\"https://images.theconversation.com/files/643771/original/file-20250121-17-hn7edi.jpeg?ixlib=rb-4.1.0&amp;q=45&amp;auto=format&amp;w=1000&amp;fit=clip\"><img alt=\"An overview of twelve opinion columns published by The Daily Telegraph and each featuring an image generated by an AI tool.\" src=\"https://images.theconversation.com/files/643771/original/file-20250121-17-hn7edi.jpeg?ixlib=rb-4.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip\" /></a><em><figcaption>The Daily Telegraph frequently turns to generative AI to illustrate its opinion columns, sometimes generating more photorealistic illustrations and sometimes less photorealistic ones. T.J. Thomson.<br />\n            </figcaption></em><br />\n          </figure>\n</p>\n<p>Overall, our participants felt most comfortable with journalists using AI for brainstorming or for enriching already created media. This was followed by using AI for editing and creating. But comfort depends heavily on the specific use.</p>\n<p>Most of our participants were comfortable with turning to AI to create icons for an infographic. But they were quite uncomfortable with the idea of an AI avatar presenting the news, for example.</p>\n<p>On the editing front, a majority of our participants were comfortable with using AI to animate historical images, <a href=\"https://purl.slwa.wa.gov.au/slwa_b3293379_1\">like this one</a>. AI can be used to \u201cenliven\u201d an otherwise static image in the hopes of attracting viewer interest and engagement.</p>\n<figure class=\"align-center zoomable\">\n            <a href=\"https://images.theconversation.com/files/648496/original/file-20250212-15-nl3utx.gif?ixlib=rb-4.1.0&amp;q=45&amp;auto=format&amp;w=1000&amp;fit=clip\"><img alt=\"\" src=\"https://images.theconversation.com/files/648496/original/file-20250212-15-nl3utx.gif?ixlib=rb-4.1.0&amp;q=45&amp;auto=format&amp;w=754&amp;fit=clip\" /></a><em><figcaption>A historical photograph from the State Library of Western Australia\u2019s collection has been animated with AI (a tool called Runway) to introduce motion to the still image. T.J. Thomson.<br />\n            </figcaption></em><br />\n          </figure>\n<h2>Your role as an audience member</h2>\n<p>If you\u2019re unsure if or how journalists are using AI, look for a  <a href=\"https://www.wired.com/about/generative-ai-policy/\">policy</a> or <a href=\"https://www.theguardian.com/help/insideguardian/2023/jun/16/the-guardians-approach-to-generative-ai\">explainer</a> from the news outlet on the topic. If you can\u2019t find one, consider asking the outlet to develop and publish a policy.</p>\n<p>Consider supporting media outlets that use AI to complement and support \u2013 rather than replace \u2013 human labour.</p>\n<p>Before making decisions, consider the past trustworthiness of the journalist or outlet in question, and what the evidence says.<!-- Below is The Conversation's page counter tag. Please DO NOT REMOVE. --><img alt=\"The Conversation\" height=\"1\" src=\"https://counter.theconversation.com/content/247232/count.gif?distributor=republish-lightbox-basic\" style=\"border: none !important; margin: 0 !important; padding: 0 !important;\" width=\"1\" /><!-- End of code. If you don't see any code above, please get new code from the Advanced tab after you click the republish button. The page counter does not collect any personal data. More info: https://theconversation.com/republishing-guidelines --></p>\n<p><span><a href=\"https://theconversation.com/profiles/t-j-thomson-503845\">T.J. Thomson</a>, Senior Lecturer in Visual Communication &#038; Digital Media, <em><a href=\"https://theconversation.com/institutions/rmit-university-1063\">RMIT University</a></em>; <a href=\"https://theconversation.com/profiles/michelle-riedlinger-1177519\">Michelle Riedlinger</a>, Associate Professor in Digital Media, <em><a href=\"https://theconversation.com/institutions/queensland-university-of-technology-847\">Queensland University of Technology</a></em>; <a href=\"https://theconversation.com/profiles/phoebe-matich-2295492\">Phoebe Matich</a>, Postdoctoral Research Fellow, Generative Authenticity in Journalism and Human Rights Media, ADM+S Centre, <em><a href=\"https://theconversation.com/institutions/queensland-university-of-technology-847\">Queensland University of Technology</a></em>, and <a href=\"https://theconversation.com/profiles/ryan-j-thomas-218412\">Ryan J. Thomas</a>, Associate Professor, <em><a href=\"https://theconversation.com/institutions/washington-state-university-1640\">Washington State University</a></em></span></p>\n<p>This article is republished from <a href=\"https://theconversation.com\">The Conversation</a> under a Creative Commons license. Read the <a href=\"https://theconversation.com/generative-ai-is-already-being-used-in-journalism-heres-how-people-feel-about-it-247232\">original article</a>.</p>"
                }
            ]
        },
        {
            "title": "Charlotte Bunne on developing AI-based diagnostic tools",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "https://aihub.org/feed/",
                "value": "Charlotte Bunne on developing AI-based diagnostic tools"
            },
            "links": [
                {
                    "rel": "alternate",
                    "type": "text/html",
                    "href": "https://aihub.org/2025/02/20/charlotte-bunne-on-developing-ai-based-diagnostic-tools/"
                }
            ],
            "link": "https://aihub.org/2025/02/20/charlotte-bunne-on-developing-ai-based-diagnostic-tools/",
            "authors": [
                {
                    "name": "EPFL"
                }
            ],
            "author": "EPFL",
            "author_detail": {
                "name": "EPFL"
            },
            "published": "Thu, 20 Feb 2025 15:37:36 +0000",
            "published_parsed": [
                2025,
                2,
                20,
                15,
                37,
                36,
                3,
                51,
                0
            ],
            "tags": [
                {
                    "term": "opinions",
                    "scheme": null,
                    "label": null
                }
            ],
            "id": "https://aihub.org/?p=16952",
            "guidislink": false,
            "summary": "Image by Alan Warburton / \u00a9 BBC / Better Images of AI / Medicine / Licenced by CC-BY 4.0 By Tanya Petersen Charlotte Bunne, head of EPFL\u2019s Artificial Intelligence in Molecular Medicine Group, is developing AI algorithms to better understand the incredibly complex and high-dimensional data that represent the hundreds of tissue layers and protein [&#8230;]",
            "summary_detail": {
                "type": "text/html",
                "language": null,
                "base": "https://aihub.org/feed/",
                "value": "Image by Alan Warburton / \u00a9 BBC / Better Images of AI / Medicine / Licenced by CC-BY 4.0 By Tanya Petersen Charlotte Bunne, head of EPFL\u2019s Artificial Intelligence in Molecular Medicine Group, is developing AI algorithms to better understand the incredibly complex and high-dimensional data that represent the hundreds of tissue layers and protein [&#8230;]"
            },
            "content": [
                {
                    "type": "text/html",
                    "language": null,
                    "base": "https://aihub.org/feed/",
                    "value": "<p><img alt=\"A photographic rendering of medical swabs and pills in a jar seen through a refractive glass grid, overlaid with a diagram of a neural network.\" class=\"aligncenter size-full wp-image-16955\" height=\"720\" src=\"https://aihub.org/wp-content/uploads/2025/02/AlanWarburton-Medicine-1280x720-1.jpg\" width=\"1280\" />Image by <a href=\"https://alanwarburton.co.uk/\">Alan Warburton</a> / \u00a9 BBC / <a href=\"https://www.betterimagesofai.org\">Better Images of AI</a> / Medicine / <a href=\"https://creativecommons.org/licenses/by/4.0/\">Licenced by CC-BY 4.0</a></p>\n<p><strong>By Tanya Petersen</strong></p>\n<p>Charlotte Bunne, head of EPFL\u2019s <a href=\"https://aimm.epfl.ch/\">Artificial Intelligence in Molecular Medicine Group</a>, is developing AI algorithms to better understand the incredibly complex and high-dimensional data that represent the hundreds of tissue layers and protein markers in an individual cell. <a href=\"https://www.epfl.ch/about/news-and-media/dimensions-en/\">EPFL magazine <em>Dimensions</em></a> spoke to Charlotte Bunne about her work at the cutting-edge of AI in medicine and biology.</p>\n<p><strong>Could you describe the focus of your research?</strong><br />\nWe are developing diagnostic tools for clinics that are driven by AI technologies. This includes forecasting the best treatment that a patient should receive, trying to understand the state of disease that a patient is in, and deciphering important biomarkers or potential drug targets that we should investigate further. Importantly, the molecular profile, and thus ultimately the associated disease phenotype of every patient, is unique to each person. Tailoring therapies to an individual\u2019s molecular profile requires both measurements that capture the cellular and molecular factors that influence treatment response as well as powerful AI technologies that robustly predict those from the correspondingly large and high-dimensional biomedical datasets originating from various experiments.</p>\n<p>And while we see these incredible achievements of AI in vision and language, biological data is very different: Measurements are indirect, obscured, multimodal, and represent only snapshots of an inherently dynamic system that governs underlying biological processes. We can\u2019t just apply AI technologies that are developed for language to the field of biology, we need to tailor architectures and learning algorithms to the intricacies of biological data and systems.</p>\n<p>While these large neural network models we develop are often black boxes in terms of their predictions, we need to design them in such a way that we at least understand which biological factors have contributed to a prediction. This understanding is crucial for biomarker and drug target discovery, as it highlights specific biological mechanisms and pathways linked to disease, revealing new therapeutic opportunities.</p>\n<p><strong>Tell me a bit about your background \u2013 how did you begin working in this really cutting-edge area, how did it pique your interest?</strong><br />\nI started early! At 14 I was part of a high-school scholarship program at the German Cancer Research Center and I was fascinated working on synthetic biology, a field that combines engineering, computer science and biotechnology. Since then, I have been convinced that only truly interdisciplinary approaches will allow us to reach our goals. Now, in my professorship I am jointly affiliated with EPFL\u2019s School of Life Sciences and School of Computer Sciences.</p>\n<p>As a high school student, we modified simple bacterial cells to have a new function: that allowed us to use them as small little machines in a product. Now, I\u2019m interested in how we can engineer human cells so that they have diagnostic properties, how we can forecast their behavior to therapies or how we can reprogram them from a disease into a healthy state. So, even though the goals, tools and in particular the level of complexity could not be more different from the work I did when I was 14, the essence remains the same.</p>\n<p><strong>Clearly this research field is an important driver towards personalized medicine. How quickly is it evolving, and has it really come into its own in the last few years with the advances in AI?</strong><br />\nI\u2019m a young researcher, so I\u2019ve joined a revolution that has been happening for some time. The field has transformed incredibly quickly in recent times because of the way we can now generate high-throughput biological data in an unprecedented resolution. Organizing massive collections of biomedical datasets is the foundation for training large neural networks. For example, a lot of the success of the latest Nobel Prize for Chemistry, awarded in parts to scientists that developed the protein-structure prediction tool AlphaFold, is thanks to the Protein Data Bank, a large collection of protein structures freely available to anyone.</p>\n<p>Our research happens one level up, where we are trying to simulate biological function and the behavior of cells and tissues. We base our AI models on data that measures hundreds of features in individual cells and provides insights into the subcellular location, presence and abundance of individual proteins and molecules within a cell. We are increasingly collecting this very rich data into databases, so progress is due to a combination of the availability of more samples and getting very rich and very high-resolved data of human cells.</p>\n<p>Often, however, we still work in low-data regimes and lack comprehensive datasets that, for example, capture dynamic cellular processes over time and across physical scales: in particular, paired data linking molecular changes to tissue-level behaviors is scarce, which means we need to be creative when developing AI systems to overcome these limitations.</p>\n<blockquote><p>Fully grasping the complexity of biological systems \u2013 which involve countless molecular interactions that organize to overall systems-level dynamics on time scales ranging from picoseconds to processes that take place over years \u2013 is a monumental task.<br />\n&#8211; Charlotte Bunne</p></blockquote>\n<p><strong>You mentioned data collection, and the databases that have been a fundamental basis to the work you are now doing. Clearly there are issues around privacy and how patient data can be used to train machine learning algorithms. How does this work and how is Switzerland placed in the global context?</strong><br />\nOf course, patient data requires the highest sensitivity. Such data is kept in secure computing environments and data protection regulations set stringent requirements for handling and processing such data. What is somewhat unique in Switzerland is the coordination of efforts to develop interoperable data infrastructures that enable the nationwide accessibility and exchange of health-related data. This sets the foundation for developing AI algorithms that use growing databases of diverse and representative patient data. Our work profits from these tremendous efforts and ecosystems that have been established in Switzerland over the past years.</p>\n<p>Another cornerstone of our research is the close exchange with clinicians and biologists. For us, this means that we are developing our AI solutions in close collaboration and can adapt them such that the diagnostic tools we build integrate seamlessly into clinical routines and processes. At the same time, these close collaborations with clinicians and biologists allow us to influence and steer future data generation in areas where data is under sampled, or to prioritize measurements of data modalities that offer deeper insights into the molecular makeup of cells and tissues. We expect that such AI-guided data collection will significantly improve the capabilities of the AI models we build.</p>\n<p><strong>You are also involved in a global community that aims to develop AI-powered Virtual Cells. What are these and how will they take current research further?</strong><br />\nThere are countless ways of measuring biology across many different physical scales, from molecular interactions to tissue architecture. The question we aim to answer is: How can we integrate all those measurements to get the full picture and a comprehensive understanding of cell behavior and function? Specifically, can we predict how a cell\u2019s molecular state will change upon an external perturbation such as a drug, an environmental influence, a disease, a treatment? Essentially, we want to understand why a cell adopts a particular state rather than another.</p>\n<p>With advances in measurement techniques and increasingly powerful AI architectures, we are now beginning to have the tools to tackle such challenges. Some of these AI models are built on single-cell measurement data, while others focus on decoding the language of DNA or predicting protein folding. The vision is to create a multimodal, multi-scale foundation model \u2013 an AI-powered Virtual Cell \u2013 that integrates all those efforts and measurements and represents and simulates the behavior of molecules, cells, and tissues across a range of states and conditions. An AI Virtual Cell serves as a learned, universal simulator capable of modeling cellular systems under diverse scenarios, including differentiation, disease states, stochastic fluctuations, and environmental influences.</p>\n<p>This is a massive, collaborative effort involving a global research community. Many groups are working on different components of this puzzle, and our challenge and opportunity lie in integrating these contributions into a cohesive vision that will push the boundaries of what\u2019s possible in biomedical research.</p>\n<p><strong>If you had a crystal ball, where would you see AI in biomedicine in a decade? What will you be doing in ten years\u2019 time?</strong><br />\nThere are some easier tasks in biology which we might have solved and for which we are able to make accurate predictions. Success stories such as AlphaFold demonstrate that we can solve specific isolated problems, and I expect more breakthroughs of that kind in the next decade. However, fully grasping the complexity of biological systems \u2013 which involve countless molecular interactions that organize to overall systems-level dynamics on time scales ranging from picoseconds to processes that take place over years \u2013 is a monumental task. I believe we will have countless problems to solve and questions to answer for many, many years to come.</p>"
                }
            ]
        },
        {
            "title": "What\u2019s coming up at #AAAI2025?",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "https://aihub.org/feed/",
                "value": "What\u2019s coming up at #AAAI2025?"
            },
            "links": [
                {
                    "rel": "alternate",
                    "type": "text/html",
                    "href": "https://aihub.org/2025/02/19/whats-coming-up-at-aaai2025/"
                }
            ],
            "link": "https://aihub.org/2025/02/19/whats-coming-up-at-aaai2025/",
            "authors": [
                {
                    "name": "Lucy Smith"
                }
            ],
            "author": "Lucy Smith",
            "author_detail": {
                "name": "Lucy Smith"
            },
            "published": "Wed, 19 Feb 2025 18:01:23 +0000",
            "published_parsed": [
                2025,
                2,
                19,
                18,
                1,
                23,
                2,
                50,
                0
            ],
            "tags": [
                {
                    "term": "news",
                    "scheme": null,
                    "label": null
                },
                {
                    "term": "AAAI",
                    "scheme": null,
                    "label": null
                },
                {
                    "term": "AAAI2025",
                    "scheme": null,
                    "label": null
                }
            ],
            "id": "https://aihub.org/?p=16908",
            "guidislink": false,
            "summary": "From Tuesday 25 February to Tuesday 4 March 2025, Philadelphia will play host to the 39th Annual AAAI Conference on Artificial Intelligence (AAAI 2025). The event will feature invited talks, tutorials, workshops, and an extensive technical programme. There are also a whole host of other sessions, including a doctoral consortium, diversity and inclusion activities, posters, [&#8230;]",
            "summary_detail": {
                "type": "text/html",
                "language": null,
                "base": "https://aihub.org/feed/",
                "value": "From Tuesday 25 February to Tuesday 4 March 2025, Philadelphia will play host to the 39th Annual AAAI Conference on Artificial Intelligence (AAAI 2025). The event will feature invited talks, tutorials, workshops, and an extensive technical programme. There are also a whole host of other sessions, including a doctoral consortium, diversity and inclusion activities, posters, [&#8230;]"
            },
            "content": [
                {
                    "type": "text/html",
                    "language": null,
                    "base": "https://aihub.org/feed/",
                    "value": "<img alt=\"\" class=\"aligncenter size-full wp-image-16910\" height=\"720\" src=\"https://aihub.org/wp-content/uploads/2025/02/philadelphia-4643451_1280.jpg\" width=\"1280\" />\n<p>From Tuesday 25 February to Tuesday 4 March 2025, Philadelphia will play host to the <a href=\"https://aaai.org/conference/aaai/aaai-25/\">39th Annual AAAI Conference on Artificial Intelligence (AAAI 2025)</a>. The event will feature invited talks, tutorials, workshops, and an extensive technical programme. There are also a whole host of other sessions, including a doctoral consortium, diversity and inclusion activities, posters, demos, and more. We (AIhub) will be running a science communication training session on Wednesday 26 February. </p>\n<h3>Invited talks</h3>\n<p>There are eight invited talks this year. There will also be a presidential address from current AAAI president Francesca Rossi.<br />\n<strong>Francesca Rossi</strong> &#8211; Presidential Address: AI Reasoning and System 2 Thinking<br />\n<strong>Susan Athey</strong> &#8211; Predicting Career Transitions and Estimating Wage Disparities Using Foundation Models<br />\n<strong>Andrew Ng</strong> &#8211; AI, Agents and Applications<br />\n<strong>Yuhuai (Tony) Wu</strong> &#8211; Reasoning at Scale<br />\n<strong>Christoph Schuhmann</strong> &#8211; Democratizing AI through Community Organizing<br />\n<strong>Alondra Nelson</strong> &#8211; Title to be confirmed<br />\n<strong>Subbarao Kambhampati</strong> &#8211; T(w)eaching AI in the Age of LLMs<br />\n<strong>Stuart J. Russell</strong> &#8211; Can AI Benefit Humanity?<br />\n<strong>David Chalmers</strong> &#8211; Propositional Interpretability in Humans and AI Systems</p>\n<h3>Science communication for AI researchers \u2013 an introduction</h3>\n<p>We (AIhub) will be running a short course on science communication on Wednesday 26 February. Find out more <a href=\"https://aihub.org/science-communication-for-ai-researchers-an-introduction-at-aaai2025/\">here</a>.</p>\n<h3>Tutorial and lab forum</h3>\n<p>The tutorial and lab forum will be held at the beginning of the conference, on Tuesday 25 and Wednesday 26 February.</p>\n<ul>\n<li>TH01: Bridging Inverse Reinforcement Learning and Large Language Model Alignment: Toward Safe and Human-Centric AI Systems</li>\n<li>TH02: Building trustworthy ML: The role of label quality and availability</li>\n<li>TH03: Fairness in AI/ML via Social Choice</li>\n<li>TH04: Foundation Models meet Embodied Agents</li>\n<li>TH05: Multi-modal Foundation Model for Scientific Discovery: With Applications in Chemistry, Material, and Biology</li>\n<li>TH06: Pre-trained Language Model with Limited Resources</li>\n<li>LH01: DAMAGeR: Deploying Automatic and Manual Approaches to GenAI Red-teaming</li>\n<li>TQ01: Advancing Offline Reinforcement Learning: Essential Theories and Techniques for Algorithm Developers</li>\n<li>TQ02: Unified Semi-Supervised Learning with Foundation Models</li>\n<li>LQ01: SOFAI Lab: A Hands-On Guide to Building Neurosymbolic Systems with Metacognitive Control</li>\n<li>TQ03: Reinforcement Learning with Temporal Logic objectives and constraints</li>\n<li>TH07: Concept-based Interpretable Deep Learning</li>\n<li>TH08: Evaluating Large Language Models: Challenges and Methods</li>\n<li>TH09: Foundation Models for Time Series Analysis: A Tutorial</li>\n<li>TH10: Neurosymbolic AI for EGI: Explainable, Grounded, and Instructable Generations</li>\n<li>TQ04: Deep Representation Learning for Tabular Data</li>\n<li>TQ05: LLMs and Copyright Risks: Benchmarks and Mitigation Approaches </li>\n<li>TQ06: Physics-Inspired Geometric Pretraining for Molecule Representation</li>\n<li>TQ07: From Tensor Factorizations to Circuits (and Back)</li>\n<li>TQ08: KV Cache Compression for Efficient Long Context LLM Inference: Challenges, Trade-Offs, and Opportunities</li>\n<li>TQ09: Supervised Algorithmic Fairness in Distribution Shifts</li>\n<li>LQ03: Developing explainable multimodal AI models with hands-on lab on the life-cycle of rare event prediction in manufacturing</li>\n<li>TH11: (Really) Using Counterfactuals to Explain AI Systems: Fundamentals, Methods, &amp; User Studies for XAI </li>\n<li>TH12: Advancing Brain-Computer Interfaces with Generative AI for Text, Vision, and Beyond </li>\n<li>TH13: AI for Science in the Era of Large Language Models </li>\n<li>TH14: Causal Representation Learning </li>\n<li>TH15: Graph Neural Networks: Architectures, Fundamental Properties and Applications </li>\n<li>TH16: Machine Learning for Protein Design </li>\n<li>TH17: The Lifecycle of Knowledge in Large Language Models: Memorization, Editing, and Beyond</li>\n<li>TH18: Thinking with Functors &#8212; Category Theory for A(G)I </li>\n<li>TH19: User-Driven Capability Assessment of Taskable AI Systems</li>\n<li>TQ10: Artificial Intelligence Safety: From Reinforcement Learning to Foundation Models</li>\n<li>TQ11: Hallucinations in Large Multimodal Models</li>\n<li>TQ12: Graph Machine Learning under Distribution Shifts: Adaptation, Generalization and Extension to LLM </li>\n<li>LQ02: Continual Learning on Graphs: Challenges, Solutions, and Opportunities</li>\n<li>TH20: AI Data Transparency: The Past, the Present, and Beyond </li>\n<li>TH21: Data-driven Decision-making in Public Health and its Real-world Applications </li>\n<li>TH22: Decision Intelligence for Two-sided Marketplaces </li>\n<li>TH23: Inferential Machine Learning: Towards Human-collaborative Vision and Language Models </li>\n<li>TH24: Machine Learning for Solvers </li>\n<li>TH25: Model Reuse: Unlocking the Power of Pre-Trained Model Resources</li>\n<li>TH26: Symbolic Regression: Towards Interpretability and Automated Scientific Discovery </li>\n<li>TH27: Tutorial: Multimodal Artificial Intelligence in Healthcare</li>\n<li>TQ13: Curriculum Learning in the Era of Large Language Models</li>\n<li>TQ14: Hypergraph Neural Networks: An In-Depth and Step-by-Step Guide</li>\n<li>TQ15: The Quest for A Science of Language Models</li>\n<li>LQ04: Financial Inclusion through AI-Powered Document Understanding </li>\n<li>TQ16: When Deep Learning Meets Polyhedral Theory: A Tutorial</li>\n</ul>\n<p>Find out more about the tutorials and labs <a href=\"https://aaai.org/conference/aaai/aaai-25/tutorial-and-lab-forum/\">here</a>.</p>\n<h3>Bridge programme</h3>\n<p>The bridge programme is designed to bring together two or more communities from different AI disciplines to foster collaborations. There are eleven different sessions this year, and these will be held on Tuesday 25 and Wednesday 26 February.</p>\n<ul>\n<li>B1: AI for Medicine and Healthcare</li>\n<li>B2: Bridge between AI and Scientific Knowledge Organization</li>\n<li>B3: Bridging Cognitive Science and AI to Bridge Neuro and Symbolic AI</li>\n<li>B4: Bridging Planning and Reasoning in Natural Language with Foundational Models (PLAN-FM)</li>\n<li>B5: Collaborative AI and Modeling of Humans</li>\n<li>B6: Combining AI and ORMS for Better Trustworthy Decision Making</li>\n<li>B7: Constraint Programming and Machine Learning</li>\n<li>B8: Continual Causality</li>\n<li>B9: Explainable AI, Energy and Critical Infrastructure Systems</li>\n<li>B10: Knowledge-guided Machine Learning: Bridging Scientific Knowledge and AI</li>\n<li>B11: Learning for Integrated Task and Motion Planning</li>\n</ul>\n<p>Find out more about the bridge programme <a href=\"https://aaai.org/conference/aaai/aaai-25/bridge-program/\">here</a>.</p>\n<h3>Workshops</h3>\n<p>There are 49 workshops to choose from this year. These will take place at the end of the main conference, on Monday 3 and Tuesday 4 March.</p>\n<ul>\n<li><a href=\"https://sites.google.com/view/tika-2025/\">W1: Translational Institute for Knowledge Axiomatization</a></li>\n<li><a href=\"https://sites.google.com/view/theory-of-mind-aaai-2025\">W2: Advancing Artificial Intelligence through Theory of Mind (ToM4AI): Bridging Human Cognition and Artificial Intelligence</a></li>\n<li><a href=\"https://sites.google.com/view/ai-public-missions-workshop\">W3: AI for Public Missions</a></li>\n<li><a href=\"https://sites.google.com/view/aaai-2025-ai-si/home\">W4: AI for Social Impact: Bridging Innovations in Finance, Social Media, and Crime Prevention</a></li>\n<li><a href=\"https://ai-for-urban-planning.github.io/AAAI25-workshop\">W5: AI for Urban Planning</a></li>\n<li><a href=\"https://aigovernance.github.io/\">W6: AI Governance: Alignment, Morality, and Law</a></li>\n<li><a href=\"https://ai-2-ase.github.io/%C2%A0\">W7: AI to Accelerate Science and Engineering (AI2ASE)</a></li>\n<li><a href=\"https://ai4ed.cc/workshops/aaai2025\">W8: AI4EDU: AI for Education: Tools, Opportunities, and Risks in the Generative AI Era</a></li>\n<li><a href=\"http://aics.site/AICS2025/\">W9: Artificial Intelligence for Cyber Security (AICS)</a></li>\n<li><a href=\"https://ai4musicians.org/2025aaai.html\">W10: Artificial Intelligence for Music</a></li>\n<li><a href=\"https://www.is3rlab.org/aaai25-cmasdl-workshop.github.io\">W11: Cooperative Multi-Agent Systems Decision-Making and Learning: Human-Multi-Agent Cognitive Fusion</a></li>\n<li><a href=\"https://sites.google.com/view/dai-2025\">W12: Deployable AI Workshop</a></li>\n<li><a href=\"https://markets-incentives-genai.github.io/\">W13: Economics of Modern ML: Markets, Incentives, and Generative AI</a></li>\n<li><a href=\"https://sites.google.com/servicenow.com/good-data-2025/\">W14: Preparing Good Data for Generative AI: Challenges and Approaches (Good-Data)</a></li>\n<li><a href=\"https://bit.ly/iraise-25\">W15: Innovation and Responsibility for AI-Supported Education</a></li>\n<li><a href=\"https://sites.google.com/view/marw-ai-agents/home\">W16: MARW: Multi-Agent AI in the Real-World Workshop</a></li>\n<li><a href=\"https://llmforplanning.github.io/\">W17: Planning in The Era of Large Language Models</a></li>\n<li><a href=\"https://www.aialign.net/pss-2025\">W18: Post-Singularity Symbiosis: Preparing for a World with Superintelligence</a></li>\n<li><a href=\"https://aaai2025-llm-misinformation.github.io/\">W19: Preventing and Detecting LLM Generated Misinformation</a></li>\n<li><a href=\"https://ppai-workshop.github.io/\">W20: Privacy-Preserving Artificial Intelligence</a></li>\n<li><a href=\"https://sites.google.com/view/qcai2025\">W21: Quantum Computing and Artificial Intelligence (QC+AI)</a></li>\n<li><a href=\"https://sites.google.com/view/web-agent-revolution/home\">W22: Web Agent Revolution: Enhancing Trust and Enterprise-Grade Adoption Through Innovation</a></li>\n<li><a href=\"https://imageomics.osu.edu/aaai25\">W23: Imageomics: Discovering Biological Knowledge from Images Using AI</a></li>\n<li><a href=\"http://airrworkshop.org/\">W24: Workshop on Datasets and Evaluators of AI Safety</a></li>\n<li><a href=\"https://sites.google.com/view/docui-aaai25/\">W25: Workshop on Document Understanding and Intelligence</a></li>\n<li><a href=\"https://womapf.github.io/aaai-25\">W26: Workshop on Multi-Agent Path Finding</a></li>\n<li><a href=\"https://llms4science-community.github.io/\">W27:Foundation Models for Biological Discoveries (FMs4Bio)</a></li>\n<li><a href=\"http://multiagents.org/workshop\">W28: Advancing LLM-Based Multi-Agent Collaboration</a></li>\n<li><a href=\"https://sites.google.com/view/ai4ir/aaai-2025\">W29: AI Agent for Information Retrieval: Generating and Ranking</a></li>\n<li><a href=\"https://sites.google.com/view/ai4research2024\">W30: AI4Research: Towards a Knowledge-grounded Scientific Research Lifecycle</a></li>\n<li><a href=\"https://ai4ts.github.io/aaai2025\">W31: Artificial Intelligence for Time Series Analysis (AI4TS): Theory, Algorithms, and Applications</a></li>\n<li><a href=\"https://aaai2025-ai4wcn.webflow.io/\">W32: Artificial Intelligence for Wireless Communications and Networking (AI4WCN)</a></li>\n<li><a href=\"https://sites.google.com/view/aict-2025\">W33: Artificial Intelligence with Causal Techniques</a></li>\n<li><a href=\"https://prl-theworkshop.github.io/prl2025-aaai/\">W34: Bridging the Gap Between AI Planning and Reinforcement Learning (PRL)</a></li>\n<li><a href=\"https://april-tools.github.io/colorai\">W35: CoLoRAI \u2013 Connecting Low-Rank Representations in AI</a></li>\n<li>W36: Computational Jobs Marketplace</li>\n<li>W37: DEFACTIFY 4.0 \u2013 Workshop Series on Multimodal Fact-Checking and Hate Speech Detection</li>\n<li><a href=\"https://fluidworkshop.github.io/\">W38: FLUID: Federated Learning for Unbounded and Intelligent Decentralization</a></li>\n<li><a href=\"https://aair-lab.github.io/genplan25\">W39: Generalization in Planning</a></li>\n<li><a href=\"https://www.nsfhdr.org/AAAI-workshop\">W40: Workshop and Challenge on Anomaly Detection in Scientific Domains</a></li>\n<li><a href=\"https://sites.google.com/view/kg4hejss/home\">W41: Knowledge Graphs for Health Equity, Justice, and Social Services</a></li>\n<li><a href=\"https://sites.google.com/view/genai4health-aaai-2025\">W42: Large Language Model and Generative AI for Health</a></li>\n<li><a href=\"https://ml4ad.github.io/\">W43: Machine Learning for Autonomous Driving</a></li>\n<li><a href=\"https://sites.google.com/view/malta2025\">W44: MALTA: Multi-Agent Reinforcement Learning for Transportation Autonomy</a></li>\n<li><a href=\"https://neurmad.github.io/\">W45: Neural Reasoning and Mathematical Discovery \u2014 An Interdisciplinary Two-Way Street</a></li>\n<li><a href=\"https://the-ai-alliance.github.io/AAAI-25-Workshop-on-Open-Source-AI-for-Mainstream-Use/\">W46: Open-Source AI for Mainstream Use</a></li>\n<li><a href=\"https://seasworkshop.github.io/aaai25/\">W47: Scalable and Efficient Artificial Intelligence Systems</a></li>\n<li><a href=\"https://knowledgeable-lm.github.io/aaai25\">W48: Towards Knowledgeable Foundation Models</a></li>\n<li><a href=\"http://w3phiai2025.w3phi.com/\">W49: Workshop on Health Intelligence (W3PHIAI-25)</a></li>\n</ul>\n<p>Find out more about the workshops <a href=\"https://aaai.org/conference/aaai/aaai-25/workshop-program/\">here</a>.</p>\n<h3>Links to other events and sessions</h3>\n<ul>\n<li><a href=\"https://aaai.org/conference/aaai/aaai-25/main-technical-track/\">Main technical track</a></li>\n<li><a href=\"https://aaai.org/conference/aaai/aaai-25/demonstration-program/\">Demonstration programme</a></li>\n<li><a href=\"https://aaai.org/conference/aaai/aaai-25/diversity-and-inclusion-activities/\">Diversity and inclusion activities</a></li>\n<li><a href=\"https://eaai-conf.github.io/year/eaai-25.html\">EAAI-25: The 15th Symposium on Educational Advances in Artificial Intelligence</a></li>\n<li><a href=\"https://aaai.org/conference/aaai/aaai-25/iaai-25-program/\">Programme for the Thirty-Seventh Annual Conference on Innovative Applications of Artificial Intelligence (IAAI-25)</a></li>\n<li><a href=\"https://aihub.org/feed/\">Doctoral Consortium</a></li>\n<li><a href=\"https://aihub.org/feed/\">Undergraduate Consortium</a></li>\n</ul>"
                }
            ]
        },
        {
            "title": "An introduction to science communication at #AAAI2025",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "https://aihub.org/feed/",
                "value": "An introduction to science communication at #AAAI2025"
            },
            "links": [
                {
                    "rel": "alternate",
                    "type": "text/html",
                    "href": "https://aihub.org/2025/02/18/an-introduction-to-science-communication-at-aaai2025/"
                }
            ],
            "link": "https://aihub.org/2025/02/18/an-introduction-to-science-communication-at-aaai2025/",
            "authors": [
                {
                    "name": "Lucy Smith"
                }
            ],
            "author": "Lucy Smith",
            "author_detail": {
                "name": "Lucy Smith"
            },
            "published": "Tue, 18 Feb 2025 16:10:10 +0000",
            "published_parsed": [
                2025,
                2,
                18,
                16,
                10,
                10,
                1,
                49,
                0
            ],
            "tags": [
                {
                    "term": "education",
                    "scheme": null,
                    "label": null
                },
                {
                    "term": "AAAI",
                    "scheme": null,
                    "label": null
                },
                {
                    "term": "AAAI2025",
                    "scheme": null,
                    "label": null
                },
                {
                    "term": "quick read",
                    "scheme": null,
                    "label": null
                }
            ],
            "id": "https://aihub.org/?p=16898",
            "guidislink": false,
            "summary": "We\u2019re pleased to announce that we will be giving an introduction to science communication for AI researchers at AAAI this year. This will be held on Wednesday 26 February from 13:00. If you are attending the conference and fancy finding out how you can communicate your research to a general audience in different formats, then [&#8230;]",
            "summary_detail": {
                "type": "text/html",
                "language": null,
                "base": "https://aihub.org/feed/",
                "value": "We\u2019re pleased to announce that we will be giving an introduction to science communication for AI researchers at AAAI this year. This will be held on Wednesday 26 February from 13:00. If you are attending the conference and fancy finding out how you can communicate your research to a general audience in different formats, then [&#8230;]"
            },
            "content": [
                {
                    "type": "text/html",
                    "language": null,
                    "base": "https://aihub.org/feed/",
                    "value": "<img alt=\"microphone in front of a crowd\" class=\"aligncenter size-full wp-image-5614\" height=\"568\" src=\"https://aihub.org/wp-content/uploads/2021/03/microphone-talking-to-public.jpg\" width=\"852\" />\n<p>We\u2019re pleased to announce that we will be giving an introduction to science communication for AI researchers at <a href=\"https://aaai.org/conference/aaai/aaai-25/\">AAAI</a> this year. This will be held on Wednesday 26 February from 13:00. If you are attending the conference and fancy finding out how you can communicate your research to a general audience in different formats, then please do join us. </p>\n<p>Following an hour-long introductory talk, there will be an optional, open, drop-in session where you can try out some of the things you learnt in the course, ask any sci-comm questions, and chat about your ideas and stories.</p>\n<h4>Timetable</h4>\n<ul>\n<li>13:00 &#8211; 14:00 Talk: science communication for AI researchers \u2013 introductory training</li>\n<li>14:00 \u2013 15:00 Open drop-in session for one-on-one support</li>\n</ul>\n<h4>Location</h4>\n<p><strong>Level 100, East Building, Room 111A</strong>, Pennsylvania Convention Center, Philadelphia</p>\n<h4>Presenters</h4>\n<p><strong>Professor Michael Littman</strong>, Brown University<br />\n<strong>Dr Lucy Smith</strong>, Senior Managing Editor, AIhub</p>\n<h4>About the session</h4>\n<p>Science communication is essential. It helps demystify AI for a broad range of people including policy makers, business leaders, and the public. As a researcher, mastering this skill can not only enhance your communication abilities but also expand your network and increase the visibility and impact of your work.</p>\n<p>In this brief tutorial, we will teach you how to clearly and concisely explain your research to non-specialists. You&#8217;ll learn how to avoid hype, how to find suitable images to illustrate your work, and where to start with social media.</p>\n<h4>What we&#8217;ll cover</h4>\n<ul>\n<li>Why science communication matters</li>\n<li>Different ways to do science communication</li>\n<li>Working with media</li>\n<li>Communicating via social media</li>\n<li>Finding your story </li>\n<li>Turning your story into a blog post</li>\n<li>How to find and use suitable images</li>\n<li>How to avoid hype in your communication</li>\n<li>Unconventional ways to do science communication</li>\n</ul>\n<p>If you\u2019d like to find out more, contact Lucy Smith at <a href=\"mailto:aihuborg@gmail.com\">aihuborg@gmail.com</a>, or see our <a href=\"https://aihub.org/science-communication-for-ai-researchers-an-introduction-at-aaai2025/\">session webpage</a>.</p>"
                }
            ]
        },
        {
            "title": "The Good Robot podcast: Critiquing tech through comedy with Laura Allcorn",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "https://aihub.org/feed/",
                "value": "The Good Robot podcast: Critiquing tech through comedy with Laura Allcorn"
            },
            "links": [
                {
                    "rel": "alternate",
                    "type": "text/html",
                    "href": "https://aihub.org/2025/02/17/the-good-robot-podcast-critiquing-tech-through-comedy-with-laura-allcorn/"
                },
                {
                    "length": "0",
                    "type": "audio/mpeg",
                    "href": "https://www.buzzsprout.com/1786427/episodes/16593993-critiquing-tech-through-comedy-with-laura-allcorn.mp3",
                    "rel": "enclosure"
                }
            ],
            "link": "https://aihub.org/2025/02/17/the-good-robot-podcast-critiquing-tech-through-comedy-with-laura-allcorn/",
            "authors": [
                {
                    "name": "The Good Robot Podcast"
                }
            ],
            "author": "The Good Robot Podcast",
            "author_detail": {
                "name": "The Good Robot Podcast"
            },
            "published": "Mon, 17 Feb 2025 09:52:54 +0000",
            "published_parsed": [
                2025,
                2,
                17,
                9,
                52,
                54,
                0,
                48,
                0
            ],
            "tags": [
                {
                    "term": "opinions",
                    "scheme": null,
                    "label": null
                }
            ],
            "id": "https://aihub.org/?p=16904",
            "guidislink": false,
            "summary": "Hosted by Eleanor Drage and Kerry McInerney, The Good Robot is a podcast which explores the many complex intersections between gender, feminism and technology. Critiquing tech through comedy with Laura Allcorn In this episode, we go shopping with artist and performer, Laura Allcorn. We enter into her practice, which is called the Institute for Comedic [&#8230;]",
            "summary_detail": {
                "type": "text/html",
                "language": null,
                "base": "https://aihub.org/feed/",
                "value": "Hosted by Eleanor Drage and Kerry McInerney, The Good Robot is a podcast which explores the many complex intersections between gender, feminism and technology. Critiquing tech through comedy with Laura Allcorn In this episode, we go shopping with artist and performer, Laura Allcorn. We enter into her practice, which is called the Institute for Comedic [&#8230;]"
            },
            "content": [
                {
                    "type": "text/html",
                    "language": null,
                    "base": "https://aihub.org/feed/",
                    "value": "<img alt=\"Space scene with words Good Robot Podcast\" class=\"alignnone size-full wp-image-10827\" height=\"837\" src=\"https://aihub.org/wp-content/uploads/2022/11/good-robot.png\" width=\"1704\" />\n<p>Hosted by Eleanor Drage and Kerry McInerney, <a href=\"https://www.thegoodrobot.co.uk/\">The Good Robot</a> is a podcast which explores the many complex intersections between gender, feminism and technology. </p>\n<h4>Critiquing tech through comedy with Laura Allcorn</h4>\n<p>In this episode, we go shopping with artist and performer, Laura Allcorn. We enter into her practice, which is called the Institute for Comedic Inquiry, to learn how she pairs humour and entertainment with participatory public engagement methods to raise awareness about bizarre and dangerous uses of AI.\u200a Laura uses comedy to skewer all manner of ethically questionable technologies, from gait surveillance to shopping algorithms. We participate in one of Laura&#8217;s performances in this episode, &#8216;SKU-MARKET&#8217;, an algorithmic shopping platform that promises to know you better than you know yourself. Stay tuned for what the algorithm says about us&#8230;</p>\n<p>Listen to the episode here:</p>\n<div class=\"audio\"><audio controls=\"controls\" src=\"https://www.buzzsprout.com/1786427/episodes/16593993-critiquing-tech-through-comedy-with-laura-allcorn.mp3\"></audio></div>\n<p></p>\n<div class=\"keep-aspect\"></div>\n<p></p>\n<p>Laura Allcorn is a creative director, experience designer, and humorist. She founded The Institute For Comedic Inquiry (IFCI), a comedian-led research group. At IFCI she creates interactive objects and participatory performances that point out absurdities through a technique she calls \u2018Participatory Satire.\u2019 Her work focuses on how humor connects people to each other and new ideas\u2013especially the ones that challenge narrow assumptions. She has studied all forms of comedy including satire writing, improvisation, sketch, and stand-up comedy.</p>\n<p>You can find the episode reading list and transcript <a href=\"https://www.thegoodrobot.co.uk/post/critiquing-tech-through-comedy-with-laura-allcorn\">here</a>.</p>\n<h4>About The Good Robot Podcast</h4>\n<p><a href=\"https://www.eleanordrage.com/\">Dr Eleanor Drage</a> and <a href=\"https://www.kerrymackereth.com/\">Dr Kerry McInerney</a> are Research Associates at the Leverhulme Centre for the Future of Intelligence, where they work on the Mercator-Stiflung funded project on Desirable Digitalisation. Previously, they were Christina Gaw Postdoctoral Researchers in Gender and Technology at the University of Cambridge Centre for Gender Studies. During the COVID-19 pandemic they decided to co-found <a href=\"https://www.thegoodrobot.co.uk/\">The Good Robot Podcast</a> to explore the many complex intersections between gender, feminism and technology. </p>"
                }
            ]
        },
        {
            "title": "Interview with Kayla Boggess: Explainable AI for more accessible and understandable technologies",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "https://aihub.org/feed/",
                "value": "Interview with Kayla Boggess: Explainable AI for more accessible and understandable technologies"
            },
            "links": [
                {
                    "rel": "alternate",
                    "type": "text/html",
                    "href": "https://aihub.org/2025/02/14/interview-with-kayla-boggess-explainable-ai-for-more-accessible-and-understandable-technologies/"
                }
            ],
            "link": "https://aihub.org/2025/02/14/interview-with-kayla-boggess-explainable-ai-for-more-accessible-and-understandable-technologies/",
            "authors": [
                {
                    "name": "Lucy Smith"
                }
            ],
            "author": "Lucy Smith",
            "author_detail": {
                "name": "Lucy Smith"
            },
            "published": "Fri, 14 Feb 2025 11:09:48 +0000",
            "published_parsed": [
                2025,
                2,
                14,
                11,
                9,
                48,
                4,
                45,
                0
            ],
            "tags": [
                {
                    "term": "opinions",
                    "scheme": null,
                    "label": null
                },
                {
                    "term": "AAAI",
                    "scheme": null,
                    "label": null
                },
                {
                    "term": "AAAI Doctoral Consortium",
                    "scheme": null,
                    "label": null
                },
                {
                    "term": "AAAI2025",
                    "scheme": null,
                    "label": null
                },
                {
                    "term": "ACM SIGAI",
                    "scheme": null,
                    "label": null
                }
            ],
            "id": "https://aihub.org/?p=16913",
            "guidislink": false,
            "summary": "In this interview series, we&#8217;re meeting some of the AAAI/SIGAI Doctoral Consortium participants to find out more about their research. The Doctoral Consortium provides an opportunity for a group of PhD students to discuss and explore their research interests and career objectives in an interdisciplinary workshop together with a panel of established researchers. In the [&#8230;]",
            "summary_detail": {
                "type": "text/html",
                "language": null,
                "base": "https://aihub.org/feed/",
                "value": "In this interview series, we&#8217;re meeting some of the AAAI/SIGAI Doctoral Consortium participants to find out more about their research. The Doctoral Consortium provides an opportunity for a group of PhD students to discuss and explore their research interests and career objectives in an interdisciplinary workshop together with a panel of established researchers. In the [&#8230;]"
            },
            "content": [
                {
                    "type": "text/html",
                    "language": null,
                    "base": "https://aihub.org/feed/",
                    "value": "<p><img alt=\"\" class=\"aligncenter size-full wp-image-16917\" height=\"1762\" src=\"https://aihub.org/wp-content/uploads/2025/02/Kayla-feature-scaled.jpg\" width=\"2560\" /><br />\nIn this interview series, we&#8217;re meeting some of the <a href=\"https://aaai.org/conference/aaai/aaai-25/doctoral-consortium/\">AAAI/SIGAI Doctoral Consortium</a> participants to find out more about their research. The Doctoral Consortium provides an opportunity for a group of PhD students to discuss and explore their research interests and career objectives in an interdisciplinary workshop together with a panel of established researchers. In the second of our interviews with the 2025 cohort, we hear from Kayla Boggess, a PhD student at the University of Virginia, and find out more about her research on explainable AI.</p>\n<h4>Tell us a bit about your PhD &#8211; where are you studying, and what is the topic of your research?</h4>\n<p>I\u2019m currently working on my PhD at the University of Virginia. I\u2019m a member of the University of Virginia Link Lab, which is a multi-disciplinary lab focused on cyber-physical systems. There\u2019s individuals from departments across the University of Virginia that all work in the lab, so I\u2019ve had the opportunity to work with other researchers in computer science, system engineering, psychology, and even law during my time there. We work on real-world problems in robotics, autonomous vehicles, health care, internet of things, and smart cities.</p>\n<p>Specifically, I work in explainable AI. My goal is to make advanced technologies more accessible and understandable for users by increasing system transparency, building user trust, and enhancing collaboration with autonomous systems. I have worked to create concept-based natural language explanations for multi-agent reinforcement learning policies and applied these methods to domains like autonomous vehicles and robotic search and rescue.</p>\n<h4>Could you give us an overview of the research you\u2019ve carried out so far during your PhD?</h4>\n<p>My research in explainable AI focuses on two key areas: explanations for multi-agent reinforcement learning (MARL) and human-centric explanations. First, I developed methods to generate comprehensive policy summaries that clarify agent behaviors within a MARL policy and provide concept-based natural language explanations to address user queries about agent decisions such as when, what, and why not. Second, I leveraged user preferences, social concepts, subjective evaluations, and information presentation methods to create more effective explanations tailored to human needs.</p>\n<h4>Is there an aspect of your research that has been particularly interesting?</h4>\n<p>I particularly enjoy the evaluation aspect of research. So, the computational experiments and user studies that are run once the algorithms are developed. Since I work in the generation of explanations there is a lot of evaluation with real-world users that needs to happen to show that the explanation we produced is actually usable and helpful. I always find it interesting how people react to the systems, what they wish the system did and didn\u2019t do, how they would change how the information is laid out, and what they take away from the explanation. People are much more difficult to deal with than algorithms, so I like to piece together the best way to help them and get them to collaborate with AI systems. Sometimes it\u2019s significantly more difficult than building the system itself.</p>\n<h4>What are your plans for building on your research so far during the PhD &#8211; what aspects will you be investigating next?</h4>\n<p>In the future, I would like to improve explainable methods for complex systems by focusing further on the development of robust algorithms and the integration of human factors. I would like to apply my methods to more complex, real-world systems like autonomous vehicles and large language models. My goal is to help ensure that understandable and satisfactory decisions can be made by AI systems for a broad<br />\naudience.</p>\n<h4>What made you want to study AI, and in particular the area of explainable AI?</h4>\n<p>I actually have two undergraduate degrees, one in computer science and the other in English Literature. I originally wanted to get my PhD in English, but after trying to apply to both English and computer science programs, I found that I had better opportunities on the computer science side. I was offered a position in the first cohort of the University of Virginia Link Lab\u2019s NRT program and I took the offer because it was going to allow me to do interdisciplinary work. I wasn\u2019t particularly sure what I was going to study yet, but I knew I wanted it to be somewhere between computer science and English. We were able to rotate through multiple advisors in my first year, so I didn\u2019t have to commit to anything directly to begin with. My advisor approached me with an explainable AI project that she wanted to get off the ground and felt like I was a good fit with my background. I enjoyed the project so much that I decided to continue working on it.</p>\n<h4>What advice would you give to someone thinking of doing a PhD in the field?</h4>\n<p>I would say that a new PhD student shouldn\u2019t tie themselves down to one problem too quickly. Take time to explore different fields and find something you are interested in. Just because you come into your PhD thinking you are going to do one thing doesn\u2019t mean you\u2019ll end your PhD working on that same problem. Play to your strengths as a researcher and don\u2019t just pick a field because you think it&#8217;s trendy. Be ready to walk away from a problem if you have to, but don\u2019t be afraid to take on new projects and try things out. You never know who you will meet and how things will work out.</p>\n<h4>Could you tell us an interesting (non-AI related) fact about you?</h4>\n<p>I&#8217;m self-taught in sewing. In my down time, I like to make all sorts of things like jackets, dresses, and pants. It\u2019s something that keeps my mind engaged in problem-solving while letting me do something creative. I\u2019ve actually won several awards for my pieces in the past.</p>\n<h4>About Kayla</h4>\n<table border=\"0\" cellpadding=\"10\" cellspacing=\"0\" width=\"100%\">\n<tbody>\n<tr>\n<td align=\"left\" valign=\"top\" width=\"150\">\n<img alt=\"\" class=\"aligncenter size-full wp-image-16915\" height=\"960\" src=\"https://aihub.org/wp-content/uploads/2025/02/Boggess_Photo.jpg\" width=\"698\" />\n</td>\n<td align=\"left\" valign=\"top\">\n<p>Kayla Boggess is a PhD student in the Department of Computer Science at the University of Virginia, advised by Dr Lu Feng. Kayla\u2019s research is at the intersection of explainable artificial intelligence, human-in-the-loop cyber-physical systems, and formal methods. She is interested in developing human-focused cyber-physical systems using natural language explanations for various single and multi-agent domains such as search and rescue and autonomous vehicles. Her research has led to multiple publications at top-tier computer science conferences such as IJCAI, ICCPS, and IROS. Kayla is a recipient of the prestigious NSF NRT Graduate Research Fellowship and a CPS Rising Star Award.</p>\n</td>\n</tr>\n</tbody>\n</table>\n<h4>Further reading</h4>\n<ul>\n<li><a href=\"https://www.ijcai.org/proceedings/2022/0016.pdf\">Toward Policy Explanations for Multi-Agent Reinforcement Learning</a>, <em>Kayla Boggess, Sarit Kraus and Lu Feng</em>.</li>\n<li><a href=\"https://www.ijcai.org/proceedings/2023/0007.pdf\">Explainable Multi-Agent Reinforcement Learning for Temporal Queries</a>, <em>Kayla Boggess, Sarit Kraus and Lu Feng</em>.</li>\n<li><a href=\"https://www.cs.virginia.edu/~lufeng/papers/aaai2025b.pdf\">Towards Computational Foreseeability</a>, <em>Sarit Kraus, Kayla Boggess, Robert Kim, Bryan H. Choi and Lu Feng</em>.</li>\n</ul>"
                }
            ]
        },
        {
            "title": "The Machine Ethics podcast: Running faster with Enrico Panai",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "https://aihub.org/feed/",
                "value": "The Machine Ethics podcast: Running faster with Enrico Panai"
            },
            "links": [
                {
                    "rel": "alternate",
                    "type": "text/html",
                    "href": "https://aihub.org/2025/02/13/the-machine-ethics-podcast-running-faster-with-enrico-panai/"
                },
                {
                    "length": "82936829",
                    "type": "audio/mpeg",
                    "href": "https://www.machine-ethics.net/site/assets/files/1567/enrico-panai_machine-ethics-podcast.mp3",
                    "rel": "enclosure"
                }
            ],
            "link": "https://aihub.org/2025/02/13/the-machine-ethics-podcast-running-faster-with-enrico-panai/",
            "authors": [
                {
                    "name": "The Machine Ethics Podcast"
                }
            ],
            "author": "The Machine Ethics Podcast",
            "author_detail": {
                "name": "The Machine Ethics Podcast"
            },
            "published": "Thu, 13 Feb 2025 11:19:21 +0000",
            "published_parsed": [
                2025,
                2,
                13,
                11,
                19,
                21,
                3,
                44,
                0
            ],
            "tags": [
                {
                    "term": "opinions",
                    "scheme": null,
                    "label": null
                }
            ],
            "id": "https://aihub.org/?p=16893",
            "guidislink": false,
            "summary": "Hosted by Ben Byford, The Machine Ethics Podcast brings together interviews with academics, authors, business leaders, designers and engineers on the subject of autonomous algorithms, artificial intelligence, machine learning, and technology\u2019s impact on society. Running faster with Enrico Panai This episode we&#8217;re chatting with Enrico Panai about the elements of the digital revolution, AI transforming [&#8230;]",
            "summary_detail": {
                "type": "text/html",
                "language": null,
                "base": "https://aihub.org/feed/",
                "value": "Hosted by Ben Byford, The Machine Ethics Podcast brings together interviews with academics, authors, business leaders, designers and engineers on the subject of autonomous algorithms, artificial intelligence, machine learning, and technology\u2019s impact on society. Running faster with Enrico Panai This episode we&#8217;re chatting with Enrico Panai about the elements of the digital revolution, AI transforming [&#8230;]"
            },
            "content": [
                {
                    "type": "text/html",
                    "language": null,
                    "base": "https://aihub.org/feed/",
                    "value": "<img alt=\"\" class=\"aligncenter size-full wp-image-16894\" height=\"760\" src=\"https://aihub.org/wp-content/uploads/2025/02/Enrico-Panai.jpg\" width=\"1046\" />\n<p>Hosted by <a href=\"https://www.benbyford.com/\">Ben Byford</a>, <a href=\"https://www.machine-ethics.net/\">The Machine Ethics Podcast</a> brings together interviews with academics, authors, business leaders, designers and engineers on the subject of autonomous algorithms, artificial intelligence, machine learning, and technology\u2019s impact on society.</p>\n<h4>Running faster with Enrico Panai</h4>\n<p>This episode we&#8217;re chatting with Enrico Panai about the elements of the digital revolution, AI transforming data into information, human-computer interaction, the importance of knowing the tech as a tech philosopher, that ethicists should diagnose not judge, quality and making pasta, whether ethics is really a burden for companies or if you can run faster with ethics, and finding a Marx for the digital world.</p>\n<p>Listen to the episode here:</p>\n<div class=\"audio\"><audio controls=\"controls\" src=\"https://www.machine-ethics.net/site/assets/files/1567/enrico-panai_machine-ethics-podcast.mp3\"></audio></div>\n<p></p>\n<hr />\n<p><a href=\"https://www.linkedin.com/in/enricopanai/\">Enrico Panai</a> is an AI ethicist with a background in philosophy and extensive consulting experience in Italy. He spent seven years as an adjunct professor of Digital Humanities at the University of Sassari. Since moving to France in 2007, he has continued his work as a consultant. In 2017, he studied Strategies for Cyber Security Awareness at the Institut National de Hautes \u00c9tudes de la S\u00e9curit\u00e9 et de la Justice in Paris. Holding a PhD in Cybergeography and AI Ethics, he is the founder of the consultancy BeEthical.be. He serves as a professor of Responsible AI at EMlyon Business School, ISEP in Paris, and La Cattolica in Milan. Additionally, he is the president of the Association of AI Ethicists.</p>\n<p>Currently, his main role is as an officer of the French Standardization Committee for AI and convenor of the working group on fundamental and societal aspects of AI at the European CEN-CENELEC JTC21\u2014the European standardization body focused on producing deliverables that address European market and societal needs. Among the core standards managed are Trustworthiness of AI, Competences of professional AI ethicists and Sustainable AI. His main research interests concern cyber-geography, human-information interaction, philosophy and ethics of information and semantic capital.</p>\n<h4>About The Machine Ethics podcast</h4>\n<p>This podcast was created and is run by <a href=\"https://www.benbyford.com/\">Ben Byford</a> and collaborators. The podcast, and other content was first created to extend Ben&#8217;s growing interest in both the AI domain and in the associated ethics. Over the last few years the podcast has grown into a place of discussion and dissemination of important ideas, not only in AI but in tech ethics generally. As the interviews unfold on they often veer into current affairs, the future of work, environmental issues, and more. Though the core is still AI and AI Ethics, we release content that is broader and therefore hopefully more useful to the general public and practitioners.</p>\n<p>The hope for the podcast is for it to promote debate concerning technology and society, and to foster the production of technology (and in particular, decision making algorithms) that promote human ideals. </p>\n<p>Join in the conversation by getting in touch via email <a href=\"mailto:hello@machine-ethics.net\">here</a> or following us on <a href=\"https://twitter.com/machine_ethics\">Twitter</a> and <a href=\"https://www.instagram.com/machineethicspodcast/\">Instagram</a>.</p>"
                }
            ]
        },
        {
            "title": "Diffusion model predicts 3D genomic structures",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "https://aihub.org/feed/",
                "value": "Diffusion model predicts 3D genomic structures"
            },
            "links": [
                {
                    "rel": "alternate",
                    "type": "text/html",
                    "href": "https://aihub.org/2025/02/12/diffusion-model-predicts-3d-genomic-structures/"
                }
            ],
            "link": "https://aihub.org/2025/02/12/diffusion-model-predicts-3d-genomic-structures/",
            "authors": [
                {
                    "name": "MIT News"
                }
            ],
            "author": "MIT News",
            "author_detail": {
                "name": "MIT News"
            },
            "published": "Wed, 12 Feb 2025 12:20:56 +0000",
            "published_parsed": [
                2025,
                2,
                12,
                12,
                20,
                56,
                2,
                43,
                0
            ],
            "tags": [
                {
                    "term": "articles",
                    "scheme": null,
                    "label": null
                }
            ],
            "id": "https://aihub.org/?p=16890",
            "guidislink": false,
            "summary": "This image shows the three-dimensional genome structures of several chromosomes reported in a Dip-C study, which were used to train the new ChromoGen model. Credit: Courtesy of the researchers, edited by MIT News. By Anne Trafton Every cell in your body contains the same genetic sequence, yet each cell expresses only a subset of those [&#8230;]",
            "summary_detail": {
                "type": "text/html",
                "language": null,
                "base": "https://aihub.org/feed/",
                "value": "This image shows the three-dimensional genome structures of several chromosomes reported in a Dip-C study, which were used to train the new ChromoGen model. Credit: Courtesy of the researchers, edited by MIT News. By Anne Trafton Every cell in your body contains the same genetic sequence, yet each cell expresses only a subset of those [&#8230;]"
            },
            "content": [
                {
                    "type": "text/html",
                    "language": null,
                    "base": "https://aihub.org/feed/",
                    "value": "<p><img alt=\"\" class=\"aligncenter size-full wp-image-16891\" height=\"599\" src=\"https://aihub.org/wp-content/uploads/2025/02/MIT-AI-Genome-01-press_0.jpg\" width=\"900\" /><em>This image shows the three-dimensional genome structures of several chromosomes reported in a Dip-C study, which were used to train the new ChromoGen model. Credit: Courtesy of the researchers, edited by MIT News.</em></p>\n<p><strong>By Anne Trafton</strong></p>\n<p>Every cell in your body contains the same genetic sequence, yet each cell expresses only a subset of those genes. These cell-specific gene expression patterns, which ensure that a brain cell is different from a skin cell, are partly determined by the three-dimensional structure of the genetic material, which controls the accessibility of each gene.</p>\n<p>MIT chemists have now come up with a new way to determine those 3D genome structures, using generative artificial intelligence. Their technique can predict thousands of structures in just minutes, making it much speedier than existing experimental methods for analyzing the structures.</p>\n<p>Using this technique, researchers could more easily study how the 3D organization of the genome affects individual cells\u2019 gene expression patterns and functions.</p>\n<p>\u201cOur goal was to try to predict the three-dimensional genome structure from the underlying DNA sequence,\u201d says Bin Zhang, an associate professor of chemistry and the senior author of the study. \u201cNow that we can do that, which puts this technique on par with the cutting-edge experimental techniques, it can really open up a lot of interesting opportunities.\u201d</p>\n<p>MIT graduate students Greg Schuette and Zhuohan Lao are the lead authors of the <a href=\"https://doi.org/10.1126/sciadv.adr8265\">paper</a>, which appears in Science Advances.</p>\n<h4>From sequence to structure</h4>\n<p>Inside the cell nucleus, DNA and proteins form a complex called chromatin, which has several levels of organization, allowing cells to cram 2 meters of DNA into a nucleus that is only one-hundredth of a millimeter in diameter. Long strands of DNA wind around proteins called histones, giving rise to a structure somewhat like beads on a string.</p>\n<p>Chemical tags known as epigenetic modifications can be attached to DNA at specific locations, and these tags, which vary by cell type, affect the folding of the chromatin and the accessibility of nearby genes. These differences in chromatin conformation help determine which genes are expressed in different cell types, or at different times within a given cell.</p>\n<p>Over the past 20 years, scientists have developed experimental techniques for determining chromatin structures. One widely used technique, known as Hi-C, works by linking together neighboring DNA strands in the cell\u2019s nucleus. Researchers can then determine which segments are located near each other by shredding the DNA into many tiny pieces and sequencing it.</p>\n<p>This method can be used on large populations of cells to calculate an average structure for a section of chromatin, or on single cells to determine structures within that specific cell. However, Hi-C and similar techniques are labor-intensive, and it can take about a week to generate data from one cell.</p>\n<p>To overcome those limitations, Zhang and his students developed a model that takes advantage of recent advances in generative AI to create a fast, accurate way to predict chromatin structures in single cells. The AI model that they designed can quickly analyze DNA sequences and predict the chromatin structures that those sequences might produce in a cell.</p>\n<p>\u201cDeep learning is really good at pattern recognition,\u201d Zhang says. \u201cIt allows us to analyze very long DNA segments, thousands of base pairs, and figure out what is the important information encoded in those DNA base pairs.\u201d</p>\n<p>ChromoGen, the model that the researchers created, has two components. The first component, a deep learning model taught to \u201cread\u201d the genome, analyzes the information encoded in the underlying DNA sequence and chromatin accessibility data, the latter of which is widely available and cell type-specific.</p>\n<p>The second component is a generative AI model that predicts physically accurate chromatin conformations, having been trained on more than 11 million chromatin conformations. These data were generated from experiments using Dip-C (a variant of Hi-C) on 16 cells from a line of human B lymphocytes.</p>\n<p>When integrated, the first component informs the generative model how the cell type-specific environment influences the formation of different chromatin structures, and this scheme effectively captures sequence-structure relationships. For each sequence, the researchers use their model to generate many possible structures. That\u2019s because DNA is a very disordered molecule, so a single DNA sequence can give rise to many different possible conformations.</p>\n<p>\u201cA major complicating factor of predicting the structure of the genome is that there isn\u2019t a single solution that we\u2019re aiming for. There\u2019s a distribution of structures, no matter what portion of the genome you\u2019re looking at. Predicting that very complicated, high-dimensional statistical distribution is something that is incredibly challenging to do,\u201d Schuette says.</p>\n<h4>Rapid analysis</h4>\n<p>Once trained, the model can generate predictions on a much faster timescale than Hi-C or other experimental techniques.</p>\n<p>\u201cWhereas you might spend six months running experiments to get a few dozen structures in a given cell type, you can generate a thousand structures in a particular region with our model in 20 minutes on just one GPU,\u201d Schuette says.</p>\n<p>After training their model, the researchers used it to generate structure predictions for more than 2,000 DNA sequences, then compared them to the experimentally determined structures for those sequences. They found that the structures generated by the model were the same or very similar to those seen in the experimental data.</p>\n<p>\u201cWe typically look at hundreds or thousands of conformations for each sequence, and that gives you a reasonable representation of the diversity of the structures that a particular region can have,\u201d Zhang says. \u201cIf you repeat your experiment multiple times, in different cells, you will very likely end up with a very different conformation. That\u2019s what our model is trying to predict.\u201d</p>\n<p>The researchers also found that the model could make accurate predictions for data from cell types other than the one it was trained on. This suggests that the model could be useful for analyzing how chromatin structures differ between cell types, and how those differences affect their function. The model could also be used to explore different chromatin states that can exist within a single cell, and how those changes affect gene expression.</p>\n<p>\u201cChromoGen provides a new framework for AI-driven discovery of genome folding principles and demonstrates that generative AI can bridge genomic and epigenomic features with 3D genome structure, pointing to future work on studying the variation of genome structure and function across a broad range of biological contexts,\u201d says Jian Ma, a professor of computational biology at Carnegie Mellon University, who was not involved in the research.</p>\n<p>Another possible application would be to explore how mutations in a particular DNA sequence change the chromatin conformation, which could shed light on how such mutations may cause disease.</p>\n<p>\u201cThere are a lot of interesting questions that I think we can address with this type of model,\u201d Zhang says.</p>\n<p>The researchers have made all of their data and the model <a href=\"https://github.com/ZhangGroup-MITChemistry/ChromoGen\">available</a> to others who wish to use it.</p>\n<p>The research was funded by the National Institutes of Health.</p>\n<h4>Read the research in full</h4>\n<p><a href=\"https://www.science.org/doi/10.1126/sciadv.adr8265\">ChromoGen: Diffusion model predicts single-cell chromatin conformations</a>, <em>Greg Schuette, Zhuohan Lao, and Bin Zhang</em>.</p>"
                }
            ]
        },
        {
            "title": "Interview with Kunpeng Xu: Kernel representation learning for time series",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "https://aihub.org/feed/",
                "value": "Interview with Kunpeng Xu: Kernel representation learning for time series"
            },
            "links": [
                {
                    "rel": "alternate",
                    "type": "text/html",
                    "href": "https://aihub.org/2025/02/11/interview-with-kunpeng-xu-kernel-representation-learning-for-time-series/"
                }
            ],
            "link": "https://aihub.org/2025/02/11/interview-with-kunpeng-xu-kernel-representation-learning-for-time-series/",
            "authors": [
                {
                    "name": "Lucy Smith"
                }
            ],
            "author": "Lucy Smith",
            "author_detail": {
                "name": "Lucy Smith"
            },
            "published": "Tue, 11 Feb 2025 09:57:50 +0000",
            "published_parsed": [
                2025,
                2,
                11,
                9,
                57,
                50,
                1,
                42,
                0
            ],
            "tags": [
                {
                    "term": "opinions",
                    "scheme": null,
                    "label": null
                },
                {
                    "term": "AAAI",
                    "scheme": null,
                    "label": null
                },
                {
                    "term": "AAAI Doctoral Consortium",
                    "scheme": null,
                    "label": null
                },
                {
                    "term": "AAAI2025",
                    "scheme": null,
                    "label": null
                },
                {
                    "term": "ACM SIGAI",
                    "scheme": null,
                    "label": null
                }
            ],
            "id": "https://aihub.org/?p=16870",
            "guidislink": false,
            "summary": "In this interview series, we\u2019re meeting some of the AAAI/SIGAI Doctoral Consortium participants to find out more about their research. The Doctoral Consortium provides an opportunity for a group of PhD students to discuss and explore their research interests and career objectives in an interdisciplinary workshop together with a panel of established researchers. In the [&#8230;]",
            "summary_detail": {
                "type": "text/html",
                "language": null,
                "base": "https://aihub.org/feed/",
                "value": "In this interview series, we\u2019re meeting some of the AAAI/SIGAI Doctoral Consortium participants to find out more about their research. The Doctoral Consortium provides an opportunity for a group of PhD students to discuss and explore their research interests and career objectives in an interdisciplinary workshop together with a panel of established researchers. In the [&#8230;]"
            },
            "content": [
                {
                    "type": "text/html",
                    "language": null,
                    "base": "https://aihub.org/feed/",
                    "value": "<img alt=\"\" class=\"aligncenter size-full wp-image-16871\" height=\"1707\" src=\"https://aihub.org/wp-content/uploads/2025/02/prof_pic_format1-scaled.jpg\" width=\"2560\" />\n<p>In this interview series, we\u2019re meeting some of the <a href=\"https://aaai.org/conference/aaai/aaai-25/doctoral-consortium/\">AAAI/SIGAI Doctoral Consortium</a> participants to find out more about their research. The Doctoral Consortium provides an opportunity for a group of PhD students to discuss and explore their research interests and career objectives in an interdisciplinary workshop together with a panel of established researchers. In the first of our interviews with the 2025 cohort, we meet Kunpeng (Chris) Xu and find out more about his research and future plans. </p>\n<h4>Tell us a bit about your PhD &#8211; where are you studying, and what is the topic of your research?</h4>\n<p>Hi! I\u2019m Kunpeng (Chris). I am a final-year Ph.D. student at the ProspectUs-Lab, Universit\u00e9 de Sherbrooke, Canada, where I have been working with Professor Shengrui Wang and Professor Lifei Chen since 2021.</p>\n<p>My research spans time series analysis, kernel learning, and self-representation learning, with a focus on forecasting, pattern mining, concept drift adaptation, and interpretability in sequential data. I explore data-driven kernel representation learning to develop more adaptive and expressive models for complex time series, while also investigating subspace learning and its applications in AI. I am also interested in AI4Science, particularly in understanding regime shifts in atmospheric and oceanic systems within environmental ecology, as well as phase transitions in physics.</p>\n<h4>Could you give us an overview of the research you\u2019ve carried out during your PhD?</h4>\n<p>During my PhD, I have explored various aspects of Kernel Representation Learning (KRL) for time series, progressing from foundational research to more complex and dynamic applications.</p>\n<p>In my first year, I focused on self-representation learning and multiple kernel learning, applying them to multi-modal categorical sequences, where each modality was modeled using a separate kernel. This work demonstrated the power of kernel-based methods in capturing structured dependencies across different modalities.</p>\n<p>As I continued my research, I wanted to make these models more adaptive \u2013 could we learn the kernel itself rather than predefining it? This question led me to explore data-driven kernel learning, where the model directly learns the kernel from the data rather than relying on manually chosen functions. This shift significantly improved the adaptability and generalization of kernel-based methods.</p>\n<p>In my third year, I extended kernel representation learning to high-dimensional and dynamically evolving time series. I developed a framework that models multiple time series as an evolving ecosystem, allowing us to track nonlinear relationships and structural changes over time. This approach has been particularly effective in domains such as finance and healthcare, where detecting patterns and adapting to concept drift is crucial. Through kernel-induced representation learning, my research addresses challenges in dynamic environments, concept drift adaptation, and regime-switching modeling, ultimately improving both predictive accuracy and interpretability in real-world applications.</p>\n<p>Finally, as a final-year PhD student, I will introduce my doctoral research &#8211; <em>\u201cKernel Representation Learning for Time Sequence: Algorithm, Theory, and Applications\u201d</em>, at the 2025 AAAI/SIGAI Doctoral Consortium, where I will be sharing my work on the theoretical foundations, algorithmic advancements, and practical applications of KRL in time series analysis. (See figure below.)</p>\n<img alt=\"\" class=\"aligncenter size-full wp-image-16874\" height=\"970\" src=\"https://aihub.org/wp-content/uploads/2025/02/AAAI2025_DC.png\" width=\"1950\" />\n<h4>Is there an aspect of your research that has been particularly interesting?</h4>\n<p>One of the most fascinating aspects of my research has been modeling multiple time series as an evolving ecosystem using Kernel Representation Learning (KRL). Traditional time series models often assume static relationships between variables, but in real-world scenarios \u2013 such as financial markets, healthcare monitoring, and environmental systems \u2013 these relationships are constantly shifting due to external factors and internal dependencies.</p>\n<p>By treating time series as an evolving ecosystem, my research allows us to track how dependencies change over time, adapt to concept drift, and uncover hidden structures that are not easily captured by traditional models. This approach has been particularly exciting because it provides a new perspective on dynamic environments, enabling models to automatically learn adaptive representations and capture nonlinear relationships between sequences in a principled way.</p>\n<p>Additionally, bridging kernel methods with deep learning approaches \u2013 such as transformers, diffusion models, and Kolmogorov-Arnold Networks (KAN) \u2013 has been a particularly rewarding challenge. It has opened up new ways to combine mathematical rigor with the flexibility of modern deep learning, leading to models that are not only highly predictive but also interpretable \u2013 a crucial factor in domains like finance and healthcare where decision-making needs to be transparent and reliable.</p>\n<h4>I understand that you spent a year as a visiting scholar at an autonomous driving research institute. Could you talk a bit about that experience?</h4>\n<p>During my PhD, I had the opportunity to work as a visiting scholar at UISEE, a leading autonomous driving research institute whose CEO also served as the Director of Intel Labs China. This experience was particularly enriching, as it allowed me to apply my expertise in sequence modeling and machine learning to real-world decision-making problems in self-driving systems.</p>\n<p>I still remember the moment I got my first interview call \u2013 I was playing basketball when my phone suddenly rang. The conversation lasted a long time, as we discussed my research and how it could be applied to motion planning and decision-making in autonomous driving systems. When I finally got the news that I had passed the interview and was offered the highest recognition available for an intern \u2013 a visiting scholar position \u2013 I was so excited. It was a great validation of my work and an exciting step into a new application domain.</p>\n<p>At UISEE, my work primarily focused on lane-change decision-making for autonomous vehicles. The challenge was to develop models capable of effectively predicting and adapting to complex and uncertain driving environments. Unlike traditional time series problems, autonomous driving involves real-time multi-agent interactions, where models must not only predict future states but also make optimal decisions under uncertainty. I explored reinforcement learning and sequence modeling techniques to improve decision robustness, particularly in scenarios where vehicles needed to navigate dynamic traffic conditions and interact unpredictably with human drivers. As part of this research, I published a paper and contributed to a patent application, which provided me with valuable experience and deeper insights into the practical challenges of applying AI in autonomous systems.</p>\n<h4>Your next position will be as a postdoc at McGill University. What research will you be focusing on there?</h4>\n<p>I\u2019m going to be a postdoctoral fellow at McGill University, where I will work with Professor Yue Li and Professor Archer Y. Yang, focusing on representation learning and explainable AI (XAI) for healthcare data. My research will involve developing adaptive and interpretable models for analyzing electronic health records (EHRs), multi-modal patient data, and biomedical signals to improve predictive modeling and decision support in healthcare.</p>\n<p>I aim to investigate the representation learning foundation model, focusing on how to design structured, efficient, and interpretable models. This includes studying the expressivity of neural architectures, the stability of learned representations under perturbations, and the role of inductive biases in model generalization. Additionally, I will explore how advances in large language models (LLMs) and generative AI can be integrated into structured healthcare data analysis, particularly in areas such as causal reasoning, uncertainty quantification, and robust inference. By combining mathematical rigor with practical considerations, we hope to develop models that not only improve predictive performance but also provide deeper theoretical insights into the mechanisms of learning and decision-making in complex medical systems.</p>\n<h4>What advice would you give to someone thinking of doing a PhD in the field?</h4>\n<p>Pursuing a PhD is a challenging yet rewarding journey that requires passion, resilience, and adaptability. Much like fitness training, the process can often feel tedious, and there will be times when you feel like giving up. Progress may seem slow, and the daily grind of research \u2013 reading papers, debugging models, revising manuscripts \u2013 can be frustrating. However, just as in fitness, the real results come with consistency and long-term effort. The breakthroughs, the deep understanding, and the ability to push the boundaries of knowledge only emerge after persistent effort over time. Staying motivated, celebrating small wins, and embracing the learning process will help you push through the challenging moments and ultimately make your PhD journey fulfilling.</p>\n<h4>Could you tell us an interesting (non-AI related) fact about you?</h4>\n<p>Outside of research, I have a deep passion for sports and fitness. I was a member of the university\u2019s basketball team and also had the honor of winning the Sherbrooke Badminton Championship. I enjoy basketball, swimming, and badminton, and I find that staying active helps me clear my mind and maintain a balanced lifestyle. Beyond competitive sports, fitness is an essential part of my daily routine \u2013 I make it a priority to work out every day.</p>\n<p>I also love photography, especially capturing landscapes and cityscapes during my travels. Exploring new places through the lens allows me to appreciate details that often go unnoticed, much like uncovering hidden patterns in data.</p>\n<h4>About Kunpeng</h4>\n<table border=\"0\" cellpadding=\"10\" cellspacing=\"0\" width=\"100%\">\n<tbody>\n<tr>\n<td align=\"left\" valign=\"top\" width=\"150\">\n<img alt=\"\" class=\"aligncenter size-full wp-image-16873\" height=\"632\" src=\"https://aihub.org/wp-content/uploads/2025/02/kunpeng.jpg\" width=\"525\" />\n</td>\n<td align=\"left\" valign=\"top\">\n<p><a href=\"https://kunpengxu.github.io/\">Kunpeng (Chris) Xu</a> is a final-year Ph.D. student in Computer Science at Universit\u00e9 de Sherbrooke (UdeS), supervised by Professor Shengrui Wang, and an incoming Postdoctoral Fellow at McGill University, where he will work with Professor Yue Li and Professor Archer Y. Yang. His research focuses on time series analysis, kernel learning, and self-representation learning, with applications in forecasting, concept drift adaptation, and interpretability. He spent a year as a visiting scholar at UISEE, where he worked on reinforcement learning for autonomous driving, and collaborated with Laplace Insights to study regime switching in financial time series. He has also served as the Session Chair at PAKDD 2024 and as a Program Committee (PC) member for top conferences, such as NeurIPS, ICLR, ICML, AAAI, IJCAI, ICDM, KDD, etc. He is also a reviewer for leading journals, including IEEE TKDE, IEEE TNNLS, ESWA, KBS, and PR.</p>\n</td>\n</tr>\n</tbody>\n</table>"
                }
            ]
        },
        {
            "title": "The Children\u2019s AI Summit \u2013 an event from The Turing Institute",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "https://aihub.org/feed/",
                "value": "The Children\u2019s AI Summit \u2013 an event from The Turing Institute"
            },
            "links": [
                {
                    "rel": "alternate",
                    "type": "text/html",
                    "href": "https://aihub.org/2025/02/10/the-childrens-ai-summit-an-event-from-the-turing-institute/"
                }
            ],
            "link": "https://aihub.org/2025/02/10/the-childrens-ai-summit-an-event-from-the-turing-institute/",
            "authors": [
                {
                    "name": "Lucy Smith"
                }
            ],
            "author": "Lucy Smith",
            "author_detail": {
                "name": "Lucy Smith"
            },
            "published": "Mon, 10 Feb 2025 12:01:57 +0000",
            "published_parsed": [
                2025,
                2,
                10,
                12,
                1,
                57,
                0,
                41,
                0
            ],
            "tags": [
                {
                    "term": "education",
                    "scheme": null,
                    "label": null
                },
                {
                    "term": "quick read",
                    "scheme": null,
                    "label": null
                }
            ],
            "id": "https://aihub.org/?p=16881",
            "guidislink": false,
            "summary": "Hanna Barakat &#038; Cambridge Diversity Fund / Better Images of AI / Data Lab Dialogue / Licenced by CC-BY 4.0 On Tuesday 4th February 2025, the Children&#8217;s AI Summit brought together around 150 children from across the UK to share their messages for global leaders, policymakers, and AI developers on what the future of AI [&#8230;]",
            "summary_detail": {
                "type": "text/html",
                "language": null,
                "base": "https://aihub.org/feed/",
                "value": "Hanna Barakat &#038; Cambridge Diversity Fund / Better Images of AI / Data Lab Dialogue / Licenced by CC-BY 4.0 On Tuesday 4th February 2025, the Children&#8217;s AI Summit brought together around 150 children from across the UK to share their messages for global leaders, policymakers, and AI developers on what the future of AI [&#8230;]"
            },
            "content": [
                {
                    "type": "text/html",
                    "language": null,
                    "base": "https://aihub.org/feed/",
                    "value": "<p><em><img alt=\"A computer lab with three rows of four desks, each occupied by students working at computers. Overlaying the computer lab are red lines connecting through nodes, symbolizing the flow of communication, data exchange, and interconnected networks. \" class=\"aligncenter size-full wp-image-16885\" height=\"1842\" src=\"https://aihub.org/wp-content/uploads/2025/02/HannaBarakat-CambridgeDiversity-FundDataLab-Dialogue-1280x1842-1.png\" width=\"1280\" /><a href=\"https://aihub.org/feed/www.hbarakat.com\">Hanna Barakat</a> &#038; <a href=\"https://www.race-equality.admin.cam.ac.uk/university-diversity-fund\">Cambridge Diversity Fund</a> / <a href=\"https://www.betterimagesofai.org\">Better Images of AI</a> / Data Lab Dialogue / <a href=\"https://creativecommons.org/licenses/by/4.0/\">Licenced by CC-BY 4.0</a></em></p>\n<p>On Tuesday 4th February 2025, the <a href=\"https://www.turing.ac.uk/events/childrens-ai-summit\">Children&#8217;s AI Summit</a> brought together around 150 children from across the UK to share their messages for global leaders, policymakers, and AI developers on what the future of AI should look like. </p>\n<p>Hosted by the <a href=\"https://www.turing.ac.uk/research/research-projects/children-and-ai\">Children and AI</a> team in The Alan Turing Institute\u2019s Public Policy Programme and Queen Mary University of London, the event aimed to put children&#8217;s voices and experiences centre stage by exploring how the technology impacts young people today, and how children can shape its future. </p>\n<p>As part of the summit, a <a href=\"https://www.turing.ac.uk/sites/default/files/2025-02/childrens_manifesto_for_the_future_of_ai.pdf\">Children&#8217;s Manifesto for the Future of AI</a> was developed. This incorporates ideas that were submitted in the run-up to the event, and was refined with the help of summit participants. </p>\n<p>The Turing\u2019s Children and AI team are attending the <a href=\"https://www.elysee.fr/en/sommet-pour-l-action-sur-l-ia\">Paris AI Action Summit</a> this week and will be taking the Children\u2019s Manifesto for the Future of AI with them, as well as screening a short film made at the Children\u2019s AI Summit. You can watch this film below: </p>\n<div class=\"keep-aspect\"></div>\n<p></p>\n<h4>Find out more</h4>\n<ul>\n<li><a href=\"https://www.turing.ac.uk/events/childrens-ai-summit\">Children&#8217;s AI Summit</a></li>\n<li><a href=\"https://www.turing.ac.uk/sites/default/files/2025-02/childrens_manifesto_for_the_future_of_ai.pdf\">Children&#8217;s Manifesto for the Future of AI</a></li>\n<li><a href=\"https://www.elysee.fr/en/sommet-pour-l-action-sur-l-ia\">Paris AI Action Summit</a></li>\n</ul>"
                }
            ]
        },
        {
            "title": "AIhub coffee corner: Bad practice in the publication world",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "https://aihub.org/feed/",
                "value": "AIhub coffee corner: Bad practice in the publication world"
            },
            "links": [
                {
                    "rel": "alternate",
                    "type": "text/html",
                    "href": "https://aihub.org/2025/02/07/aihub-coffee-corner-bad-practice-in-the-publication-world/"
                }
            ],
            "link": "https://aihub.org/2025/02/07/aihub-coffee-corner-bad-practice-in-the-publication-world/",
            "authors": [
                {
                    "name": "AIhub"
                }
            ],
            "author": "AIhub",
            "author_detail": {
                "name": "AIhub"
            },
            "published": "Fri, 07 Feb 2025 14:41:06 +0000",
            "published_parsed": [
                2025,
                2,
                7,
                14,
                41,
                6,
                4,
                38,
                0
            ],
            "tags": [
                {
                    "term": "opinions",
                    "scheme": null,
                    "label": null
                },
                {
                    "term": "AAAI",
                    "scheme": null,
                    "label": null
                },
                {
                    "term": "coffee corner",
                    "scheme": null,
                    "label": null
                }
            ],
            "id": "https://aihub.org/?p=16868",
            "guidislink": false,
            "summary": "The AIhub coffee corner captures the musings of AI experts over a short conversation. This month we tackle the topic of bad practice in the sphere of publication. Joining the conversation this time are: Sanmay Das (Virginia Tech), Tom Dietterich (Oregon State University), Sabine Hauert (University of Bristol), and Sarit Kraus (Bar-Ilan University). Sabine Hauert: [&#8230;]",
            "summary_detail": {
                "type": "text/html",
                "language": null,
                "base": "https://aihub.org/feed/",
                "value": "The AIhub coffee corner captures the musings of AI experts over a short conversation. This month we tackle the topic of bad practice in the sphere of publication. Joining the conversation this time are: Sanmay Das (Virginia Tech), Tom Dietterich (Oregon State University), Sabine Hauert (University of Bristol), and Sarit Kraus (Bar-Ilan University). Sabine Hauert: [&#8230;]"
            },
            "content": [
                {
                    "type": "text/html",
                    "language": null,
                    "base": "https://aihub.org/feed/",
                    "value": "<img alt=\"AIhub coffee corner\" class=\"alignnone size-full wp-image-1184\" height=\"612\" src=\"https://aihub.org/wp-content/uploads/2020/02/AIhub-coffee-corner-1.jpg\" width=\"847\" />\n<p>The <a href=\"https://aihub.org/tag/coffee-corner/\">AIhub coffee corner</a> captures the musings of AI experts over a short conversation. This month we tackle the topic of bad practice in the sphere of publication. Joining the conversation this time are: Sanmay Das (Virginia Tech), Tom Dietterich (Oregon State University), Sabine Hauert (University of Bristol), and Sarit Kraus (Bar-Ilan University).</p>\n<p><strong>Sabine Hauert:</strong> Today\u2019s topic is bad practice in the publication world. For example, people trying to cheat the review system, paper mills. What bad behaviors have you seen, and is it really a problem?</p>\n<p><strong>Tom Dietterich:</strong> Well, I can talk about it from an arXiv point of view. The main bad behavior we see is citation stuffing. We&#8217;re seeing authors writing very low-quality papers that cite a bunch of references that are not really relevant to the paper. It seems that their goal is to have a paper that is good enough for arXiv to release, but they don&#8217;t want anybody to actually read it. They just want Google Scholar to index the citations. And we&#8217;ve seen it in various forms. The typical papers are things where they claim to be doing, say, heart disease using machine learning, but they&#8217;re just downloading the Cleveland heart dataset from the UCI repository, running standard machine learning algorithms on it, and writing up the results. They often have a very beautiful introduction, presumably written by ChatGPT, all about heart disease and its causes. But then, the references are irrelevant. </p>\n<p>I&#8217;ve seen other ones where it seemed like it was more or less a real paper, but for every citation they made that was relevant, they would have another one that was irrelevant. So, they all came in pairs. That&#8217;s the main thing we see, basically trying to boost citation counts by having things released on arXiv.</p>\n<p><strong>Sabine:</strong> And it does matter, this citation stuffing. I recently heard of a panel for faculty appointments. They screened a ton of applications and the ones that made it to the interview had great things going for them &#8211; they worked in interesting research areas, they had high h-indices, they were very productive. However, when the panel spoke to them, they realized that they had never worked with anyone in the field that they claimed to work in, it was just purely a niche they&#8217;d invented. They were very productive in gaming the system. Without talking to that person, they made it to the top of the pile. Unfortunately, that does remove a lot of people at the screening stage who didn&#8217;t play that game, so it really does matter that they&#8217;re doing that. Are there other examples of bad behavior that you\u2019ve seen?</p>\n<p><strong>Sarit Kraus:</strong> One example is sending the same paper to multiple conferences. Sometimes people will make small changes but usually they don\u2019t even try to make the papers different. Another problem is poor quality reviews. A lot of reviewers are using LLMs to write the review for them, but then they don\u2019t read the output before submitting the review. I don\u2019t mind the reviewers using a LLM to generate a review, as long as they read it and check the paper to see if it is reasonable. </p>\n<p><strong>Tom:</strong> One of my colleagues put jailbreak instructions in white text to ChatGPT into a homework assignment to find out how many students were using LLMs to answer the homework and were not reading the results. We could do that with every conference paper &#8211; embed something that encourages the LLM to output a certain phrase that we could then scan for. Basically, fingerprint the output.</p>\n<p><strong>Sabine:</strong> How big of a problem is bad practice? Is it 1% of submissions that are bad practice or is it something that&#8217;s really growing?</p>\n<p><strong>Tom:</strong> Of course, we only know the ones that we detect, but on arXiv it&#8217;s much less than 1%. In the machine learning category, we probably have 15,000 papers released under machine learning and maybe we found 5-10 with problems. But we don&#8217;t have any measure of our missed alarms.</p>\n<p><strong>Sabine:</strong> Should we do anything about it?</p>\n<p><strong>Tom:</strong> Well, the biggest problem I think has been the reviewing rings at conferences. I haven&#8217;t seen any of the evidence, but there are reports from ICML and NeurIPS. The big problem there is the bidding system for reviewers to bid on papers they want to review. That basically opens up people bidding on each other&#8217;s papers. We have to change how we assign reviewers to papers to break those rings up. We also lack an enforcement mechanism for punishing people who break the rules. The conferences don&#8217;t have legal staff, they don&#8217;t have all the processes in place to collect the evidence and be able to present it, and no one has the time to spend contacting the supervisors. What are the penalties that should be applied? What kind of due process should we have? The community needs to decide these things.</p>\n<p><strong>Sabine:</strong> It&#8217;s also a fine line because, in a small area of work you might bid for people&#8217;s papers that you know well because you happen to be in a small community. That might be a legitimate set of papers that you want to review, and you review them in an accurate way. </p>\n<p><strong>Sarit:</strong> Bidding may not be a good mechanism. At IJCAI, we utilize keywords and similar methods to assign papers to reviewers. However, we still have bidding, and I don\u2019t think this bidding is a good idea. However, I think that even if we remove the bidding system, we will still have a big problem. And the problem is, as Tom said, the lack of punishment. There is no punishment for fabricating, for cheating, nothing. It was good when we were a small community, and it was enough of a punishment for the rest of the community to know that somebody broke the rules.  If there was some entity that could take care of these events, that would be very useful. We are worried because if we put a name in the public domain, they can sue us, because we don&#8217;t have the legal backing. And we want to spend our time doing our research. We are volunteers, managing conferences, and once we finish organizing one, we want some quiet for a few years. </p>\n<p><strong>Sabine:</strong> Could part of this bad practice just be not knowing better, not knowing that this is not the way it&#8217;s done? Could more education help?</p>\n<p><strong>Sarit:</strong> No, it&#8217;s not education. People know that they are breaking the rules.</p>\n<p><strong>Tom:</strong> I mean, they&#8217;re exchanging paper titles with each other so they know who has authored which papers.</p>\n<p><strong>Sabine:</strong> Yes, that&#8217;s explicit.</p>\n<p><strong>Sarit:</strong> The benefit of cheating is much higher than the risk of being caught because you are not getting punished. If your paper is not accepted at the current conference, you can just submit it to another conference next year. </p>\n<p><strong>Tom:</strong> There is this joint body, the <a href=\"https://aisocc.org/\">Artificial Intelligence Scientific Organizations Coordinating Council (AISOCC)</a>, that AAAI has been helping to establish. It is trying to get people from many conferences to talk to each other about these kinds of issues. I think OpenReview, which supports the review process for most of the machine learning conferences, has information that they can pool across conferences. NeurIPS recently revised their <a href=\"https://neurips.cc/public/CodeOfConduct\">Code of Conduct</a> to explicitly allow information sharing between sister organizations. </p>\n<p>My thought is that someplace like OpenReview could be the group that, if the various users pool funds, they can hire a legal team and establish a set of standards and terminology that could then be adopted by all the various conferences. And they could be the center of the enforcement mechanism as well.</p>\n<p><strong>Sabine:</strong> At the least, putting a little star next to papers suspected of bad practice.</p>\n<p><strong>Tom:</strong> I think that the goal then would be to go beyond that and actually publicize the rule breakers. Contact their management, get them fired.</p>\n<p><strong>Sanmay Das:</strong> I feel like conferences should be doing some coordination to at least have a common code of conduct, and we probably need legal advice to make sure that it goes the right way. I think the one thing that needs to be done is that, when people submit to a conference, they commit to a process which will be followed by the conference.  And if they are blacklisted by that process, they&#8217;ve agreed to that as a condition of submission. </p>\n<p>The other thing I have to point out though, is that there have been situations that I&#8217;ve been aware of where very senior people in the community are pretty clearly engaging in these kinds of practices. And they can defend themselves very strongly. And it&#8217;s hard to actually fully pin it down. They can claim that they didn\u2019t do any of this intentionally.  Nobody wants to get involved in a legal fight about this. </p>\n<p><strong>Sabine:</strong> I do wonder when people submit, whether they&#8217;re going to read all those rules [regarding LLM use, for example] when they click. However, if there was a short step where they were questioned on whether they\u2019d engaged in a particular bad practice, it might make them feel just bad enough so they don&#8217;t engage in it, or just make requirements explicit. I like to be hopeful about people. </p>\n<p><strong>Sarit:</strong> Before IJCAI 2019, I was like you, you know \u201cwhy will people cheat? We are all involved in research, that&#8217;s our life, why would a person cheat?\u201d But then, I encountered a case where someone managed to review their own paper. When confronted, they claimed it was their student who had submitted it. What could I do? I rejected all of that person\u2019s submissions for that conference, but I had no way to carry this information forward to the next event. Who knows if they repeated the behavior at the next conference?  I stopped being na\u00efve at that point.</p>"
                }
            ]
        },
        {
            "title": "Explained: Generative AI\u2019s environmental impact",
            "title_detail": {
                "type": "text/plain",
                "language": null,
                "base": "https://aihub.org/feed/",
                "value": "Explained: Generative AI\u2019s environmental impact"
            },
            "links": [
                {
                    "rel": "alternate",
                    "type": "text/html",
                    "href": "https://aihub.org/2025/02/06/explained-generative-ais-environmental-impact/"
                }
            ],
            "link": "https://aihub.org/2025/02/06/explained-generative-ais-environmental-impact/",
            "authors": [
                {
                    "name": "MIT News"
                }
            ],
            "author": "MIT News",
            "author_detail": {
                "name": "MIT News"
            },
            "published": "Thu, 06 Feb 2025 15:46:00 +0000",
            "published_parsed": [
                2025,
                2,
                6,
                15,
                46,
                0,
                3,
                37,
                0
            ],
            "tags": [
                {
                    "term": "articles",
                    "scheme": null,
                    "label": null
                }
            ],
            "id": "https://aihub.org/?p=16863",
            "guidislink": false,
            "summary": "Fritzchens Fritz / Better Images of AI / GPU shot etched 5 / Licenced by CC-BY 4.0 By Adam Zewe In a two-part series, MIT News explores the environmental implications of generative AI. In this article, we look at why this technology is so resource-intensive. A second piece will investigate what experts are doing to [&#8230;]",
            "summary_detail": {
                "type": "text/html",
                "language": null,
                "base": "https://aihub.org/feed/",
                "value": "Fritzchens Fritz / Better Images of AI / GPU shot etched 5 / Licenced by CC-BY 4.0 By Adam Zewe In a two-part series, MIT News explores the environmental implications of generative AI. In this article, we look at why this technology is so resource-intensive. A second piece will investigate what experts are doing to [&#8230;]"
            },
            "content": [
                {
                    "type": "text/html",
                    "language": null,
                    "base": "https://aihub.org/feed/",
                    "value": "<p><img alt=\"Abstract microscopic photography of a Graphics Processing Unit resembling a satellite image of a big city\" class=\"aligncenter size-full wp-image-11829\" height=\"533\" src=\"https://aihub.org/wp-content/uploads/2023/03/FritzchensFritz-GPUshot-etched-5-799x533-1.jpg\" width=\"799\" /><em><a href=\"https://www.flickr.com/photos/130561288@N04/\">Fritzchens Fritz</a> / <a href=\"https://www.betterimagesofai.org\">Better Images of AI</a> / GPU shot etched 5 / <a href=\"https://creativecommons.org/licenses/by/4.0/\">Licenced by CC-BY 4.0</a></em></p>\n<p><strong>By Adam Zewe</strong></p>\n<p><em>In a two-part series,</em> MIT News <em>explores the environmental implications of <a href=\"https://news.mit.edu/2023/explained-generative-ai-1109\">generative AI</a>. In this article, we look at why this technology is so resource-intensive. A second piece will investigate what experts are doing to reduce genAI\u2019s carbon footprint and other impacts.</em></p>\n<p>The excitement surrounding potential benefits of generative AI, from improving worker productivity to advancing scientific research, is hard to ignore. While the explosive growth of this new technology has enabled rapid deployment of powerful models in many industries, the environmental consequences of this generative AI \u201cgold rush\u201d remain difficult to pin down, let alone mitigate.</p>\n<p>The computational power required to train generative AI models that often have billions of parameters, such as OpenAI\u2019s GPT-4, can demand a staggering amount of electricity, which leads to increased carbon dioxide emissions and pressures on the electric grid.</p>\n<p>Furthermore, deploying these models in real-world applications, enabling millions to use generative AI in their daily lives, and then fine-tuning the models to improve their performance draws large amounts of energy long after a model has been developed.</p>\n<p>Beyond electricity demands, a great deal of water is needed to cool the hardware used for training, deploying, and fine-tuning generative AI models, which can strain municipal water supplies and disrupt local ecosystems. The increasing number of generative AI applications has also spurred demand for high-performance computing hardware, adding indirect environmental impacts from its manufacture and transport.</p>\n<p>\u201cWhen we think about the environmental impact of generative AI, it is not just the electricity you consume when you plug the computer in. There are much broader consequences that go out to a system level and persist based on actions that we take,\u201d says Elsa A. Olivetti, professor in the Department of Materials Science and Engineering and the lead of the Decarbonization Mission of MIT\u2019s new <a href=\"https://climateproject.mit.edu/\">Climate Project</a>.</p>\n<p>Olivetti is senior author of a 2024 paper, <a href=\"https://mit-genai.pubpub.org/pub/8ulgrckc/release/2\">\u201cThe Climate and Sustainability Implications of Generative AI,\u201d</a> co-authored by MIT colleagues in response to an Institute-wide call for papers that explore the transformative potential of generative AI, in both positive and negative directions for society.</p>\n<h4>Demanding data centers</h4>\n<p>The electricity demands of data centers are one major factor contributing to the environmental impacts of generative AI, since data centers are used to train and run the deep learning models behind popular tools like ChatGPT and DALL-E.</p>\n<p>A data center is a temperature-controlled building that houses computing infrastructure, such as servers, data storage drives, and network equipment. For instance, Amazon has more than <a href=\"https://aws.amazon.com/about-aws/global-infrastructure/\">100 data centers worldwide</a>, each of which has about 50,000 servers that the company uses to support cloud computing services.</p>\n<p>While data centers have been around since the 1940s (the first was built at the University of Pennsylvania in 1945 to support the <a href=\"https://www.seas.upenn.edu/about/history-heritage/eniac/\">first general-purpose digital computer</a>, the ENIAC), the rise of generative AI has dramatically increased the pace of data center construction.</p>\n<p>\u201cWhat is different about generative AI is the power density it requires. Fundamentally, it is just computing, but a generative AI training cluster might consume seven or eight times more energy than a typical computing workload,\u201d says Noman Bashir, lead author of the impact paper, who is a Computing and Climate Impact Fellow at MIT Climate and Sustainability Consortium (MCSC) and a postdoc in the Computer Science and Artificial Intelligence Laboratory (CSAIL).</p>\n<p>Scientists have estimated that the power requirements of data centers in North America increased from 2,688 megawatts at the end of 2022 to 5,341 megawatts at the end of 2023, partly driven by the demands of generative AI. Globally, the electricity consumption of data centers rose to 460 terawatts in 2022. This would have made data centers the 11th largest electricity consumer in the world, between the nations of Saudi Arabia (371 terawatts) and France (463 terawatts), according to the Organization for Economic Co-operation and Development.</p>\n<p>By 2026, the electricity consumption of data centers is expected to approach 1,050 terawatts (which would bump data centers up to fifth place on the global list, between Japan and Russia).</p>\n<p>While not all data center computation involves generative AI, the technology has been a major driver of increasing energy demands.</p>\n<p>\u201cThe demand for new data centers cannot be met in a sustainable way. The pace at which companies are building new data centers means the bulk of the electricity to power them must come from fossil fuel-based power plants,\u201d says Bashir.</p>\n<p>The power needed to train and deploy a model like OpenAI\u2019s GPT-3 is difficult to ascertain. In a 2021 research paper, scientists from Google and the University of California at Berkeley estimated the training process alone consumed 1,287 megawatt hours of electricity (enough to power about 120 average U.S. homes for a year), generating about 552 tons of carbon dioxide.</p>\n<p>While all machine-learning models must be trained, one issue unique to generative AI is the rapid fluctuations in energy use that occur over different phases of the training process, Bashir explains.</p>\n<p>Power grid operators must have a way to absorb those fluctuations to protect the grid, and they usually employ <a href=\"https://aihub.org/feed/\">diesel-based generators</a> for that task.</p>\n<h4>Increasing impacts from inference</h4>\n<p>Once a generative AI model is trained, the energy demands don\u2019t disappear.</p>\n<p>Each time a model is used, perhaps by an individual asking ChatGPT to summarize an email, the computing hardware that performs those operations consumes energy. Researchers have estimated that a ChatGPT query consumes about five times more electricity than a simple web search.</p>\n<p>\u201cBut an everyday user doesn\u2019t think too much about that,\u201d says Bashir. \u201cThe ease-of-use of generative AI interfaces and the lack of information about the environmental impacts of my actions means that, as a user, I don\u2019t have much incentive to cut back on my use of generative AI.\u201d</p>\n<p>With traditional AI, the energy usage is split fairly evenly between data processing, model training, and inference, which is the process of using a trained model to make predictions on new data. However, Bashir expects the electricity demands of generative AI inference to eventually dominate since these models are becoming ubiquitous in so many applications, and the electricity needed for inference will increase as future versions of the models become larger and more complex.</p>\n<p>Plus, generative AI models have an especially short shelf-life, driven by rising demand for new AI applications. Companies release new models every few weeks, so the energy used to train prior versions goes to waste, Bashir adds. New models often consume more energy for training, since they usually have more parameters than their predecessors.</p>\n<p>While electricity demands of data centers may be getting the most attention in research literature, the amount of water consumed by these facilities has environmental impacts, as well.</p>\n<p>Chilled water is used to cool a data center by absorbing heat from computing equipment. It has been estimated that, for each kilowatt hour of energy a data center consumes, it would need two liters of water for cooling, says Bashir.</p>\n<p>\u201cJust because this is called \u2018cloud computing\u2019 doesn\u2019t mean the hardware lives in the cloud. Data centers are present in our physical world, and because of their water usage they have direct and indirect implications for biodiversity,\u201d he says.</p>\n<p>The computing hardware inside data centers brings its own, less direct environmental impacts.</p>\n<p>While it is difficult to estimate how much power is needed to manufacture a GPU, a type of powerful processor that can handle intensive generative AI workloads, it would be more than what is needed to produce a simpler CPU because the fabrication process is more complex. A GPU\u2019s carbon footprint is compounded by the emissions related to material and product transport.</p>\n<p>There are also environmental implications of obtaining the raw materials used to fabricate GPUs, which can involve dirty mining procedures and the use of toxic chemicals for processing.</p>\n<p>Market research firm TechInsights estimates that the three major producers (NVIDIA, AMD, and Intel) shipped 3.85 million GPUs to data centers in 2023, up from about 2.67 million in 2022. That number is expected to have increased by an even greater percentage in 2024.</p>\n<p>The industry is on an unsustainable path, but there are ways to encourage responsible development of generative AI that supports environmental objectives, Bashir says.</p>\n<p>He, Olivetti, and their MIT colleagues argue that this will require a comprehensive consideration of all the environmental and societal costs of generative AI, as well as a detailed assessment of the value in its perceived benefits.</p>\n<p>\u201cWe need a more contextual way of systematically and comprehensively understanding the implications of new developments in this space. Due to the speed at which there have been improvements, we haven\u2019t had a chance to catch up with our abilities to measure and understand the tradeoffs,\u201d Olivetti says.</p>"
                }
            ]
        }
    ]
}