{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curating data sources to get\n",
    "\n",
    "Asked chatgpt\n",
    " - Provide the top 20 AI related RSS Feeds. \n",
    " - Give me their URLs formatted as a markdown list\n",
    " - How were these ranked. What was the metric that was used to decide that they were popular ? _ChatGPT said that this was objectively ranked and picked from an online list._ It offered to get a more data-driven ranking based on \n",
    "   - `RSS Subscriber Count`\n",
    "   - `Domain Authority (DA)`: A score indicating how well the blog ranks on search engines\n",
    "   - `Traffic Analytics`: Using services like SimilarWeb or Alexa to measure the blog's web traffic.\n",
    "   - `Social Media Following and Engagement`: Number of followers, likes, and shares on platforms like Twitter, LinkedIn, etc.\n",
    "   - `Content Quality and Frequency`: Consistency and quality of posts.\n",
    "   - `Backlink Profile`: The number of reputable websites linking to the blog.\n",
    " - I said yes and it did provide me a ranking based on `Domain Authority` and `web traffic` metrics. The greater the DA score, the higher the `authority` of the link _(how well it'll rank on a search list)_. Basically, I could have googled this and taken the list from there.\n",
    "\n",
    "It gave me\n",
    "\n",
    "```markdown\n",
    "- [MIT News - Artificial Intelligence (DA 94)](http://news.mit.edu/rss/topic/artificial-intelligence)\n",
    "- [Google AI Blog (DA 93)](https://ai.googleblog.com/feeds/posts/default)\n",
    "- [DeepMind Blog (DA 91)](https://www.deepmind.com/blog/rss.xml)\n",
    "- [OpenAI Blog (DA 89)](https://openai.com/blog/rss/)\n",
    "- [KDnuggets (DA 85)](https://www.kdnuggets.com/feed)\n",
    "- [Analytics Vidhya (DA 82)](https://www.analyticsvidhya.com/feed/)\n",
    "- [Machine Learning Mastery (DA 78)](https://machinelearningmastery.com/feed/)\n",
    "- [BAIR Blog (DA 75)](https://bair.berkeley.edu/blog/feed.xml)\n",
    "- [Towards Data Science (DA 74)](https://towardsdatascience.com/feed)\n",
    "- [MarkTechPost (DA 72)](https://www.marktechpost.com/feed/)\n",
    "- [AIhub (DA 70)](https://aihub.org/feed/)\n",
    "- [Unite.AI (DA 68)](https://www.unite.ai/feed/)\n",
    "- [Artificial-Intelligence.Blog (DA 65)](https://artificial-intelligence.blog/feed/)\n",
    "```\n",
    "\n",
    "The following were present when I asked for the top-20 list but were not there in the list ranked by DA. Maybe ignore them for now.\n",
    "```markdown\n",
    "- [AI21 Labs Blog](https://www.ai21.com/blog/rss.xml)\n",
    "- [Adversa AI Blog](https://adversa.ai/feed/)\n",
    "- [Aurora Labs Blog](https://www.auroralabs.com/feed/)\n",
    "- [Run:AI Blog](https://www.run.ai/feed/)\n",
    "- [D-ID Blog](https://www.d-id.com/feed/)\n",
    "- [AI Accelerator Institute](https://aiacceleratorinstitute.com/rss)\n",
    "- [AI Summer](https://theaisummer.com/feed/)\n",
    "- [Becoming Human](https://becominghuman.ai/feed)\n",
    "```\n",
    "\n",
    "I am going to add\n",
    " - [Simon Willison - Atom only!](https://simonwillison.net/atom/entries/)\n",
    " - [Arxiv - for cs.AI category](https://rss.arxiv.org/rss/cs.AI) - See their [category taxonomy](https://arxiv.org/category_taxonomy) under the `cs` section.\n",
    " - If this was for real, I would add the people first. Karpathy, Willison and others. Emerging topics from the guys who marinate in this stuff are truly emerging. The generic blog and state-of-ai lists will be trailing indicators.\n",
    "\n",
    "When using `feedparser`, the following errored out so I gave up on them\n",
    " - ❌ MIT News - Artificial Intelligence\n",
    " - ❌ Google AI Blog\n",
    " - ❌ OpenAI Blog\n",
    " - ❌ Towards Data Science\n",
    " - ❌ Artificial-Intelligence.Blog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Control this when experimenting to prototype with just one feed\n",
    "ai_blogs = {\n",
    "    \"MIT News - Artificial Intelligence\": {\n",
    "        \"url\": \"http://news.mit.edu/rss/topic/artificial-intelligence\",\n",
    "        \"DA\": 94\n",
    "    },\n",
    "    \"Google AI Blog\": {\n",
    "        \"url\": \"https://ai.googleblog.com/feeds/posts/default\",\n",
    "        \"DA\": 93\n",
    "    },\n",
    "    \"DeepMind Blog\": {\n",
    "        \"url\": \"https://www.deepmind.com/blog/rss.xml\",\n",
    "        \"DA\": 91\n",
    "    },\n",
    "    \"OpenAI Blog\": {\n",
    "        \"url\": \"https://openai.com/blog/rss/\",\n",
    "        \"DA\": 89\n",
    "    },\n",
    "    \"Arxiv - cs.AI category\" : {\n",
    "        \"url\" : \"https://rss.arxiv.org/rss/cs.AI\",\n",
    "        \"DA\"  : 89  # manually obtained from ChatGPT for the parent domain.\n",
    "    },\n",
    "    \"KDnuggets\": {\n",
    "        \"url\": \"https://www.kdnuggets.com/feed\",\n",
    "        \"DA\": 85\n",
    "    },\n",
    "    \"Analytics Vidhya\": {\n",
    "        \"url\": \"https://www.analyticsvidhya.com/feed/\",\n",
    "        \"DA\": 82\n",
    "    },\n",
    "    \"Machine Learning Mastery\": {\n",
    "        \"url\": \"https://machinelearningmastery.com/feed/\",\n",
    "        \"DA\": 78\n",
    "    },\n",
    "    \"BAIR Blog\": {\n",
    "        \"url\": \"https://bair.berkeley.edu/blog/feed.xml\",\n",
    "        \"DA\": 75\n",
    "    },\n",
    "    \"Towards Data Science\": {\n",
    "        \"url\": \"https://towardsdatascience.com/feed\",\n",
    "        \"DA\": 74\n",
    "    },\n",
    "    \"MarkTechPost\": {\n",
    "        \"url\": \"https://www.marktechpost.com/feed/\",\n",
    "        \"DA\": 72\n",
    "    },\n",
    "    \"AIhub\": {\n",
    "        \"url\": \"https://aihub.org/feed/\",\n",
    "        \"DA\": 70\n",
    "    },\n",
    "    \"Unite.AI\": {\n",
    "        \"url\": \"https://www.unite.ai/feed/\",\n",
    "        \"DA\": 68\n",
    "    },\n",
    "    \"Artificial-Intelligence.Blog\": {\n",
    "        \"url\": \"https://artificial-intelligence.blog/feed/\",\n",
    "        \"DA\": 65\n",
    "    }\n",
    "    ,\n",
    "    \"Simon Willison\": {\n",
    "        \"url\": \"https://simonwillison.net/atom/entries/\",\n",
    "        \"DA\" : 1  # unavailable on ChatGPT. Says personal blogs typically have low DA.\n",
    "    }    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore what is actually in one of these feeds\n",
    "\n",
    "The main entries are of type (`FeedParserDict` which is json convertible). They look like this\n",
    "\n",
    "### Arxiv feed item\n",
    "\n",
    " - `title`\n",
    " - `title_detail \\ value` \n",
    " - `link`\n",
    " - `summary`\n",
    " - `summary_detail / value` has more detauls of the summary. There is an `Annount Type: new` annotation in there as well.\n",
    " - ` tags` containing `{term, schema, label}` with the term being `cs.AI, cs.SY etc` Short names\n",
    "   - short names to descriptive names ?? Man!   \n",
    "\n",
    "```json\n",
    "{\n",
    "    \"title\": \"AI-driven control of bioelectric signalling for real-time topological reorganization of cells\",\n",
    "    \"title_detail\": {\n",
    "        \"type\": \"text/plain\",\n",
    "        \"language\": null,\n",
    "        \"base\": \"https://rss.arxiv.org/rss/cs.AI\",\n",
    "        \"value\": \"AI-driven control of bioelectric signalling for real-time topological reorganization of cells\"\n",
    "    },\n",
    "    \"links\": [\n",
    "        {\n",
    "            \"rel\": \"alternate\",\n",
    "            \"type\": \"text/html\",\n",
    "            \"href\": \"https://arxiv.org/abs/2503.13489\"\n",
    "        }\n",
    "    ],\n",
    "    \"link\": \"https://arxiv.org/abs/2503.13489\",\n",
    "    \"summary\": \"arXiv:2503.13489v1 Announce Type: new \\nAbstract: Understanding and manipulating bioelectric signaling could present a new wave of progress in developmental biology, regenerative medicine, and synthetic biology. Bioelectric signals, defined as voltage gradients across cell membranes caused by ionic movements, play a role in regulating crucial processes including cellular differentiation, proliferation, apoptosis, and tissue morphogenesis. Recent studies demonstrate the ability to modulate these signals to achieve controlled tissue regeneration and morphological outcomes in organisms such as planaria and frogs. However, significant knowledge gaps remain, particularly in predicting and controlling the spatial and temporal dynamics of membrane potentials (V_mem), understanding their regulatory roles in tissue and organ development, and exploring their therapeutic potential in diseases. In this work we propose an experiment using Deep Reinforcement Learning (DRL) framework together with lab automation techniques for real-time manipulation of bioelectric signals to guide tissue regeneration and morphogenesis. The proposed framework should interact continuously with biological systems, adapting strategies based on direct biological feedback. Combining DRL with real-time measurement techniques -- such as optogenetics, voltage-sensitive dyes, fluorescent reporters, and advanced microscopy -- could provide a comprehensive platform for precise bioelectric control, leading to improved understanding of bioelectric mechanisms in morphogenesis, quantitative bioelectric models, identification of minimal experimental setups, and advancements in bioelectric modulation techniques relevant to regenerative medicine and cancer therapy. Ultimately, this research aims to utilize bioelectric signaling to develop new biomedical and bioengineering applications.\",\n",
    "    \"summary_detail\": {\n",
    "        \"type\": \"text/html\",\n",
    "        \"language\": null,\n",
    "        \"base\": \"https://rss.arxiv.org/rss/cs.AI\",\n",
    "        \"value\": \"arXiv:2503.13489v1 Announce Type: new \\nAbstract: Understanding and manipulating bioelectric signaling could present a new wave of progress in developmental biology, regenerative medicine, and synthetic biology. Bioelectric signals, defined as voltage gradients across cell membranes caused by ionic movements, play a role in regulating crucial processes including cellular differentiation, proliferation, apoptosis, and tissue morphogenesis. Recent studies demonstrate the ability to modulate these signals to achieve controlled tissue regeneration and morphological outcomes in organisms such as planaria and frogs. However, significant knowledge gaps remain, particularly in predicting and controlling the spatial and temporal dynamics of membrane potentials (V_mem), understanding their regulatory roles in tissue and organ development, and exploring their therapeutic potential in diseases. In this work we propose an experiment using Deep Reinforcement Learning (DRL) framework together with lab automation techniques for real-time manipulation of bioelectric signals to guide tissue regeneration and morphogenesis. The proposed framework should interact continuously with biological systems, adapting strategies based on direct biological feedback. Combining DRL with real-time measurement techniques -- such as optogenetics, voltage-sensitive dyes, fluorescent reporters, and advanced microscopy -- could provide a comprehensive platform for precise bioelectric control, leading to improved understanding of bioelectric mechanisms in morphogenesis, quantitative bioelectric models, identification of minimal experimental setups, and advancements in bioelectric modulation techniques relevant to regenerative medicine and cancer therapy. Ultimately, this research aims to utilize bioelectric signaling to develop new biomedical and bioengineering applications.\"\n",
    "    },\n",
    "    \"id\": \"oai:arXiv.org:2503.13489v1\",\n",
    "    \"guidislink\": false,\n",
    "    \"tags\": [\n",
    "        {\n",
    "            \"term\": \"cs.AI\",\n",
    "            \"scheme\": null,\n",
    "            \"label\": null\n",
    "        },\n",
    "        {\n",
    "            \"term\": \"cs.SY\",\n",
    "            \"scheme\": null,\n",
    "            \"label\": null\n",
    "        },\n",
    "        {\n",
    "            \"term\": \"eess.SY\",\n",
    "            \"scheme\": null,\n",
    "            \"label\": null\n",
    "        },\n",
    "        {\n",
    "            \"term\": \"physics.bio-ph\",\n",
    "            \"scheme\": null,\n",
    "            \"label\": null\n",
    "        },\n",
    "        {\n",
    "            \"term\": \"q-bio.CB\",\n",
    "            \"scheme\": null,\n",
    "            \"label\": null\n",
    "        },\n",
    "        {\n",
    "            \"term\": \"q-bio.QM\",\n",
    "            \"scheme\": null,\n",
    "            \"label\": null\n",
    "        }\n",
    "    ],\n",
    "    \"published\": \"Wed, 19 Mar 2025 00:00:00 -0400\",\n",
    "    \"published_parsed\": [\n",
    "        2025,\n",
    "        3,\n",
    "        19,\n",
    "        4,\n",
    "        0,\n",
    "        0,\n",
    "        2,\n",
    "        78,\n",
    "        0\n",
    "    ],\n",
    "    \"arxiv_announce_type\": \"new\",\n",
    "    \"rights\": \"http://creativecommons.org/licenses/by/4.0/\",\n",
    "    \"rights_detail\": {\n",
    "        \"type\": \"text/plain\",\n",
    "        \"language\": null,\n",
    "        \"base\": \"https://rss.arxiv.org/rss/cs.AI\",\n",
    "        \"value\": \"http://creativecommons.org/licenses/by/4.0/\"\n",
    "    },\n",
    "    \"authors\": [\n",
    "        {\n",
    "            \"name\": \"Gon\\\\c{c}alo Hora de Carvalho\"\n",
    "        }\n",
    "    ],\n",
    "    \"author\": \"Gon\\\\c{c}alo Hora de Carvalho\",\n",
    "    \"author_detail\": {\n",
    "        \"name\": \"Gon\\\\c{c}alo Hora de Carvalho\"\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "### Deepmind feed item\n",
    "\n",
    " - ❌ tags!\n",
    " - everything else\n",
    "\n",
    "### Simon Willisons blog item\n",
    "\n",
    "Is an `atom` feed unlike the `RSS` ones but it parses it just fine.\n",
    " - has tags\n",
    " - has everything else.\n",
    "\n",
    "OK. From this, I can extract a few basic things and just make gpt do the work using structured extraction I guess. Hopefully no contentflags otw manual mapping which is not too bad since everything is JSON. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feed title: Simon Willison's Weblog: Entries\n",
      "{\n",
      "    \"title\": \"Not all AI-assisted programming is vibe coding (but vibe coding rocks)\",\n",
      "    \"title_detail\": {\n",
      "        \"type\": \"text/plain\",\n",
      "        \"language\": \"en-us\",\n",
      "        \"base\": \"https://simonwillison.net/atom/entries/\",\n",
      "        \"value\": \"Not all AI-assisted programming is vibe coding (but vibe coding rocks)\"\n",
      "    },\n",
      "    \"links\": [\n",
      "        {\n",
      "            \"href\": \"https://simonwillison.net/2025/Mar/19/vibe-coding/#atom-entries\",\n",
      "            \"rel\": \"alternate\",\n",
      "            \"type\": \"text/html\"\n",
      "        }\n",
      "    ],\n",
      "    \"link\": \"https://simonwillison.net/2025/Mar/19/vibe-coding/#atom-entries\",\n",
      "    \"published\": \"2025-03-19T17:57:18+00:00\",\n",
      "    \"published_parsed\": [\n",
      "        2025,\n",
      "        3,\n",
      "        19,\n",
      "        17,\n",
      "        57,\n",
      "        18,\n",
      "        2,\n",
      "        78,\n",
      "        0\n",
      "    ],\n",
      "    \"updated\": \"2025-03-19T17:57:18+00:00\",\n",
      "    \"updated_parsed\": [\n",
      "        2025,\n",
      "        3,\n",
      "        19,\n",
      "        17,\n",
      "        57,\n",
      "        18,\n",
      "        2,\n",
      "        78,\n",
      "        0\n",
      "    ],\n",
      "    \"id\": \"https://simonwillison.net/2025/Mar/19/vibe-coding/#atom-entries\",\n",
      "    \"guidislink\": false,\n",
      "    \"summary\": \"<p><strong>Vibe coding</strong> is having a moment. The term <a href=\\\"https://twitter.com/karpathy/status/1886192184808149383\\\">was coined by Andrej Karpathy</a> just a few weeks ago (on February 6th) and has since been featured <a href=\\\"https://www.nytimes.com/2025/02/27/technology/personaltech/vibecoding-ai-software-programming.html\\\">in the New York Times</a>, <a href=\\\"https://arstechnica.com/ai/2025/03/is-vibe-coding-with-ai-gnarly-or-reckless-maybe-some-of-both/\\\">Ars Technica</a>, <a href=\\\"https://www.theguardian.com/technology/2025/mar/16/ai-software-coding-programmer-expertise-jobs-threat\\\">the Guardian</a> and countless online discussions.</p>\\n<p>I'm concerned that the definition is already escaping its original intent. I'm seeing people apply the term \\\"vibe coding\\\" to all forms of code written with the assistance of AI. I think that both dilutes the term and gives a false impression of what's possible with responsible <a href=\\\"https://simonwillison.net/tags/ai-assisted-programming/\\\">AI-assisted programming</a>.</p>\\n<p>Vibe coding is <em>not</em> the same thing as writing code with the help of LLMs!</p>\\n<p>To quote Andrej's <a href=\\\"https://twitter.com/karpathy/status/1886192184808149383\\\">original tweet</a> in full (with my emphasis added):</p>\\n<blockquote>\\n<p>There's a new kind of coding I call \\\"vibe coding\\\", where you fully give in to the vibes, embrace exponentials, and <strong>forget that the code even exists</strong>. It's possible because the LLMs (e.g. Cursor Composer w Sonnet) are getting too good. Also I just talk to Composer with SuperWhisper so I barely even touch the keyboard.</p>\\n<p>I ask for the dumbest things like \\\"decrease the padding on the sidebar by half\\\" because I'm too lazy to find it. I \\\"Accept All\\\" always, I don't read the diffs anymore. When I get error messages I just copy paste them in with no comment, usually that fixes it. The code grows beyond my usual comprehension, I'd have to really read through it for a while. Sometimes the LLMs can't fix a bug so I just work around it or ask for random changes until it goes away.</p>\\n<p><strong>It's not too bad for throwaway weekend projects, but still quite amusing</strong>. I'm building a project or webapp, but it's not really coding - I just see stuff, say stuff, run stuff, and copy paste stuff, and it mostly works.</p>\\n</blockquote>\\n<p>I <em>love</em> this definition. Andrej is an extremely talented and experienced programmer - he has no need for AI assistance at all. He's using LLMs like this because it's fun to try out wild new ideas, and the speed at which an LLM can produce code is an order of magnitude faster than even the most skilled human programmers. For low stakes projects and prototypes why not just <em>let it rip</em>?</p>\\n<h4 id=\\\"using-llms-for-code-responsibly-is-not-vibe-coding\\\">Using LLMs for code responsibly is not vibe coding</h4>\\n<p>Let's contrast this \\\"forget that the code even exists\\\" approach to how professional software developers use LLMs.</p>\\n<p>The job of a software developer is not (just) to churn out code and features. We need to create code that demonstrably works, and can be understood by other humans (and machines), and that will support continued development in the future.</p>\\n<p>We need to consider performance, accessibility, security, maintainability, cost efficiency. Software engineering is all about trade-offs - our job is to pick from dozens of potential solutions by balancing all manner of requirements, both explicit and implied.</p>\\n<p>We also <em>need</em> to read the code. My golden rule for production-quality AI-assisted programming is that I won't commit any code to my repository if I couldn't explain exactly what it does to somebody else.</p>\\n<p>If an LLM wrote the code for you, and you then reviewed it, tested it thoroughly and made sure you could explain how it works to someone else that's not vibe coding, it's software development. The usage of an LLM to support that activity is immaterial.</p>\\n<p>I wrote extensively about my own process in <a href=\\\"https://simonwillison.net/2025/Mar/11/using-llms-for-code/\\\">Here\\u2019s how I use LLMs to help me write code</a>. Vibe coding only describes a small subset of my approach.</p>\\n<h4 id=\\\"let-s-not-lose-track-of-what-makes-vibe-coding-special\\\">Let's not lose track of what makes vibe coding special</h4>\\n<p>I don't want \\\"vibe coding\\\" to become a negative term that's synonymous with irresponsible AI-assisted programming either. This weird new shape of programming has so much to offer the world!</p>\\n<p>I believe <strong>everyone deserves the ability</strong> to automate tedious tasks in their lives with computers. You shouldn't need a computer science degree or programming bootcamp in order to get computers to do extremely specific tasks for you.</p>\\n<p>If vibe coding grants millions of new people the ability to build their own custom tools, I could not be happier about it.</p>\\n<p>Some of those people will get bitten by the programming bug and go on to become proficient software developers. One of the biggest barriers to that profession is the incredibly steep initial learning curve - vibe coding shaves that initial barrier down to almost flat.</p>\\n<p>Vibe coding also has a ton to offer experienced developers. I've talked before about how <a href=\\\"https://simonwillison.net/2025/Mar/11/using-llms-for-code/\\\">using LLMs for code is difficult</a> - figuring out what does and doesn't work is a case of building intuition over time, and there are plenty of hidden sharp edges and traps along the way.</p>\\n<p>I think vibe coding is the best tool we have to help experienced developers build that intuition as to what LLMs can and cannot do for them. I've published more than <a href=\\\"https://tools.simonwillison.net/colophon\\\">80 experiments</a> I built with vibe coding and I've learned so much along the way. I would encourage any other developer, no matter their skill level, to try the same.</p>\\n<h4 id=\\\"when-is-it-ok-to-vibe-code-\\\">When is it OK to vibe code?</h4>\\n<p>If you're an experienced engineer this is likely obvious to you already, so I'm writing this section for people who are just getting started building software.</p>\\n<ul>\\n<li>Projects should be <strong>low stakes</strong>. Think about how much harm the code you are writing could cause if it has bugs or security vulnerabilities. Could somebody be harmed - damaged reputation, lost money or something worse? This is particularly important if you plan to build software that will be used by other people!</li>\\n<li>Consider <strong>security</strong>. This is a really difficult one - security is a huge topic. Some high level notes:\\n<ul>\\n<li>Watch out for <strong>secrets</strong> - anything that looks similar in shape to a password, such as the API key used to access an online tool. If your code involves secrets you need to take care not to accidentally expose them, which means you need to understand how the code works!</li>\\n<li>Think about <strong>data privacy</strong>. If you are building a tool that has access to private data - anything you wouldn't want to display to the world in a screen-sharing session - approach with caution. It's possible to vibe code personal tools that you paste private information into but you need to be very sure you understand if there are ways that data might leave your machine.</li>\\n</ul>\\n</li>\\n<li>Be a <strong>good network citizen</strong>. Anything that makes requests out to other platforms could increase the load (and hence the cost) on those services. This is a reason I like <a href=\\\"https://simonwillison.net/tags/claude-artifacts/\\\">Claude Artifacts</a> - their sandbox prevents accidents from causing harm elsewhere.</li>\\n<li>Is <strong>your money on the line</strong>? I've seen horror stories about people who vibe coded a feature against some API without a billing limit and racked up thousands of dollars in charges. Be very careful about using vibe coding against anything that's charged based on usage.</li>\\n</ul>\\n<p>If you're going to vibe code anything that might be used by other people, I recommend checking in with someone more experienced for a vibe check (hah) before you share it with the world.</p>\\n<h4 id=\\\"how-do-we-make-vibe-coding-better-\\\">How do we make vibe coding better?</h4>\\n<p>I think there are some fascinating software design challenges to be solved here.</p>\\n<p>Safe vibe coding for complete beginners starts with a <a href=\\\"https://en.wikipedia.org/wiki/Sandbox_(computer_security)\\\">sandbox</a>. Claude Artifacts was one of the first widely available vibe coding platforms and their approach to sandboxing is fantastic: code is restricted to running in a locked down <code>&lt;iframe&gt;</code>, can load only approved libraries and can't make any network requests to other sites.</p>\\n<p>This makes it very difficult for people to mess up and cause any harm with their projects. It also greatly limits what those projects can do - you can't use a Claude Artifact project to access data from external APIs for example, or even to build software that runs your own prompts against an LLM.</p>\\n<p>Other popular vibe coding tools like Cursor (which was initially intended for professional developers) have far less safety rails.</p>\\n<p>There's plenty of room for innovation in this space. I'm hoping to see a cambrian explosion in tooling to help people build their own custom tools as productively and safely as possible.</p>\\n<h4 id=\\\"go-forth-and-vibe-code\\\">Go forth and vibe code</h4>\\n<p>I really don't want to discourage people who are new to software from trying out vibe coding. The best way to learn anything is to build a project!</p>\\n<p>For experienced programmers this is an amazing way to start developing an intuition for what LLMs can and can't do. For beginners there's no better way to open your eyes to what's possible to achieve with code itself.</p>\\n<p>But please, don't confuse vibe coding with all other uses of LLMs for code.</p>\",\n",
      "    \"summary_detail\": {\n",
      "        \"type\": \"text/html\",\n",
      "        \"language\": \"en-us\",\n",
      "        \"base\": \"https://simonwillison.net/atom/entries/\",\n",
      "        \"value\": \"<p><strong>Vibe coding</strong> is having a moment. The term <a href=\\\"https://twitter.com/karpathy/status/1886192184808149383\\\">was coined by Andrej Karpathy</a> just a few weeks ago (on February 6th) and has since been featured <a href=\\\"https://www.nytimes.com/2025/02/27/technology/personaltech/vibecoding-ai-software-programming.html\\\">in the New York Times</a>, <a href=\\\"https://arstechnica.com/ai/2025/03/is-vibe-coding-with-ai-gnarly-or-reckless-maybe-some-of-both/\\\">Ars Technica</a>, <a href=\\\"https://www.theguardian.com/technology/2025/mar/16/ai-software-coding-programmer-expertise-jobs-threat\\\">the Guardian</a> and countless online discussions.</p>\\n<p>I'm concerned that the definition is already escaping its original intent. I'm seeing people apply the term \\\"vibe coding\\\" to all forms of code written with the assistance of AI. I think that both dilutes the term and gives a false impression of what's possible with responsible <a href=\\\"https://simonwillison.net/tags/ai-assisted-programming/\\\">AI-assisted programming</a>.</p>\\n<p>Vibe coding is <em>not</em> the same thing as writing code with the help of LLMs!</p>\\n<p>To quote Andrej's <a href=\\\"https://twitter.com/karpathy/status/1886192184808149383\\\">original tweet</a> in full (with my emphasis added):</p>\\n<blockquote>\\n<p>There's a new kind of coding I call \\\"vibe coding\\\", where you fully give in to the vibes, embrace exponentials, and <strong>forget that the code even exists</strong>. It's possible because the LLMs (e.g. Cursor Composer w Sonnet) are getting too good. Also I just talk to Composer with SuperWhisper so I barely even touch the keyboard.</p>\\n<p>I ask for the dumbest things like \\\"decrease the padding on the sidebar by half\\\" because I'm too lazy to find it. I \\\"Accept All\\\" always, I don't read the diffs anymore. When I get error messages I just copy paste them in with no comment, usually that fixes it. The code grows beyond my usual comprehension, I'd have to really read through it for a while. Sometimes the LLMs can't fix a bug so I just work around it or ask for random changes until it goes away.</p>\\n<p><strong>It's not too bad for throwaway weekend projects, but still quite amusing</strong>. I'm building a project or webapp, but it's not really coding - I just see stuff, say stuff, run stuff, and copy paste stuff, and it mostly works.</p>\\n</blockquote>\\n<p>I <em>love</em> this definition. Andrej is an extremely talented and experienced programmer - he has no need for AI assistance at all. He's using LLMs like this because it's fun to try out wild new ideas, and the speed at which an LLM can produce code is an order of magnitude faster than even the most skilled human programmers. For low stakes projects and prototypes why not just <em>let it rip</em>?</p>\\n<h4 id=\\\"using-llms-for-code-responsibly-is-not-vibe-coding\\\">Using LLMs for code responsibly is not vibe coding</h4>\\n<p>Let's contrast this \\\"forget that the code even exists\\\" approach to how professional software developers use LLMs.</p>\\n<p>The job of a software developer is not (just) to churn out code and features. We need to create code that demonstrably works, and can be understood by other humans (and machines), and that will support continued development in the future.</p>\\n<p>We need to consider performance, accessibility, security, maintainability, cost efficiency. Software engineering is all about trade-offs - our job is to pick from dozens of potential solutions by balancing all manner of requirements, both explicit and implied.</p>\\n<p>We also <em>need</em> to read the code. My golden rule for production-quality AI-assisted programming is that I won't commit any code to my repository if I couldn't explain exactly what it does to somebody else.</p>\\n<p>If an LLM wrote the code for you, and you then reviewed it, tested it thoroughly and made sure you could explain how it works to someone else that's not vibe coding, it's software development. The usage of an LLM to support that activity is immaterial.</p>\\n<p>I wrote extensively about my own process in <a href=\\\"https://simonwillison.net/2025/Mar/11/using-llms-for-code/\\\">Here\\u2019s how I use LLMs to help me write code</a>. Vibe coding only describes a small subset of my approach.</p>\\n<h4 id=\\\"let-s-not-lose-track-of-what-makes-vibe-coding-special\\\">Let's not lose track of what makes vibe coding special</h4>\\n<p>I don't want \\\"vibe coding\\\" to become a negative term that's synonymous with irresponsible AI-assisted programming either. This weird new shape of programming has so much to offer the world!</p>\\n<p>I believe <strong>everyone deserves the ability</strong> to automate tedious tasks in their lives with computers. You shouldn't need a computer science degree or programming bootcamp in order to get computers to do extremely specific tasks for you.</p>\\n<p>If vibe coding grants millions of new people the ability to build their own custom tools, I could not be happier about it.</p>\\n<p>Some of those people will get bitten by the programming bug and go on to become proficient software developers. One of the biggest barriers to that profession is the incredibly steep initial learning curve - vibe coding shaves that initial barrier down to almost flat.</p>\\n<p>Vibe coding also has a ton to offer experienced developers. I've talked before about how <a href=\\\"https://simonwillison.net/2025/Mar/11/using-llms-for-code/\\\">using LLMs for code is difficult</a> - figuring out what does and doesn't work is a case of building intuition over time, and there are plenty of hidden sharp edges and traps along the way.</p>\\n<p>I think vibe coding is the best tool we have to help experienced developers build that intuition as to what LLMs can and cannot do for them. I've published more than <a href=\\\"https://tools.simonwillison.net/colophon\\\">80 experiments</a> I built with vibe coding and I've learned so much along the way. I would encourage any other developer, no matter their skill level, to try the same.</p>\\n<h4 id=\\\"when-is-it-ok-to-vibe-code-\\\">When is it OK to vibe code?</h4>\\n<p>If you're an experienced engineer this is likely obvious to you already, so I'm writing this section for people who are just getting started building software.</p>\\n<ul>\\n<li>Projects should be <strong>low stakes</strong>. Think about how much harm the code you are writing could cause if it has bugs or security vulnerabilities. Could somebody be harmed - damaged reputation, lost money or something worse? This is particularly important if you plan to build software that will be used by other people!</li>\\n<li>Consider <strong>security</strong>. This is a really difficult one - security is a huge topic. Some high level notes:\\n<ul>\\n<li>Watch out for <strong>secrets</strong> - anything that looks similar in shape to a password, such as the API key used to access an online tool. If your code involves secrets you need to take care not to accidentally expose them, which means you need to understand how the code works!</li>\\n<li>Think about <strong>data privacy</strong>. If you are building a tool that has access to private data - anything you wouldn't want to display to the world in a screen-sharing session - approach with caution. It's possible to vibe code personal tools that you paste private information into but you need to be very sure you understand if there are ways that data might leave your machine.</li>\\n</ul>\\n</li>\\n<li>Be a <strong>good network citizen</strong>. Anything that makes requests out to other platforms could increase the load (and hence the cost) on those services. This is a reason I like <a href=\\\"https://simonwillison.net/tags/claude-artifacts/\\\">Claude Artifacts</a> - their sandbox prevents accidents from causing harm elsewhere.</li>\\n<li>Is <strong>your money on the line</strong>? I've seen horror stories about people who vibe coded a feature against some API without a billing limit and racked up thousands of dollars in charges. Be very careful about using vibe coding against anything that's charged based on usage.</li>\\n</ul>\\n<p>If you're going to vibe code anything that might be used by other people, I recommend checking in with someone more experienced for a vibe check (hah) before you share it with the world.</p>\\n<h4 id=\\\"how-do-we-make-vibe-coding-better-\\\">How do we make vibe coding better?</h4>\\n<p>I think there are some fascinating software design challenges to be solved here.</p>\\n<p>Safe vibe coding for complete beginners starts with a <a href=\\\"https://en.wikipedia.org/wiki/Sandbox_(computer_security)\\\">sandbox</a>. Claude Artifacts was one of the first widely available vibe coding platforms and their approach to sandboxing is fantastic: code is restricted to running in a locked down <code>&lt;iframe&gt;</code>, can load only approved libraries and can't make any network requests to other sites.</p>\\n<p>This makes it very difficult for people to mess up and cause any harm with their projects. It also greatly limits what those projects can do - you can't use a Claude Artifact project to access data from external APIs for example, or even to build software that runs your own prompts against an LLM.</p>\\n<p>Other popular vibe coding tools like Cursor (which was initially intended for professional developers) have far less safety rails.</p>\\n<p>There's plenty of room for innovation in this space. I'm hoping to see a cambrian explosion in tooling to help people build their own custom tools as productively and safely as possible.</p>\\n<h4 id=\\\"go-forth-and-vibe-code\\\">Go forth and vibe code</h4>\\n<p>I really don't want to discourage people who are new to software from trying out vibe coding. The best way to learn anything is to build a project!</p>\\n<p>For experienced programmers this is an amazing way to start developing an intuition for what LLMs can and can't do. For beginners there's no better way to open your eyes to what's possible to achieve with code itself.</p>\\n<p>But please, don't confuse vibe coding with all other uses of LLMs for code.</p>\"\n",
      "    },\n",
      "    \"tags\": [\n",
      "        {\n",
      "            \"term\": \"sandboxing\",\n",
      "            \"scheme\": null,\n",
      "            \"label\": null\n",
      "        },\n",
      "        {\n",
      "            \"term\": \"ai\",\n",
      "            \"scheme\": null,\n",
      "            \"label\": null\n",
      "        },\n",
      "        {\n",
      "            \"term\": \"generative-ai\",\n",
      "            \"scheme\": null,\n",
      "            \"label\": null\n",
      "        },\n",
      "        {\n",
      "            \"term\": \"llms\",\n",
      "            \"scheme\": null,\n",
      "            \"label\": null\n",
      "        },\n",
      "        {\n",
      "            \"term\": \"ai-assisted-programming\",\n",
      "            \"scheme\": null,\n",
      "            \"label\": null\n",
      "        },\n",
      "        {\n",
      "            \"term\": \"vibe-coding\",\n",
      "            \"scheme\": null,\n",
      "            \"label\": null\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# from online example\n",
    "import json\n",
    "import feedparser\n",
    "\n",
    "#url = \"https://rss.arxiv.org/rss/cs.AI\"\n",
    "#url = \"https://www.deepmind.com/blog/rss.xml\"\n",
    "url = \"https://simonwillison.net/atom/entries/\"\n",
    "\n",
    "feed = feedparser.parse(url)\n",
    "if feed.bozo == 1:\n",
    "        print(\"Error parsing feed:\", feed.bozo_exception)\n",
    "else:\n",
    "    print(\"Feed title:\", feed.feed.title)\n",
    "    for entry in feed.entries:        \n",
    "        print(json.dumps(entry, indent=4))\n",
    "        break\n",
    "        #print(\"Entry title:\", entry.title)\n",
    "        #print(\"Entry link:\", entry.link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from typing import List, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# If we are incrementally adding to this to extract historical trend \n",
    "# then also save list of IDs so we only add things not in the id list.\n",
    "# IDs could be saved separately in a pickled set maybe.\n",
    "class Feed(BaseModel):\n",
    "    title: str\n",
    "    fname: str\n",
    "    url  : str\n",
    "    items: List[dict]\n",
    "\n",
    "# Unused currently. Will simply load the JSON that is provided by feedreader.\n",
    "class FeedItem(BaseModel):\n",
    "    title: str\n",
    "    title_detail: str\n",
    "    url:str = Field(description=\"The main URL referenced\")\n",
    "    summary: str\n",
    "    summary_detail: str\n",
    "    tags : Optional[List[str]] = Field(description=\"The list of tags if present\")\n",
    "    published_date: datetime = Field(description=\"The date when the item was published\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing: MIT News - Artificial Intelligence: http://news.mit.edu/rss/topic/artificial-intelligence\n",
      "Error parsing feed: <unknown>:22:46: not well-formed (invalid token)\n",
      "Parsing: Google AI Blog: https://ai.googleblog.com/feeds/posts/default\n",
      "Error parsing feed: <unknown>:4:31: mismatched tag\n",
      "Parsing: DeepMind Blog: https://www.deepmind.com/blog/rss.xml\n",
      "Feed title: Google DeepMind Blog\n",
      "Parsing: OpenAI Blog: https://openai.com/blog/rss/\n",
      "Error parsing feed: <unknown>:4:17: not well-formed (invalid token)\n",
      "Parsing: Arxiv - cs.AI category: https://rss.arxiv.org/rss/cs.AI\n",
      "Feed title: cs.AI updates on arXiv.org\n",
      "Parsing: KDnuggets: https://www.kdnuggets.com/feed\n",
      "Feed title: KDnuggets\n",
      "Parsing: Analytics Vidhya: https://www.analyticsvidhya.com/feed/\n",
      "Feed title: Analytics Vidhya\n",
      "Parsing: Machine Learning Mastery: https://machinelearningmastery.com/feed/\n",
      "Feed title: MachineLearningMastery.com\n",
      "Parsing: BAIR Blog: https://bair.berkeley.edu/blog/feed.xml\n",
      "Feed title: The Berkeley Artificial Intelligence Research Blog\n",
      "Parsing: Towards Data Science: https://towardsdatascience.com/feed\n",
      "Error parsing feed: <unknown>:2:737: not well-formed (invalid token)\n",
      "Parsing: MarkTechPost: https://www.marktechpost.com/feed/\n",
      "Feed title: MarkTechPost\n",
      "Parsing: AIhub: https://aihub.org/feed/\n",
      "Feed title: ΑΙhub\n",
      "Parsing: Unite.AI: https://www.unite.ai/feed/\n",
      "Feed title: Unite.AI\n",
      "Parsing: Artificial-Intelligence.Blog: https://artificial-intelligence.blog/feed/\n",
      "Error parsing feed: <unknown>:2:0: syntax error\n",
      "Parsing: Simon Willison: https://simonwillison.net/atom/entries/\n",
      "Feed title: Simon Willison's Weblog: Entries\n",
      "Could nto read the following feeds:\n",
      "MIT News - Artificial Intelligence\n",
      " Google AI Blog\n",
      " OpenAI Blog\n",
      " Towards Data Science\n",
      " Artificial-Intelligence.Blog\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import feedparser\n",
    "\n",
    "def blog_title_to_fname(title:str):\n",
    "    fname = re.sub(r'[^a-zA-z\\s]*', '', title)\n",
    "    return re.sub(r'(\\s+)', '_', fname)\n",
    "\n",
    "# Load all the feed data into this with whatever JSON feedparser gives us\n",
    "# feedparser gives us a dict but it seems to be proper json as json.dumps works.\n",
    "ai_feeds = []\n",
    "err_list = []\n",
    "\n",
    "for title, val in ai_blogs.items():    \n",
    "    url = val[\"url\"]\n",
    "    f = Feed(\n",
    "        title = title,\n",
    "        fname = blog_title_to_fname(title),\n",
    "        url   = url,\n",
    "        items = []\n",
    "    )\n",
    "\n",
    "    print(f\"Parsing: {title}: {url}\")\n",
    "    feed = feedparser.parse(url)\n",
    "    if feed.bozo == 1:\n",
    "        print(\"Error parsing feed:\", feed.bozo_exception)\n",
    "        err_list.append(title)\n",
    "    else:\n",
    "        print(\"Feed title:\", feed.feed.title)\n",
    "        f.items = feed.entries\n",
    "        ai_feeds.append(f)\n",
    "\n",
    "print(f\"Could not read the following feeds:\\n{\"\\n \".join(err_list)}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Feed:DeepMind Blog to /home/vamsi/bitbucket/hillops/nbs/BSL_TakeHome/data/feed/raw/DeepMind_Blog.json\n",
      "Saving Feed:Arxiv - cs.AI category to /home/vamsi/bitbucket/hillops/nbs/BSL_TakeHome/data/feed/raw/Arxiv_csAI_category.json\n",
      "Saving Feed:KDnuggets to /home/vamsi/bitbucket/hillops/nbs/BSL_TakeHome/data/feed/raw/KDnuggets.json\n",
      "Saving Feed:Analytics Vidhya to /home/vamsi/bitbucket/hillops/nbs/BSL_TakeHome/data/feed/raw/Analytics_Vidhya.json\n",
      "Saving Feed:Machine Learning Mastery to /home/vamsi/bitbucket/hillops/nbs/BSL_TakeHome/data/feed/raw/Machine_Learning_Mastery.json\n",
      "Saving Feed:BAIR Blog to /home/vamsi/bitbucket/hillops/nbs/BSL_TakeHome/data/feed/raw/BAIR_Blog.json\n",
      "Saving Feed:MarkTechPost to /home/vamsi/bitbucket/hillops/nbs/BSL_TakeHome/data/feed/raw/MarkTechPost.json\n",
      "Saving Feed:AIhub to /home/vamsi/bitbucket/hillops/nbs/BSL_TakeHome/data/feed/raw/AIhub.json\n",
      "Saving Feed:Unite.AI to /home/vamsi/bitbucket/hillops/nbs/BSL_TakeHome/data/feed/raw/UniteAI.json\n",
      "Saving Feed:Simon Willison to /home/vamsi/bitbucket/hillops/nbs/BSL_TakeHome/data/feed/raw/Simon_Willison.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "DATA_DIR = Path(os.getcwd()) / \"data\"\n",
    "FEED_RAW_DATA_DIR = DATA_DIR / \"feed\" / \"raw\"\n",
    "\n",
    "os.makedirs(FEED_RAW_DATA_DIR, exist_ok=True)\n",
    "\n",
    "for feed in ai_feeds:\n",
    "    if feed.items and len(feed.items) > 0:\n",
    "        fpath = FEED_RAW_DATA_DIR / f\"{feed.fname}.json\"\n",
    "        print(f\"Saving Feed:{feed.title} to {str(fpath)}\")        \n",
    "        with open(str(fpath), 'w') as outfile:\n",
    "            json.dump(feed.model_dump(), outfile, indent=4)\n",
    "    else:\n",
    "        print(f\"Feed {feed.title} has no items!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratchpad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing the string output from the feedreader\n",
    "import datetime\n",
    "import dateutil\n",
    "\n",
    "#x = datetime.datetime(\"Wed, 19 Mar 2025 00:00:00 -0400\")\n",
    "x = dateutil.parser.parse(\"Wed, 19 Mar 2025 00:00:00 -0400\")\n",
    "\n",
    "print(x)\n",
    "print(type(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the names of the ai_blog keys into file titles for the jsonl files\n",
    "# Save them all in whatever json format they come in from feedreader\n",
    "# This way I can pull whatever I need for my formats as things change \n",
    "# without having to download everything.\n",
    "import re\n",
    "\n",
    "for nm in ai_blogs.keys():\n",
    "    nm2 = re.sub(r'[^a-zA-z\\s]*', '', nm)    \n",
    "    nm2 = re.sub(r'(\\s+)', '_', nm2)\n",
    "    print(f\"2: {nm} -> {nm2}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
