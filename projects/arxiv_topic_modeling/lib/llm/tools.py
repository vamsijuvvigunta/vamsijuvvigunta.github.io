import logging
from pydantic import ValidationError

#------------------------------------------------------------------------
# Tool execution infrastructure
# Updated from nbs/LLM/Py_llm_module_development.ipynb on 3/11/2025
#------------------------------------------------------------------------
import json
import jsonref
import inspect
from typing import TypeVar
from pydantic import ValidationError, BaseModel, create_model


class InPromptToolSchema:    
    """
    Holds the definition of the in-prompt schema and a collection
    of methods for fixed string generation recipes.
    """
    def __init__(self, name:str, desc:str, arg_json_str:str):
        self.name = name
        self.description = desc
        self.arg_json_str = arg_json_str

    # Follows the LlamaIndex format.
    # Use the fields directly for custom formats.
    def __str__(self):
        _fields = [f"Tool Name : {self.name}"]

        if self.description : 
            _fields.append(f"Tool Description : {self.description}")

        if self.arg_json_str: 
            _fields.append(f"Tool Args: {self.arg_json_str}")
        else:
            _fields.append(f"Tool Args: tool takes no arguments, use an empty string \"\" ")

        return "\n".join(_fields)            

F = TypeVar('F')

class Tool:    
    # tool_fn: fn(PyDanticObject) -> str
    def __init__(self,               
                 tool_fn):
        
        logging.debug(f"Tool : {tool_fn.__name__}, Initialization")
        _items = Tool.build_tool_call_items(tool_fn)
        assert(len(_items) == 3)

        # Name of the tool taken from function name.
        self.name                  = tool_fn.__name__

        # Tool Schema suitable for OpenAI tool calls. 
        # `tools=[schema1, schema2,..]``        
        self.tool_schema           = _items[0]        
        logging.debug(f"Tool : {tool_fn.__name__}, Schema=\n{json.dumps(self.tool_schema,indent=4)}\n")

        # Lambd to deserialize from string
        self.tool_arg_deserializer = _items[1] 

        # lambda to call function with deserialized arg (if any) 
        # or empty arg-list
        self.tool_func             = _items[2]

        # Tool schema suitable for in-prompt use (less verboce 
        # than full schema)
        # Type: InPromptToolSchema, not JSON
        self.in_prompt_schema      = Tool.build_inprompt_tool_schema(self.tool_schema)        
        logging.debug(f"Tool : {tool_fn.__name__}, InPromptSchema=\n{self.in_prompt_schema}\n")
    
    def exec(self, json_arg: str) -> str:
        if self.tool_arg_deserializer:
            try:
                logging.debug(f"Attempting to deserialize {json_arg} for tool: {self.name}")

                arg_obj = self.tool_arg_deserializer(json_arg)
                logging.debug(f"✔️ deserialized to {arg_obj}. Calling function")

                func_result = self.tool_func(arg_obj)
                logging.debug(f"✔️ function returned {func_result}")

                return func_result

            except ValidationError as e:
                logging.error(f"JSON string {json_arg} is not valid for {self.name}:{e}")
        else:            
            logging.debug(f"Calling no-arg function: {self.name}")            
            assert(json_arg == '{}' or json_arg == "" or json_arg is None)
            
            func_result = self.tool_func()
            logging.debug(f"✔️ function returned {func_result}")
            return func_result
    
    @staticmethod
    def build_inprompt_tool_schema(tool_schema:json) -> InPromptToolSchema:
        """
        Given a full tool-schema (as generated by build_tool_call_items), this builds 
        a simplified function schema meant for insertion into a prompt.

        Meant for use by the ctor. Not directly by client code except for testing.
        """    
        func_schema = tool_schema["function"]

        return InPromptToolSchema(
            name = func_schema["name"],
            desc = func_schema["description"] if "description" in func_schema else None,
            arg_json_str = json.dumps(func_schema["parameters"]) if "parameters" in func_schema else None
        )

    @staticmethod
    def build_tool_call_items(f:F):
        """
        f: A function of the form 'func(arg:BaseModel)` | `func()`
        Max of 1 argument and it should be a class deriving from PyDantic BaseModel  

        Returns a tuple: (tool_schema, arg_schema, arg_deserializer, func_call)
            tool_schema      - JSON representing the function/tool schema required by OpenAI etc
            arg_schema       - JSON representing the arg portion of the schema required by OpenAI etc
                               Meant for use inside prompts (ReAct prompts)
            arg_deserializer - f(str) -> PyDanticObj. Lambda to deserialize from string to the 
                               arg type used by the function
            func_call        - f(obj) -> str. Lambda to invoke the function with the deserialized json

        Eg.

        @dataclass
        class GetWeather(BaseModel):        
            location : str = Field(description="City and country e.g. San Jose, USA")

        def get_weather(args: GetWeather) -> float:
            '''
            Get current temperature for a given location.
            '''
            return 10    

        And use this thus:
        
            (tool_schema, arg_schema, arg_deserializer, fn_call) = build_tool_call_items(get_weather)
        """    
        if not inspect.isfunction(f):
            raise TypeError(f"{str(f)} should be a python function")

        sig = inspect.signature(f)
        num_params = len(sig.parameters)

        if num_params == 0:
            # 0 args case            
            return Tool._build_tool_call_items_0_args(f)

        else:            
            params = list(sig.parameters.items())
            p_ann   = params[0][1].annotation            
            p_class = p_ann.__class__

            # Special: 1 arg case with BaseModel argument. We directly use it's serialization
            # Special power to add docs per-field etc.
            if num_params == 1 and "pydantic._internal._model_construction.ModelMetaclass" in str(p_class):
                return Tool._build_tool_call_items_1_arg_pydantic(f) 
            else:
                # Dynamically create the BaseModel 
                # and build the rest from that                
                return Tool._build_tool_call_items_n_arg_dynamic(f)
    
    def _build_tool_call_items_0_args(fn):
        """
        Helper for build_tool_call_items
        """
        # See https://platform.openai.com/docs/guides/function-calling
        # Note: OpenAI does not like it if we send a parameters key with nul
        #       so not using that key at all.
        tool_schema = Tool._build_tool_schema_json(fn, None)        
        func_arg_deserializer = None
        func_call             = lambda : fn()        

        return (tool_schema, func_arg_deserializer, func_call)
    
    def _build_tool_call_items_1_arg_pydantic(fn):
        """
        Helper for build_tool_call_items when there is 1 arg 
        and it is a Pydantic BaseModel
        """
        sig = inspect.signature(fn)
        assert(len(sig.parameters) == 1)
        
        params = list(sig.parameters.items())
        p_ann   = params[0][1].annotation            
        p_class = p_ann.__class__
        assert("pydantic._internal._model_construction.ModelMetaclass" in str(p_class))

        # exec the class method to generate the json schema
        arg_schema = getattr(p_ann, 'model_json_schema').__call__()
        arg_schema = jsonref.replace_refs(arg_schema)

        # 👉 OpenAI enforces that "additionalProperties" : False is set!
        arg_schema["additionalProperties"] = False
                    
        # Now generate the schema for the full function
        tool_schema = Tool._build_tool_schema_json(fn, arg_schema)        

        # generate lambda to deserialize from stringified json
        des_callable = getattr(p_ann, 'model_validate_json')
        func_arg_deserializer = lambda json_str: des_callable.__call__(json_str)        

        # generate lambda to call the function with deaserialized json
        func_call = lambda deserialized: fn(deserialized)   

        return (tool_schema, func_arg_deserializer, func_call)
    
    def _build_tool_call_items_n_arg_dynamic(fn):
        """
        Helper for build_tool_call_items when there are more than one
        args of any type. 

        a Pydantic BaseModel is built dynamically from the signature
        """
        sig = inspect.signature(fn)
        assert(len(sig.parameters))

        # Build args to send to pydantic.create_model
        dyn_create_model_args = [f"\"{fn.__name__}_args\""]
        call_args_vec  = []
        for p in sig.parameters.values():    
            # build arg to generate the model
            arg = f"{p.name}=({p.annotation.__name__}, ...)"                
            dyn_create_model_args.append(arg)    

            # build arg to call fn using model fields
            # Assumes deserialized model-object will be called `des_obj`
            # (deserialized object)
            call_arg = f"{p.name} = des_obj.{p.name}"
            call_args_vec.append(call_arg)            

        cmd = f"create_model({", ".join(dyn_create_model_args)})"        
        dyn_model = eval(cmd)

        # Schema ----------
        arg_schema = dyn_model.model_json_schema()
        arg_schema = jsonref.replace_refs(arg_schema)                
        arg_schema["additionalProperties"] = False   # 👉 OpenAI needs this.

        # Now generate the schema for the full function
        # See https://platform.openai.com/docs/guides/function-calling
        tool_schema = Tool._build_tool_schema_json(fn, arg_schema)

        # deserializer ---
        func_arg_deserializer = lambda jstr: dyn_model.model_validate_json(jstr)
        
        # caller ---------
        # This is a bit complex. What I want for `func_call` is 
        # lambda deserialized_object : fn(deserialized_object)
        # However, when this is built using eval, it does not close over fn!
        # only globals. So we need a second level of indirection with a function 
        # that does close over fn
        call_eval_str = f"lambda des_obj, fn: fn({", ".join(call_args_vec)})"
        logging.info(f"eval string for func calling = {call_eval_str}")
        call_fn_2 = eval(call_eval_str)                   # does not close over fn, so sending fn as arg
        func_call= lambda des_obj: call_fn_2(des_obj, fn) # this closes over fn and can call call_fn_2

        return (tool_schema, func_arg_deserializer, func_call)
    
    def _build_tool_schema_json(fn, arg_schema):
        # See https://platform.openai.com/docs/guides/function-calling
        tool_schema = {
            "type"       : "function",
            "function"   : {
                "name"       : fn.__name__,
                "description": fn.__doc__.strip() if fn.__doc__ else f"function {fn.__name__}",                
                "strict"     : True
            }
        }            

        if arg_schema:
            tool_schema["function"]["parameters"] = arg_schema
        else:
            # empty args is not accepted. Seems to vary by mood of OpenAI
            # this works
            # 👉 OpenAI enforces that "additionalProperties" : False is set!
            tool_schema["function"]["parameters"] = {
                "type" : "object",
                "properties" : {},
                "required"   : [],
                "additionalProperties" : False
            }

        return tool_schema

        
                    
#------------------------------------------------------------------------------
class ToolCollection:
    def __init__(self, tools= None):
        # {name : Tool}
        self.tool_dict = {}

        if tools:
            for t in tools:
                self.register_tool(t)

    def register_tool(self, tool: Tool):
        """
         Registers a tool by name for later use
         tool : Tool | python function.
        """
        if inspect.isfunction(tool):            
            tool = Tool(tool)

        if tool.name in self.tool_dict:
            logging.warn(f"Tool {tool.name} has already been registed. Overwriting!")
        
        assert(tool.tool_func)
        assert(tool.tool_schema)
        self.tool_dict[tool.name] = tool
        
    def exec_tool(self, name: str, args: str) -> str :
        if not name in self.tool_dict:
            raise KeyError(f"Tool: {name} is not registered! Cannot call!")
        else:            
            tool = self.tool_dict[name]
            logging.debug(f"Executing tool: {tool.name}")
            return tool.exec(args)
    
    def has_tool(self, tool_name:str):
        return tool_name in self.tool_dict

    def get_tool_names(self):
        return [key for key in self.tool_dict.keys()]
    
    def get_schemas(self, mapper=None) :
        mapper = mapper if mapper else lambda x: x
        return [mapper(tool.tool_schema) for tool in self.tool_dict.values()]
    
    def get_inprompt_schemas(self, mapper=None) :
        mapper = mapper if mapper else lambda x: x
        return [mapper(tool.in_prompt_schema) for tool in self.tool_dict.values()]        
